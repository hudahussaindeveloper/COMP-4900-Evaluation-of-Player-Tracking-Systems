{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# Player Tracking System Comparison\n",
        "\n",
        "This notebook compares 3 different player tracking systems:\n",
        "- Eagle\n",
        "- Darkmyter (using Ultralytics YOLO)\n",
        "- Ultralytics YOLO 11 + Botsort\n",
        "\n",
        "**Important**: Run cells in order from top to bottom!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "setup",
        "outputId": "4dd1b8ad-6fff-44f2-f6a8-88327c01a100"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m[SUCCESS] Directory structure created\u001b[0m\n",
            "Working directory: /content\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Setup directories and utilities\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "BASE_DIR = Path(\"/content\")\n",
        "REPOS_DIR = BASE_DIR / \"repositories\"\n",
        "VIDEOS_DIR = BASE_DIR / \"videos\"\n",
        "CLIPS_DIR = BASE_DIR / \"clips\"\n",
        "OUTPUT_DIR = BASE_DIR / \"output\"\n",
        "\n",
        "for d in [REPOS_DIR, VIDEOS_DIR, CLIPS_DIR, OUTPUT_DIR]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def print_status(msg, status=\"INFO\"):\n",
        "    \"Print colored status messages\"\n",
        "    colors = {\n",
        "        \"INFO\": \"\\033[94m\",\n",
        "        \"SUCCESS\": \"\\033[92m\",\n",
        "        \"WARNING\": \"\\033[93m\",\n",
        "        \"ERROR\": \"\\033[91m\",\n",
        "        \"RESET\": \"\\033[0m\"\n",
        "    }\n",
        "    print(f\"{colors.get(status, '')}[{status}] {msg}{colors['RESET']}\")\n",
        "\n",
        "print_status(\"Directory structure created\", \"SUCCESS\")\n",
        "print(f\"Working directory: {BASE_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clone",
        "outputId": "ffc776ce-ded1-4442-ebac-030e0c93d9d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Cloning repositories...\u001b[0m\n",
            "\u001b[94m[INFO] eagle: Cloning...\u001b[0m\n",
            "\u001b[92m[SUCCESS] eagle: Cloned successfully\u001b[0m\n",
            "\u001b[94m[INFO] darkmyter: Cloning...\u001b[0m\n",
            "\u001b[92m[SUCCESS] darkmyter: Cloned successfully\u001b[0m\n",
            "\u001b[92m[SUCCESS] Repository cloning complete\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Clone all repositories\n",
        "\n",
        "import subprocess\n",
        "\n",
        "REPOSITORIES = {\n",
        "    \"eagle\": \"https://github.com/nreHieW/Eagle.git\",\n",
        "    \"darkmyter\": \"https://github.com/Darkmyter/Football-Players-Tracking.git\",\n",
        "}\n",
        "\n",
        "print_status(\"Cloning repositories...\", \"INFO\")\n",
        "\n",
        "for name, url in REPOSITORIES.items():\n",
        "    repo_path = REPOS_DIR / name\n",
        "\n",
        "    if repo_path.exists():\n",
        "        print_status(f\"{name}: Already exists, skipping\", \"WARNING\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        print_status(f\"{name}: Cloning...\", \"INFO\")\n",
        "        result = subprocess.run(\n",
        "            [\"git\", \"clone\", url, str(repo_path)],\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=300\n",
        "        )\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            print_status(f\"{name}: Cloned successfully\", \"SUCCESS\")\n",
        "        else:\n",
        "            print_status(f\"{name}: Clone failed - {result.stderr[:100]}\", \"ERROR\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print_status(f\"{name}: Clone failed - {str(e)}\", \"ERROR\")\n",
        "\n",
        "print_status(\"Repository cloning complete\", \"SUCCESS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "install",
        "outputId": "105bc672-d307-4b35-f9ae-34d91b21a6b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Installing dependencies...\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.0/180.0 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.4/335.4 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m827.9/827.9 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.6/831.6 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.5/159.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m120.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.4/212.4 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.0/80.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onemetric\n",
            "  Using cached onemetric-0.1.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from onemetric) (11.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from onemetric) (2.0.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from onemetric) (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from onemetric) (3.10.0)\n",
            "Collecting dataclasses-json (from onemetric)\n",
            "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->onemetric)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->onemetric)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->onemetric) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->onemetric) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->onemetric) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->onemetric) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->onemetric) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->onemetric) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->onemetric) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn->onemetric) (2.2.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn->onemetric) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn->onemetric) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->onemetric) (1.17.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->onemetric)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->onemetric) (4.15.0)\n",
            "Downloading onemetric-0.1.2-py3-none-any.whl (21 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, onemetric\n",
            "Successfully installed dataclasses-json-0.6.7 marshmallow-3.26.1 mypy-extensions-1.1.0 onemetric-0.1.2 typing-inspect-0.9.0\n",
            "\u001b[92m[SUCCESS] Dependencies installed\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Install dependencies\n",
        "\n",
        "print_status(\"Installing dependencies...\", \"INFO\")\n",
        "\n",
        "!pip install -q torch torchvision torchaudio tracklab\n",
        "!pip install -q opencv-python numpy scipy pandas scikit-learn matplotlib\n",
        "!pip install -q ultralytics supervision\n",
        "!pip install -q gdown Pillow tqdm requests\n",
        "!pip install -q \\\n",
        "    loguru cython cython_bbox lap onemetric scikit-image tabulate tqdm numpy torch torchvision opencv-python pyyaml yolox\n",
        "!pip install -q loguru\n",
        "!pip install onemetric #THIS CELL IS IMPORTANT\n",
        "\n",
        "\n",
        "print_status(\"Dependencies installed\", \"SUCCESS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzy7qI3atgID",
        "outputId": "bf713d3a-f994-42bb-bb8c-e9f5ca242b28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m.pt to 'yolo11m.pt': 100% ━━━━━━━━━━━━ 38.8MB 209.1MB/s 0.2s\n",
            "Loaded weights from: yolo11m.pt\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO(\"yolo11m.pt\")\n",
        "print(\"Loaded weights from:\", getattr(model, \"ckpt_path\", \"unknown path\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "download_videos",
        "outputId": "65d9390e-e74f-41f9-d702-360c5b25f912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Downloading videos from shared folder...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1rdgLjwQwjrrHt0k2v34v9XCGEJYIwjVH FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720-seg02.mp4\n",
            "Processing file 1fdNwRhMj73wycryjntayMyUx2XNJB1Wr FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720-seg03.mp4\n",
            "Processing file 107jRObGsfiRFCJXMcXPoZj-kld9hSYtf FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720-seg04.mp4\n",
            "Processing file 1mlQNwre8ixs6K96UndFU14SPmJHOKH7Q FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720-seg08.mp4\n",
            "Processing file 1vlOGrvj-X9k6jhN6CHWCM4XAePPivL3I FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720-seg14.mp4\n",
            "Processing file 1axUbU4cIlVoYgUw5R8YszVP9zN-N3fPl FULL MATCH  Brazil v Mexico  World Cup 2018 720p-seg04.mp4\n",
            "Processing file 1BGpZmffrpdxEA9K6eIQc3ky4mUKJCEsk FULL MATCH  Brazil v Mexico  World Cup 2018 720p-seg06.mp4\n",
            "Processing file 1sGVeVIk9TgOMsGS0ClrzZM8J-hXYruKN FULL MATCH  Brazil v Mexico  World Cup 2018 720p-seg07.mp4\n",
            "Processing file 1_sN4paZaPWCxmgRLIN7Us3AdtFYHtEp- FULL MATCH  Brazil v Mexico  World Cup 2018 720p-seg12.mp4\n",
            "Processing file 1wzvRUt7nDKX_HSLPKANcAUfI3hncHO38 FULL MATCH  Brazil v Mexico  World Cup 2018 720p-seg13.mp4\n",
            "Processing file 1xprUH7x0_Jkue0iW2ko7LK6iRVX_HJz5 FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p-seg03.mp4\n",
            "Processing file 1eDZueK96t6dnYV-EWSrwNTlz1MvuDz6u FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p-seg06.mp4\n",
            "Processing file 1cILw9rB_Ba-CKoFlpvMn9kVvo2ekhZUR FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p-seg09.mp4\n",
            "Processing file 1EfNdjmGV9vdtsjWrHuOfLoGUC__i_V75 FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p-seg15.mp4\n",
            "Processing file 1O3hhGF8URj4uUOglwFLq4azmUgvCi1II FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p-seg17.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rdgLjwQwjrrHt0k2v34v9XCGEJYIwjVH\n",
            "To: /content/videos/FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720-seg02.mp4\n",
            "100%|██████████| 85.5M/85.5M [00:01<00:00, 54.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fdNwRhMj73wycryjntayMyUx2XNJB1Wr\n",
            "To: /content/videos/FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720-seg03.mp4\n",
            "100%|██████████| 84.8M/84.8M [00:02<00:00, 40.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=107jRObGsfiRFCJXMcXPoZj-kld9hSYtf\n",
            "To: /content/videos/FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720-seg04.mp4\n",
            "100%|██████████| 84.6M/84.6M [00:02<00:00, 29.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1mlQNwre8ixs6K96UndFU14SPmJHOKH7Q\n",
            "To: /content/videos/FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720-seg08.mp4\n",
            "100%|██████████| 81.3M/81.3M [00:01<00:00, 64.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vlOGrvj-X9k6jhN6CHWCM4XAePPivL3I\n",
            "To: /content/videos/FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720-seg14.mp4\n",
            "100%|██████████| 81.7M/81.7M [00:22<00:00, 3.61MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1axUbU4cIlVoYgUw5R8YszVP9zN-N3fPl\n",
            "To: /content/videos/FULL MATCH  Brazil v Mexico  World Cup 2018 720p-seg04.mp4\n",
            "100%|██████████| 82.2M/82.2M [00:02<00:00, 38.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BGpZmffrpdxEA9K6eIQc3ky4mUKJCEsk\n",
            "To: /content/videos/FULL MATCH  Brazil v Mexico  World Cup 2018 720p-seg06.mp4\n",
            "100%|██████████| 83.5M/83.5M [00:01<00:00, 64.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1sGVeVIk9TgOMsGS0ClrzZM8J-hXYruKN\n",
            "To: /content/videos/FULL MATCH  Brazil v Mexico  World Cup 2018 720p-seg07.mp4\n",
            "100%|██████████| 96.2M/96.2M [00:01<00:00, 54.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_sN4paZaPWCxmgRLIN7Us3AdtFYHtEp-\n",
            "To: /content/videos/FULL MATCH  Brazil v Mexico  World Cup 2018 720p-seg12.mp4\n",
            "100%|██████████| 98.7M/98.7M [00:01<00:00, 79.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wzvRUt7nDKX_HSLPKANcAUfI3hncHO38\n",
            "To: /content/videos/FULL MATCH  Brazil v Mexico  World Cup 2018 720p-seg13.mp4\n",
            "100%|██████████| 85.9M/85.9M [00:01<00:00, 54.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xprUH7x0_Jkue0iW2ko7LK6iRVX_HJz5\n",
            "To: /content/videos/FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p-seg03.mp4\n",
            "100%|██████████| 72.5M/72.5M [00:01<00:00, 53.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1eDZueK96t6dnYV-EWSrwNTlz1MvuDz6u\n",
            "To: /content/videos/FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p-seg06.mp4\n",
            "100%|██████████| 71.7M/71.7M [00:01<00:00, 45.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cILw9rB_Ba-CKoFlpvMn9kVvo2ekhZUR\n",
            "To: /content/videos/FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p-seg09.mp4\n",
            "100%|██████████| 73.8M/73.8M [00:00<00:00, 78.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1EfNdjmGV9vdtsjWrHuOfLoGUC__i_V75\n",
            "To: /content/videos/FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p-seg15.mp4\n",
            "100%|██████████| 65.8M/65.8M [00:00<00:00, 69.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1O3hhGF8URj4uUOglwFLq4azmUgvCi1II\n",
            "To: /content/videos/FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p-seg17.mp4\n",
            "100%|██████████| 62.5M/62.5M [00:01<00:00, 50.1MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DOWNLOADED 15 VIDEO(S)\n",
            "==================================================\n",
            "1. FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p-seg06.mp4 (68.4 MB)\n",
            "2. FULL MATCH  Brazil v Mexico  World Cup 2018 720p-seg07.mp4 (91.7 MB)\n",
            "3. FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720-seg02.mp4 (81.6 MB)\n",
            "4. FULL MATCH  Brazil v Mexico  World Cup 2018 720p-seg04.mp4 (78.4 MB)\n",
            "5. FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p-seg15.mp4 (62.8 MB)\n",
            "6. FULL MATCH  Brazil v Mexico  World Cup 2018 720p-seg12.mp4 (94.1 MB)\n",
            "7. FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720-seg03.mp4 (80.9 MB)\n",
            "8. FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p-seg09.mp4 (70.4 MB)\n",
            "9. FULL MATCH  Brazil v Mexico  World Cup 2018 720p-seg13.mp4 (82.0 MB)\n",
            "10. FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p-seg03.mp4 (69.1 MB)\n",
            "11. FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720-seg14.mp4 (77.9 MB)\n",
            "12. FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720-seg08.mp4 (77.5 MB)\n",
            "13. FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p-seg17.mp4 (59.6 MB)\n",
            "14. FULL MATCH  Brazil v Mexico  World Cup 2018 720p-seg06.mp4 (79.7 MB)\n",
            "15. FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720-seg04.mp4 (80.7 MB)\n",
            "\n",
            "\n",
            "VIDEO SELECTION\n",
            "\n",
            "How many videos do you want to evaluate?\n",
            "  - Enter a number between 1 and 15\n",
            "  - Enter 'all' or leave blank to process ALL 15 videos\n",
            "\n",
            "Number of videos: \n",
            "\u001b[92m[SUCCESS] Selected ALL 15 videos\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Download videos from Google Drive\n",
        "\n",
        "!pip install -q gdown\n",
        "\n",
        "import gdown\n",
        "from pathlib import Path\n",
        "\n",
        "# Shared folder ID\n",
        "FOLDER_ID = \"1Cs4kTX6GYwfcpKyDZdqRKBezz49wT7_N\"\n",
        "\n",
        "print_status(\"Downloading videos from shared folder...\", \"INFO\")\n",
        "\n",
        "try:\n",
        "    gdown.download_folder(\n",
        "        id=FOLDER_ID,\n",
        "        output=str(VIDEOS_DIR),\n",
        "        quiet=False,\n",
        "        use_cookies=False\n",
        "    )\n",
        "\n",
        "    # List downloaded videos\n",
        "    video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.MP4', '.AVI', '.MOV', '.MKV']\n",
        "    available_videos = []\n",
        "\n",
        "    for ext in video_extensions:\n",
        "        available_videos.extend(list(VIDEOS_DIR.glob(f\"*{ext}\")))\n",
        "\n",
        "    if not available_videos:\n",
        "        print_status(\"No video files found\", \"ERROR\")\n",
        "    else:\n",
        "        print(f\"\\nDOWNLOADED {len(available_videos)} VIDEO(S)\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        for idx, video in enumerate(available_videos, 1):\n",
        "            size_mb = video.stat().st_size / (1024 * 1024)\n",
        "            print(f\"{idx}. {video.name} ({size_mb:.1f} MB)\")\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(\"VIDEO SELECTION\")\n",
        "\n",
        "        # Ask for number of videos\n",
        "        print(\"\\nHow many videos do you want to evaluate?\")\n",
        "        print(f\"  - Enter a number between 1 and {len(available_videos)}\")\n",
        "        print(f\"  - Enter 'all' or leave blank to process ALL {len(available_videos)} videos\")\n",
        "\n",
        "        num_selection = input(\"\\nNumber of videos: \").strip().lower()\n",
        "\n",
        "        VIDEO_PATHS = []\n",
        "\n",
        "        if not num_selection or num_selection == 'all':\n",
        "            VIDEO_PATHS = available_videos\n",
        "            print_status(f\"Selected ALL {len(VIDEO_PATHS)} videos\", \"SUCCESS\")\n",
        "        elif num_selection.isdigit():\n",
        "            num_videos = int(num_selection)\n",
        "            if 1 <= num_videos <= len(available_videos):\n",
        "                if num_videos == len(available_videos):\n",
        "                    VIDEO_PATHS = available_videos\n",
        "                else:\n",
        "                    print(f\"\\nSelect {num_videos} video(s) from the list above:\")\n",
        "                    print(\"  - Enter comma-separated numbers (e.g., '1,3,5')\")\n",
        "                    print(f\"  - Or enter 'first' to select the first {num_videos} videos\")\n",
        "\n",
        "                    video_selection = input(\"\\nYour selection: \").strip().lower()\n",
        "\n",
        "                    if video_selection == 'first':\n",
        "                        VIDEO_PATHS = available_videos[:num_videos]\n",
        "                    else:\n",
        "                        try:\n",
        "                            indices = [int(x.strip()) for x in video_selection.split(',')]\n",
        "                            if len(indices) != num_videos:\n",
        "                                print_status(f\"Warning: Selected {len(indices)} videos instead of {num_videos}\", \"WARNING\")\n",
        "                            for idx in indices[:num_videos]:\n",
        "                                if 1 <= idx <= len(available_videos):\n",
        "                                    VIDEO_PATHS.append(available_videos[idx - 1])\n",
        "                        except ValueError:\n",
        "                            print_status(\"Invalid input, selecting first videos\", \"WARNING\")\n",
        "                            VIDEO_PATHS = available_videos[:num_videos]\n",
        "\n",
        "                print_status(f\"Selected {len(VIDEO_PATHS)} video(s)\", \"SUCCESS\")\n",
        "                for video in VIDEO_PATHS:\n",
        "                    print(f\"  - {video.name}\")\n",
        "            else:\n",
        "                print_status(f\"Invalid number. Must be between 1 and {len(available_videos)}\", \"ERROR\")\n",
        "        else:\n",
        "            print_status(\"Invalid input\", \"ERROR\")\n",
        "\n",
        "        if not VIDEO_PATHS:\n",
        "            print_status(\"No videos selected\", \"ERROR\")\n",
        "\n",
        "except Exception as e:\n",
        "    print_status(f\"Download failed: {str(e)}\", \"ERROR\")\n",
        "    print(\"\\nNote: Make sure the folder is set to 'Anyone with the link can view'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "extract_clips",
        "outputId": "61b241b7-aa45-4ae0-9f48-3fbc111608e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PREPARING: FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p-seg06\n",
            "Duration: 304.8s | FPS: 25.0 | Frames: 7620\n",
            "\u001b[94m[INFO] Will extract start, middle, and end clips\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'start' ready (13.0 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'middle' ready (12.7 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'end' ready (14.3 MB)\u001b[0m\n",
            "\n",
            "PREPARING: FULL MATCH  Brazil v Mexico  World Cup 2018 720p-seg07\n",
            "Duration: 306.0s | FPS: 50.0 | Frames: 15301\n",
            "\u001b[94m[INFO] Will extract start, middle, and end clips\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'start' ready (13.0 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'middle' ready (17.8 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'end' ready (20.5 MB)\u001b[0m\n",
            "\n",
            "PREPARING: FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720-seg02\n",
            "Duration: 305.0s | FPS: 25.0 | Frames: 7626\n",
            "\u001b[94m[INFO] Will extract start, middle, and end clips\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'start' ready (14.9 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'middle' ready (15.4 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'end' ready (15.1 MB)\u001b[0m\n",
            "\n",
            "PREPARING: FULL MATCH  Brazil v Mexico  World Cup 2018 720p-seg04\n",
            "Duration: 306.0s | FPS: 50.0 | Frames: 15301\n",
            "\u001b[94m[INFO] Will extract start, middle, and end clips\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'start' ready (15.3 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'middle' ready (16.7 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'end' ready (12.2 MB)\u001b[0m\n",
            "\n",
            "PREPARING: FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p-seg15\n",
            "Duration: 302.9s | FPS: 25.0 | Frames: 7572\n",
            "\u001b[94m[INFO] Will extract start, middle, and end clips\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'start' ready (11.6 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'middle' ready (11.4 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'end' ready (11.6 MB)\u001b[0m\n",
            "\n",
            "PREPARING: FULL MATCH  Brazil v Mexico  World Cup 2018 720p-seg12\n",
            "Duration: 306.0s | FPS: 50.0 | Frames: 15301\n",
            "\u001b[94m[INFO] Will extract start, middle, and end clips\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'start' ready (19.9 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'middle' ready (17.0 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'end' ready (14.2 MB)\u001b[0m\n",
            "\n",
            "PREPARING: FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720-seg03\n",
            "Duration: 305.0s | FPS: 25.0 | Frames: 7626\n",
            "\u001b[94m[INFO] Will extract start, middle, and end clips\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'start' ready (14.9 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'middle' ready (14.9 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'end' ready (15.0 MB)\u001b[0m\n",
            "\n",
            "PREPARING: FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p-seg09\n",
            "Duration: 304.8s | FPS: 25.0 | Frames: 7620\n",
            "\u001b[94m[INFO] Will extract start, middle, and end clips\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'start' ready (13.1 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'middle' ready (14.1 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'end' ready (13.6 MB)\u001b[0m\n",
            "\n",
            "PREPARING: FULL MATCH  Brazil v Mexico  World Cup 2018 720p-seg13\n",
            "Duration: 306.0s | FPS: 50.0 | Frames: 15301\n",
            "\u001b[94m[INFO] Will extract start, middle, and end clips\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'start' ready (13.9 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'middle' ready (12.9 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'end' ready (15.0 MB)\u001b[0m\n",
            "\n",
            "PREPARING: FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p-seg03\n",
            "Duration: 305.0s | FPS: 25.0 | Frames: 7626\n",
            "\u001b[94m[INFO] Will extract start, middle, and end clips\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'start' ready (11.8 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'middle' ready (13.4 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'end' ready (13.1 MB)\u001b[0m\n",
            "\n",
            "PREPARING: FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720-seg14\n",
            "Duration: 304.9s | FPS: 25.0 | Frames: 7622\n",
            "\u001b[94m[INFO] Will extract start, middle, and end clips\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'start' ready (14.4 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'middle' ready (14.2 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'end' ready (16.1 MB)\u001b[0m\n",
            "\n",
            "PREPARING: FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720-seg08\n",
            "Duration: 305.0s | FPS: 25.0 | Frames: 7626\n",
            "\u001b[94m[INFO] Will extract start, middle, and end clips\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'start' ready (14.1 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'middle' ready (14.7 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'end' ready (14.4 MB)\u001b[0m\n",
            "\n",
            "PREPARING: FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p-seg17\n",
            "Duration: 302.2s | FPS: 25.0 | Frames: 7556\n",
            "\u001b[94m[INFO] Will extract start, middle, and end clips\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'start' ready (11.4 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'middle' ready (10.4 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'end' ready (12.1 MB)\u001b[0m\n",
            "\n",
            "PREPARING: FULL MATCH  Brazil v Mexico  World Cup 2018 720p-seg06\n",
            "Duration: 306.0s | FPS: 50.0 | Frames: 15301\n",
            "\u001b[94m[INFO] Will extract start, middle, and end clips\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'start' ready (17.0 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'middle' ready (13.3 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'end' ready (14.2 MB)\u001b[0m\n",
            "\n",
            "PREPARING: FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720-seg04\n",
            "Duration: 305.0s | FPS: 25.0 | Frames: 7626\n",
            "\u001b[94m[INFO] Will extract start, middle, and end clips\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'start' ready (14.8 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'middle' ready (15.5 MB)\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'end' ready (14.8 MB)\u001b[0m\n",
            "\n",
            "\n",
            "PREPARATION COMPLETE\n",
            "Prepared 15 video(s) with both full and clip options\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Prepare videos and clips\n",
        "\n",
        "import cv2\n",
        "import subprocess\n",
        "\n",
        "CLIP_DURATION = 60\n",
        "\n",
        "# Prepare both full videos and clips\n",
        "FULL_VIDEOS = {}\n",
        "VIDEO_CLIPS = {}\n",
        "\n",
        "for VIDEO_PATH in VIDEO_PATHS:\n",
        "    VIDEO_NAME = VIDEO_PATH.stem\n",
        "\n",
        "    print(f\"\\nPREPARING: {VIDEO_NAME}\")\n",
        "\n",
        "    # Store full video path\n",
        "    FULL_VIDEOS[VIDEO_NAME] = {\"full\": VIDEO_PATH}\n",
        "\n",
        "    # Get video info for clip extraction\n",
        "    cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    duration = total_frames / fps\n",
        "    cap.release()\n",
        "\n",
        "    print(f\"Duration: {duration:.1f}s | FPS: {fps:.1f} | Frames: {total_frames}\")\n",
        "\n",
        "    # Determine clip positions\n",
        "    if duration < CLIP_DURATION * 3:\n",
        "        if duration < CLIP_DURATION:\n",
        "            CLIPS = [(0, duration, \"full\")]\n",
        "            print_status(f\"Video shorter than {CLIP_DURATION}s, will use full video\", \"INFO\")\n",
        "        else:\n",
        "            CLIPS = [\n",
        "                (0, CLIP_DURATION, \"start\"),\n",
        "                (max(duration - CLIP_DURATION, 0), CLIP_DURATION, \"end\")\n",
        "            ]\n",
        "            print_status(\"Will extract start and end clips\", \"INFO\")\n",
        "    else:\n",
        "        CLIPS = [\n",
        "            (0, CLIP_DURATION, \"start\"),\n",
        "            ((duration - CLIP_DURATION) / 2, CLIP_DURATION, \"middle\"),\n",
        "            (duration - CLIP_DURATION, CLIP_DURATION, \"end\")\n",
        "        ]\n",
        "        print_status(\"Will extract start, middle, and end clips\", \"INFO\")\n",
        "\n",
        "    # Extract clips\n",
        "    CLIP_PATHS = {}\n",
        "    for start_time, clip_dur, position in CLIPS:\n",
        "        clip_name = f\"{VIDEO_NAME}_{position}.mp4\"\n",
        "        clip_path = CLIPS_DIR / clip_name\n",
        "\n",
        "        cmd = [\n",
        "            \"ffmpeg\", \"-i\", str(VIDEO_PATH),\n",
        "            \"-ss\", str(start_time),\n",
        "            \"-t\", str(clip_dur),\n",
        "            \"-c\", \"copy\",\n",
        "            str(clip_path),\n",
        "            \"-y\",\n",
        "            \"-loglevel\", \"error\"\n",
        "        ]\n",
        "\n",
        "        result = subprocess.run(cmd, capture_output=True)\n",
        "\n",
        "        if result.returncode == 0 and clip_path.exists():\n",
        "            CLIP_PATHS[position] = clip_path\n",
        "            size_mb = clip_path.stat().st_size / (1024 * 1024)\n",
        "            print_status(f\"Clip '{position}' ready ({size_mb:.1f} MB)\", \"SUCCESS\")\n",
        "        else:\n",
        "            print_status(f\"Failed to extract '{position}' clip\", \"ERROR\")\n",
        "\n",
        "    VIDEO_CLIPS[VIDEO_NAME] = CLIP_PATHS\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"PREPARATION COMPLETE\")\n",
        "print(f\"Prepared {len(VIDEO_PATHS)} video(s) with both full and clip options\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "H_etsZN8K1QG",
        "outputId": "27634047-aa94-4de3-936f-7561ab3f3148"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Setting up Darkmyter tracking...\u001b[0m\n",
            "\u001b[94m[INFO] Cloning original ByteTrack repository...\u001b[0m\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for cython_bbox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[94m[INFO] Downloading Darkmyter football weights...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=12dWRBsegmyGE3feTdy9LBf1eZ-hTZ9Sx\n",
            "From (redirected): https://drive.google.com/uc?id=12dWRBsegmyGE3feTdy9LBf1eZ-hTZ9Sx&confirm=t&uuid=e2a65c2e-964b-41ca-a590-64b4f7f040f3\n",
            "To: /content/repositories/darkmyter/yolov8-weights/yolov8l-football-players.pt\n",
            "100%|██████████| 87.6M/87.6M [00:03<00:00, 22.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m[SUCCESS] Darkmyter weights downloaded\u001b[0m\n",
            "\u001b[92m[SUCCESS] Darkmyter wrapper created (original ByteTrack)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Cell: Setup Darkmyter (Original ByteTrack + YOLO - Authentic Implementation)\n",
        "\n",
        "print_status(\"Setting up Darkmyter tracking...\", \"INFO\")\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "darkmyter_dir = REPOS_DIR / \"darkmyter\"\n",
        "\n",
        "# Clone original ByteTrack repo (required for authentic Darkmyter)\n",
        "bytetrack_dir = darkmyter_dir / \"ByteTrack\"\n",
        "if not bytetrack_dir.exists():\n",
        "    print_status(\"Cloning original ByteTrack repository...\", \"INFO\")\n",
        "    subprocess.run([\n",
        "        \"git\", \"clone\", \"--depth\", \"1\",\n",
        "        \"https://github.com/ifzhang/ByteTrack.git\",\n",
        "        str(bytetrack_dir)\n",
        "    ], check=True)\n",
        "\n",
        "# Install ByteTrack dependencies\n",
        "!pip install -q cython lap cython_bbox\n",
        "\n",
        "# Download football-specific weights\n",
        "weights_dir = darkmyter_dir / \"yolov8-weights\"\n",
        "weights_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "custom_weights = weights_dir / \"yolov8l-football-players.pt\"\n",
        "gdrive_id = \"12dWRBsegmyGE3feTdy9LBf1eZ-hTZ9Sx\"\n",
        "\n",
        "def download_darkmyter_weights():\n",
        "    print_status(\"Downloading Darkmyter football weights...\", \"INFO\")\n",
        "    try:\n",
        "        import gdown\n",
        "        url = f\"https://drive.google.com/uc?id={gdrive_id}\"\n",
        "        gdown.download(url, str(custom_weights), quiet=False)\n",
        "        print_status(\"Darkmyter weights downloaded\", \"SUCCESS\")\n",
        "    except Exception as e:\n",
        "        print_status(f\"Failed to download weights: {e}\", \"ERROR\")\n",
        "\n",
        "if custom_weights.exists():\n",
        "    try:\n",
        "        with open(custom_weights, \"rb\") as f:\n",
        "            header = f.read(16)\n",
        "        if header.startswith(b\"<\"):\n",
        "            print_status(\"Weights file is HTML, re-downloading...\", \"ERROR\")\n",
        "            custom_weights.unlink(missing_ok=True)\n",
        "            download_darkmyter_weights()\n",
        "        else:\n",
        "            print_status(\"Darkmyter weights already present\", \"SUCCESS\")\n",
        "    except Exception:\n",
        "        custom_weights.unlink(missing_ok=True)\n",
        "        download_darkmyter_weights()\n",
        "else:\n",
        "    download_darkmyter_weights()\n",
        "\n",
        "# Create Darkmyter wrapper\n",
        "darkmyter_wrapper = darkmyter_dir / \"run_darkmyter.py\"\n",
        "darkmyter_wrapper.write_text('''\n",
        "#!/usr/bin/env python\n",
        "\"\"\"\n",
        "Darkmyter: YOLOv8 + original ByteTrack (football, notebook-authentic).\n",
        "\n",
        "This script is a CLI version of the Roboflow \"track players with ByteTrack + YOLOv8\"\n",
        "notebook, adapted to output JSON instead of an annotated video.\n",
        "\n",
        "It:\n",
        "- Uses yolov8l-football-players.pt if present, else falls back to yolov8x.pt\n",
        "- Uses original ifzhang/ByteTrack\n",
        "- Uses football-specific BYTETrackerArgs\n",
        "- Uses the same format_predictions + match_detections_with_tracks pattern\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import sys\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    from ultralytics import YOLO\n",
        "    import torch\n",
        "except ImportError:\n",
        "    print(\"Error: ultralytics or torch not installed\", file=sys.stderr)\n",
        "    sys.exit(1)\n",
        "\n",
        "# Original ByteTrack imports\n",
        "BYTETRACK_PATH = Path(__file__).resolve().parent / \"ByteTrack\"\n",
        "sys.path.insert(0, str(BYTETRACK_PATH))\n",
        "\n",
        "try:\n",
        "    from yolox.tracker.byte_tracker import BYTETracker, STrack  # noqa: F401\n",
        "except ImportError:\n",
        "    print(\"Error: ByteTrack repo not found; expected at ./ByteTrack\", file=sys.stderr)\n",
        "    sys.exit(1)\n",
        "\n",
        "try:\n",
        "    from onemetric.cv.utils.iou import box_iou_batch\n",
        "except ImportError:\n",
        "    print(\"Error: onemetric not installed (needed for IoU). \"\n",
        "          \"Install with: pip install onemetric\", file=sys.stderr)\n",
        "    sys.exit(1)\n",
        "try:\n",
        "    from yolox.tracker.byte_tracker import BYTETracker, STrack\n",
        "except ImportError as e:\n",
        "    import traceback\n",
        "    print(\"Error importing ByteTrack from ./ByteTrack:\", e, file=sys.stderr)\n",
        "    traceback.print_exc()\n",
        "    sys.exit(1)\n",
        "\n",
        "\n",
        "#BYTETrackerArgs: football-specific params (from notebook)\n",
        "@dataclass(frozen=True)\n",
        "class BYTETrackerArgs:\n",
        "    track_thresh: float = 0.25\n",
        "    track_buffer: int = 30\n",
        "    match_thresh: float = 0.8\n",
        "    aspect_ratio_thresh: float = 3.0\n",
        "    min_box_area: float = 1.0\n",
        "    mot20: bool = False\n",
        "\n",
        "\n",
        "# Same mapping as in the notebook\n",
        "IND_TO_CLS = {\n",
        "    0: \"ball\",\n",
        "    1: \"goalkeeper\",\n",
        "    2: \"player\",\n",
        "    3: \"referee\",\n",
        "}\n",
        "\n",
        "\n",
        "def format_predictions(predictions, with_conf: bool = True) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Format YOLO detections to ByteTrack format: (x1, y1, x2, y2, conf).\n",
        "\n",
        "    This mirrors the notebook's function exactly:\n",
        "        bbox = pred.boxes.xyxy.int().tolist()[0]\n",
        "        conf = pred.boxes.conf.item()\n",
        "    \"\"\"\n",
        "    frame_detections = []\n",
        "    for pred in predictions:\n",
        "        # pred is a ultralytics Results object with a single box\n",
        "        bbox = pred.boxes.xyxy.int().tolist()[0]  # [x1, y1, x2, y2]\n",
        "        conf = float(pred.boxes.conf.item())\n",
        "        if with_conf:\n",
        "            detection = bbox + [conf]\n",
        "        else:\n",
        "            detection = bbox\n",
        "        frame_detections.append(detection)\n",
        "\n",
        "    if not frame_detections:\n",
        "        # shape must be (0, 5) or (0, 4) depending on with_conf\n",
        "        return np.zeros((0, 5 if with_conf else 4), dtype=float)\n",
        "\n",
        "    return np.array(frame_detections, dtype=float)\n",
        "\n",
        "\n",
        "def match_detections_with_tracks(detections, tracks):\n",
        "    \"\"\"\n",
        "    Notebook-authentic matching:\n",
        "\n",
        "    - Build detections_bboxes using format_predictions(with_conf=False)\n",
        "    - Build tracks_bboxes from track.tlbr\n",
        "    - Compute IoU matrix with box_iou_batch\n",
        "    - For each track, assign its track_id to the best IoU detection if IoU != 0\n",
        "    \"\"\"\n",
        "    if not detections or not tracks:\n",
        "        return detections\n",
        "\n",
        "    detections_bboxes = format_predictions(detections, with_conf=False)\n",
        "    tracks_bboxes = np.array([track.tlbr for track in tracks], dtype=float)\n",
        "\n",
        "    iou = box_iou_batch(tracks_bboxes, detections_bboxes)  # [num_tracks, num_dets]\n",
        "    track2detection = np.argmax(iou, axis=1)\n",
        "\n",
        "    for tracker_index, detection_index in enumerate(track2detection):\n",
        "        if iou[tracker_index, detection_index] != 0:\n",
        "            detections[detection_index].tracker_id = tracks[tracker_index].track_id\n",
        "\n",
        "    return detections\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=\"Darkmyter: YOLOv8 + original ByteTrack (football)\"\n",
        "    )\n",
        "    parser.add_argument(\"--video\", required=True, help=\"Path to input video\")\n",
        "    parser.add_argument(\"--output\", required=True, help=\"Path to output JSON file\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    video_path = Path(args.video)\n",
        "    output_path = Path(args.output)\n",
        "\n",
        "    if not video_path.exists():\n",
        "        print(f\"Error: video not found: {video_path}\", file=sys.stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "    # --- Load YOLO model (football weights if available) -----------------------\n",
        "    repo_root = Path(__file__).resolve().parent\n",
        "    custom_weights = repo_root / \"yolov8-weights\" / \"yolov8l-football-players.pt\"\n",
        "\n",
        "    if custom_weights.exists():\n",
        "        print(f\"[Darkmyter] Using football-specific weights: {custom_weights}\", file=sys.stderr)\n",
        "        model = YOLO(str(custom_weights))\n",
        "        model_name = \"yolov8l-football\"\n",
        "        football_specific = True\n",
        "    else:\n",
        "        print(\"[Darkmyter] Football weights not found, using yolov8x.pt\", file=sys.stderr)\n",
        "        model = YOLO(\"yolov8x.pt\")\n",
        "        model_name = \"yolov8x\"\n",
        "        football_specific = False\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"[Darkmyter] Device: {device}\", file=sys.stderr)\n",
        "\n",
        "    # --- Open video -----------------------------------------------------------\n",
        "    cap = cv2.VideoCapture(str(video_path))\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: cannot open video: {video_path}\", file=sys.stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    if fps is None or fps <= 0:\n",
        "        fps = 30.0\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) if cap.get(cv2.CAP_PROP_FRAME_COUNT) > 0 else -1\n",
        "\n",
        "    print(f\"[Darkmyter] FPS={fps:.1f}, total_frames={total_frames}\", file=sys.stderr)\n",
        "\n",
        "    # --- Initialize ByteTrack (with proper frame_rate) ------------------------\n",
        "    tracker = BYTETracker(BYTETrackerArgs(), frame_rate=int(round(fps)))\n",
        "\n",
        "    detections_json = []\n",
        "    total_tracks = set()\n",
        "    frame_idx = 0\n",
        "\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Notebook: detections = yolo_model(frame, verbose=0)[0]\n",
        "        results = model(frame, verbose=False)[0]\n",
        "\n",
        "        # \"detections\" in the notebook is iterable; each element is a single-box Results\n",
        "        detections_with_tracker = []\n",
        "        for detection in results:\n",
        "            detection.tracker_id = \"\"  # will be filled in after tracking\n",
        "            detections_with_tracker.append(detection)\n",
        "\n",
        "        if detections_with_tracker:\n",
        "            # get trackers with ByteTrack\n",
        "            bt_input = format_predictions(detections_with_tracker, with_conf=True)\n",
        "\n",
        "            tracks = tracker.update(\n",
        "                output_results=bt_input,\n",
        "                img_info=frame.shape,\n",
        "                img_size=frame.shape,\n",
        "            )\n",
        "\n",
        "            # set tracker_id in yolo detections\n",
        "            detections_with_tracker = match_detections_with_tracks(\n",
        "                detections_with_tracker,\n",
        "                tracks,\n",
        "            )\n",
        "\n",
        "            # Convert to JSON rows\n",
        "            for det in detections_with_tracker:\n",
        "                if det.tracker_id == \"\":\n",
        "                    continue\n",
        "\n",
        "                # Single box per det\n",
        "                bbox = det.boxes.xyxy.tolist()[0]\n",
        "                x1, y1, x2, y2 = map(float, bbox)\n",
        "                conf = float(det.boxes.conf.item())\n",
        "                cls_idx = int(det.boxes.cls.item()) if det.boxes.cls is not None else 0\n",
        "\n",
        "                detections_json.append(\n",
        "                    {\n",
        "                        \"frame_id\": int(frame_idx),\n",
        "                        \"track_id\": int(det.tracker_id),\n",
        "                        \"bbox\": [x1, y1, x2, y2],\n",
        "                        \"score\": conf,\n",
        "                        \"class_id\": cls_idx,\n",
        "                        \"class_name\": IND_TO_CLS.get(cls_idx, \"unknown\"),\n",
        "                    }\n",
        "                )\n",
        "                total_tracks.add(int(det.tracker_id))\n",
        "\n",
        "        if frame_idx % 100 == 0:\n",
        "            if total_frames > 0:\n",
        "                pct = 100.0 * frame_idx / total_frames\n",
        "                print(f\"[Darkmyter] Processed {frame_idx}/{total_frames} frames ({pct:.1f}%)\",\n",
        "                      file=sys.stderr)\n",
        "            else:\n",
        "                print(f\"[Darkmyter] Processed {frame_idx} frames...\", file=sys.stderr)\n",
        "\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    stats = {\n",
        "        \"total_tracks\": len(total_tracks),\n",
        "        \"frames_processed\": frame_idx,\n",
        "    }\n",
        "\n",
        "    full_output = {\n",
        "        \"framework\": \"Darkmyter\",\n",
        "        \"model\": model_name,\n",
        "        \"tracker\": \"ByteTrack (ifzhang/ByteTrack)\",\n",
        "        \"tracker_params\": {\n",
        "            \"track_thresh\": BYTETrackerArgs.track_thresh,\n",
        "            \"track_buffer\": BYTETrackerArgs.track_buffer,\n",
        "            \"match_thresh\": BYTETrackerArgs.match_thresh,\n",
        "            \"aspect_ratio_thresh\": BYTETrackerArgs.aspect_ratio_thresh,\n",
        "            \"min_box_area\": BYTETrackerArgs.min_box_area,\n",
        "        },\n",
        "        \"features\": {\n",
        "            \"football_specific\": football_specific,\n",
        "            \"original_bytetrack\": True,\n",
        "        },\n",
        "        \"detections\": detections_json,\n",
        "        \"statistics\": stats,\n",
        "    }\n",
        "\n",
        "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with output_path.open(\"w\") as f:\n",
        "        json.dump(full_output, f, indent=2)\n",
        "\n",
        "    print(\n",
        "        f\"[Darkmyter] Complete: {len(detections_json)} detections, \"\n",
        "        f\"{stats['total_tracks']} tracks. Output saved to: {output_path}\",\n",
        "        file=sys.stderr,\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "''')\n",
        "\n",
        "darkmyter_wrapper.chmod(0o755)\n",
        "print_status(\"Darkmyter wrapper created (original ByteTrack)\", \"SUCCESS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2ES5pWHUmqE",
        "outputId": "44c778f3-2859-4969-f728-d4c3431519a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patched: /content/repositories/darkmyter/ByteTrack/yolox/tracker/matching.py\n",
            "Patched: /content/repositories/darkmyter/ByteTrack/yolox/tracker/byte_tracker.py\n",
            "Patched: /content/repositories/darkmyter/ByteTrack/yolox/motdt_tracker/matching.py\n",
            "Patched: /content/repositories/darkmyter/ByteTrack/yolox/motdt_tracker/reid_model.py\n",
            "Patched: /content/repositories/darkmyter/ByteTrack/yolox/motdt_tracker/motdt_tracker.py\n",
            "Patched: /content/repositories/darkmyter/ByteTrack/yolox/deepsort_tracker/detection.py\n",
            "Patched: /content/repositories/darkmyter/ByteTrack/yolox/deepsort_tracker/deepsort.py\n",
            "Patched: /content/repositories/darkmyter/ByteTrack/tutorials/cstrack/tracker.py\n",
            "Patched: /content/repositories/darkmyter/ByteTrack/tutorials/cstrack/byte_tracker.py\n",
            "Patched: /content/repositories/darkmyter/ByteTrack/tutorials/centertrack/byte_tracker.py\n",
            "Patched: /content/repositories/darkmyter/ByteTrack/tutorials/centertrack/mot_online/matching.py\n",
            "Patched: /content/repositories/darkmyter/ByteTrack/tutorials/ctracker/byte_tracker.py\n",
            "Patched: /content/repositories/darkmyter/ByteTrack/tutorials/ctracker/mot_online/matching.py\n",
            "Patched: /content/repositories/darkmyter/ByteTrack/tutorials/qdtrack/tracker_reid_motion.py\n",
            "Patched: /content/repositories/darkmyter/ByteTrack/tutorials/qdtrack/byte_tracker.py\n",
            "Patched: /content/repositories/darkmyter/ByteTrack/tutorials/qdtrack/mot_online/matching.py\n",
            "Patched: /content/repositories/darkmyter/ByteTrack/tutorials/fairmot/tracker.py\n",
            "Patched: /content/repositories/darkmyter/ByteTrack/tutorials/fairmot/byte_tracker.py\n",
            "Patched: /content/repositories/darkmyter/ByteTrack/tutorials/transtrack/mot_online/matching.py\n",
            "Patched: /content/repositories/darkmyter/ByteTrack/tutorials/transtrack/mot_online/byte_tracker.py\n",
            "Patched: /content/repositories/darkmyter/ByteTrack/tutorials/motr/byte_tracker.py\n",
            "Patched: /content/repositories/darkmyter/ByteTrack/tutorials/motr/mot_online/matching.py\n",
            "Patched: /content/repositories/darkmyter/ByteTrack/tutorials/jde/tracker.py\n",
            "Patched: /content/repositories/darkmyter/ByteTrack/tutorials/jde/byte_tracker.py\n",
            "Patched: /content/repositories/darkmyter/ByteTrack/tutorials/trades/tracker.py\n",
            "Patched: /content/repositories/darkmyter/ByteTrack/tutorials/trades/byte_tracker.py\n",
            "Patched: /content/repositories/darkmyter/ByteTrack/tutorials/trades/mot_online/matching.py\n",
            "ByteTrack patched for NumPy compatibility\n"
          ]
        }
      ],
      "source": [
        "# Patch ByteTrack for NumPy 1.24+ compatibility\n",
        "import os\n",
        "\n",
        "bytetrack_path = REPOS_DIR / \"darkmyter\" / \"ByteTrack\"\n",
        "\n",
        "# Files that typically have np.float issues\n",
        "for root, dirs, files in os.walk(bytetrack_path):\n",
        "    for file in files:\n",
        "        if file.endswith('.py'):\n",
        "            filepath = os.path.join(root, file)\n",
        "            try:\n",
        "                with open(filepath, 'r') as f:\n",
        "                    content = f.read()\n",
        "\n",
        "                # Replace deprecated numpy aliases\n",
        "                new_content = content\n",
        "                new_content = new_content.replace('np.float,', 'float,')\n",
        "                new_content = new_content.replace('np.float)', 'float)')\n",
        "                new_content = new_content.replace('np.float]', 'float]')\n",
        "                new_content = new_content.replace('np.int,', 'int,')\n",
        "                new_content = new_content.replace('np.int)', 'int)')\n",
        "                new_content = new_content.replace('np.int]', 'int]')\n",
        "\n",
        "                if new_content != content:\n",
        "                    with open(filepath, 'w') as f:\n",
        "                        f.write(new_content)\n",
        "                    print(f\"Patched: {filepath}\")\n",
        "            except Exception as e:\n",
        "                pass\n",
        "\n",
        "print(\"ByteTrack patched for NumPy compatibility\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2I5iE6qiWWTy",
        "outputId": "4da3cbbe-e9f5-4fc9-db61-35b3ec25b50c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m[SUCCESS] Created wrapper for Botsort and Bytetrack\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import textwrap\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "import ultralytics\n",
        "\n",
        "REPOS_DIR = Path(\"/content/repositories\")\n",
        "ultra_dir = REPOS_DIR / \"ultra_trackers\"\n",
        "ultra_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "# 1) Choose custom configs for bytetrack + botsort\n",
        "runner_script = ultra_dir / \"run_ultra_yolo_tracker.py\"\n",
        "runner_script.write_text(textwrap.dedent(\"\"\"\\\n",
        "    #!/usr/bin/env python\n",
        "    \\\"\\\"\\\"Run Ultralytics YOLO (v5 / v8 / v11 weights) with a chosen tracker and dump JSON tracks.\n",
        "\n",
        "    Usage:\n",
        "      python run_ultra_yolo_tracker.py \\\\\n",
        "          --video input.mp4 \\\\\n",
        "          --output output.json \\\\\n",
        "          --weights yolo11m.pt \\\\\n",
        "          --tracker botsort\n",
        "    \\\"\\\"\\\"\n",
        "\n",
        "    import argparse\n",
        "    import json\n",
        "    from pathlib import Path\n",
        "    from ultralytics import YOLO\n",
        "    import yaml\n",
        "\n",
        "    def main():\n",
        "        parser = argparse.ArgumentParser(description=\"YOLO + tracker to JSON\")\n",
        "        parser.add_argument(\"--video\", required=True, help=\"Path to input video\")\n",
        "        parser.add_argument(\"--output\", required=True, help=\"Path to output JSON\")\n",
        "        parser.add_argument(\n",
        "            \"--weights\",\n",
        "            default=\"yolo11m.pt\",\n",
        "            help=\"YOLO weights (e.g., yolov5s.pt, yolov8n.pt, yolo11m.pt, ...)\",\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--tracker\",\n",
        "            default=\"botsort\",\n",
        "            choices=[\"botsort\", \"bytetrack\", \"deepsort\"],\n",
        "            help=\"Which tracker to use\",\n",
        "        )\n",
        "        parser.add_argument(\"--conf\", type=float, default=0.3,\n",
        "                    help=\"Confidence threshold (detector)\")\n",
        "        parser.add_argument(\"--iou\", type=float, default=0.4,\n",
        "                    help=\"IOU threshold for NMS (lower = keep more boxes)\")\n",
        "        parser.add_argument(\"--imgsz\", type=int, default=1280,\n",
        "                    help=\"Image size for inference\")\n",
        "        parser.add_argument(\"--max-det\", type=int, default=300,\n",
        "                    help=\"Maximum detections per image\")\n",
        "\n",
        "        args = parser.parse_args()\n",
        "\n",
        "        video_path = Path(args.video)\n",
        "        out_path = Path(args.output)\n",
        "\n",
        "        if not video_path.exists():\n",
        "            raise SystemExit(f\"Video not found: {video_path}\")\n",
        "\n",
        "        # Load YOLO model\n",
        "        model = YOLO(args.weights)\n",
        "\n",
        "        # Get the script's directory for saving custom configs\n",
        "        ultra_root = Path(__file__).resolve().parent\n",
        "\n",
        "        # Try to load Ultralytics default configs first\n",
        "        import ultralytics\n",
        "        ultra_path = Path(ultralytics.__file__).parent\n",
        "        tracker_base_path = ultra_path / \"cfg\" / \"trackers\"\n",
        "\n",
        "        # Select the default config path\n",
        "        if args.tracker == \"bytetrack\":\n",
        "            default_cfg_path = tracker_base_path / \"bytetrack.yaml\"\n",
        "        elif args.tracker == \"botsort\":\n",
        "            default_cfg_path = tracker_base_path / \"botsort.yaml\"\n",
        "        else:  # deepsort\n",
        "            default_cfg_path = tracker_base_path / \"deepsort.yaml\"\n",
        "\n",
        "        # Path for our custom config\n",
        "        custom_cfg_path = ultra_root / f\"{args.tracker}_football.yaml\"\n",
        "\n",
        "        # Load and modify the config\n",
        "        if default_cfg_path.exists():\n",
        "            # Load the default config\n",
        "            with open(default_cfg_path, 'r') as f:\n",
        "                tracker_cfg = yaml.safe_load(f)\n",
        "\n",
        "            # Modify with football-optimized values from tracklab\n",
        "\n",
        "            if args.tracker == \"botsort\":\n",
        "                tracker_cfg.update({\n",
        "                    \"track_high_thresh\": 0.33824964456239337,\n",
        "                    \"new_track_thresh\": 0.21144301345190655,\n",
        "                    \"track_buffer\": 60,\n",
        "                    \"match_thresh\": 0.22734550911325851,\n",
        "                    \"proximity_thresh\": 0.5945380911899254,\n",
        "                    \"appearance_thresh\": 0.4818211117541298,\n",
        "                    \"cmc_method\": \"sparseOptFlow\",\n",
        "                    \"frame_rate\": 30,\n",
        "                    \"lambda_\": 0.9896143462366406,\n",
        "                    \"conf_thres\": 0.3501265956918775,\n",
        "                    \"with_reid\": True\n",
        "                })\n",
        "\n",
        "            # Save the modified config to a file\n",
        "            with open(custom_cfg_path, 'w') as f:\n",
        "                yaml.dump(tracker_cfg, f)\n",
        "\n",
        "            # Use the custom config FILE PATH (not the dictionary!)\n",
        "            tracker_cfg_path = str(custom_cfg_path)\n",
        "        else:\n",
        "            # Fallback: just use the default tracker name\n",
        "            print(f\"Warning: Could not find default config at {default_cfg_path}\")\n",
        "            print(f\"Using default tracker: {args.tracker}.yaml\")\n",
        "            tracker_cfg_path = f\"{args.tracker}.yaml\"\n",
        "\n",
        "        # Run tracking with the config FILE PATH\n",
        "        results = model.track(\n",
        "            source=str(video_path),\n",
        "            tracker=tracker_cfg_path,  # Pass the FILE PATH, not dictionary!\n",
        "            conf=args.conf,\n",
        "            iou=args.iou,\n",
        "            imgsz=args.imgsz,\n",
        "            max_det=args.max_det,\n",
        "            stream=True,\n",
        "            device=0,\n",
        "            save=False,\n",
        "            verbose=False,\n",
        "            persist=True,\n",
        "            vid_stride=1,\n",
        "        )\n",
        "\n",
        "        print(f\"Tracking with {args.tracker} on device: {model.device}\")\n",
        "\n",
        "        all_detections = []\n",
        "        frame_idx = 0\n",
        "\n",
        "        for r in results:\n",
        "            boxes = r.boxes\n",
        "            if boxes is None:\n",
        "                frame_idx += 1\n",
        "                continue\n",
        "\n",
        "            ids = boxes.id\n",
        "            if ids is None:\n",
        "                frame_idx += 1\n",
        "                continue\n",
        "\n",
        "            xyxy = boxes.xyxy\n",
        "            confs = boxes.conf\n",
        "            clses = boxes.cls\n",
        "\n",
        "            ids = ids.cpu().tolist()\n",
        "            xyxy = xyxy.cpu().tolist()\n",
        "            confs = confs.cpu().tolist()\n",
        "            clses = clses.cpu().tolist()\n",
        "\n",
        "            for tid, (x1, y1, x2, y2), score, c in zip(ids, xyxy, confs, clses):\n",
        "                all_detections.append({\n",
        "                    \"frame_id\": frame_idx,\n",
        "                    \"track_id\": int(tid),\n",
        "                    \"bbox\": [float(x1), float(y1), float(x2), float(y2)],\n",
        "                    \"score\": float(score),\n",
        "                    \"class_id\": int(c),\n",
        "                })\n",
        "\n",
        "            frame_idx += 1\n",
        "\n",
        "        out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        with out_path.open(\"w\") as f:\n",
        "            json.dump(all_detections, f)\n",
        "\n",
        "        print(f\"Wrote {len(all_detections)} tracked detections to {out_path}\")\n",
        "\n",
        "\n",
        "    if __name__ == \"__main__\":\n",
        "        main()\n",
        "    \"\"\"))\n",
        "\n",
        "runner_script.chmod(0o755)\n",
        "print_status(\"Created wrapper for Botsort and Bytetrack\", \"SUCCESS\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jIMyv7HMfsbb",
        "outputId": "f37d66fa-e98c-4153-9cf1-728cc536ca08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Setting up Eagle with Python 3.13...\u001b[0m\n",
            "\u001b[94m[INFO] Installing Python 3.13...\u001b[0m\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "software-properties-common is already the newest version (0.99.22.9).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 54 not upgraded.\n",
            "Repository: 'deb https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu/ jammy main'\n",
            "Description:\n",
            "This PPA contains more recent Python versions packaged for Ubuntu.\n",
            "\n",
            "Disclaimer: there's no guarantee of timely updates in case of security problems or other issues. If you want to use them in a security-or-otherwise-critical environment (say, on a production server), you do so at your own risk.\n",
            "\n",
            "Update Note\n",
            "===========\n",
            "Please use this repository instead of ppa:fkrull/deadsnakes.\n",
            "\n",
            "Reporting Issues\n",
            "================\n",
            "\n",
            "Issues can be reported in the master issue tracker at:\n",
            "https://github.com/deadsnakes/issues/issues\n",
            "\n",
            "Supported Ubuntu and Python Versions\n",
            "====================================\n",
            "\n",
            "- Ubuntu 22.04 (jammy) Python3.7 - Python3.9, Python3.11 - Python3.13\n",
            "- Ubuntu 24.04 (noble) Python3.7 - Python3.11, Python3.13\n",
            "- Note: Python 3.10 (jammy), Python3.12 (noble) are not provided by deadsnakes as upstream ubuntu provides those packages.\n",
            "\n",
            "Why some packages aren't built:\n",
            "- Note: for jammy and noble, older python versions requre libssl<3 so they are not currently built\n",
            "- If you need these, reach out to asottile to set up a private ppa\n",
            "\n",
            "The packages may also work on other versions of Ubuntu or Debian, but that is not tested or supported.\n",
            "\n",
            "Packages\n",
            "========\n",
            "\n",
            "The packages provided here are loosely based on the debian upstream packages with some modifications to make them more usable as non-default pythons and on ubuntu.  As such, the packages follow debian's patterns and often do not include a full python distribution with just `apt install python#.#`.  Here is a list of packages that may be useful along with the default install:\n",
            "\n",
            "- `python#.#-dev`: includes development headers for building C extensions\n",
            "- `python#.#-venv`: provides the standard library `venv` module\n",
            "- `python#.#-distutils`: provides the standard library `distutils` module\n",
            "- `python#.#-lib2to3`: provides the `2to3-#.#` utility as well as the standard library `lib2to3` module\n",
            "- `python#.#-gdbm`: provides the standard library `dbm.gnu` module\n",
            "- `python#.#-tk`: provides the standard library `tkinter` module\n",
            "\n",
            "Third-Party Python Modules\n",
            "==========================\n",
            "\n",
            "Python modules in the official Ubuntu repositories are packaged to work with the Python interpreters from the official repositories. Accordingly, they generally won't work with the Python interpreters from this PPA. As an exception, pure-Python modules for Python 3 will work, but any compiled extension modules won't.\n",
            "\n",
            "To install 3rd-party Python modules, you should use the common Python packaging tools.  For an introduction into the Python packaging ecosystem and its tools, refer to the Python Packaging User Guide:\n",
            "https://packaging.python.org/installing/\n",
            "\n",
            "Sources\n",
            "=======\n",
            "The package sources are available at:\n",
            "https://github.com/deadsnakes/\n",
            "\n",
            "Nightly Builds\n",
            "==============\n",
            "\n",
            "For nightly builds, see ppa:deadsnakes/nightly https://launchpad.net/~deadsnakes/+archive/ubuntu/nightly\n",
            "More info: https://launchpad.net/~deadsnakes/+archive/ubuntu/ppa\n",
            "Adding repository.\n",
            "Found existing deb entry in /etc/apt/sources.list.d/deadsnakes-ubuntu-ppa-jammy.list\n",
            "Adding deb entry to /etc/apt/sources.list.d/deadsnakes-ubuntu-ppa-jammy.list\n",
            "Found existing deb-src entry in /etc/apt/sources.list.d/deadsnakes-ubuntu-ppa-jammy.list\n",
            "Adding disabled deb-src entry to /etc/apt/sources.list.d/deadsnakes-ubuntu-ppa-jammy.list\n",
            "Adding key to /etc/apt/trusted.gpg.d/deadsnakes-ubuntu-ppa.gpg with fingerprint F23C5A6CF475977595C89F51BA6932366A755776\n",
            "Hit:1 https://cli.github.com/packages stable InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package python3.13-distutils\n",
            "E: Couldn't find any package by glob 'python3.13-distutils'\n",
            "E: Couldn't find any package by regex 'python3.13-distutils'\n",
            "/bin/bash: line 1: python3.13: command not found\n",
            "curl: (23) Failure writing output to destination\n",
            "\u001b[94m[INFO] Installing uv...\u001b[0m\n",
            "downloading uv 0.9.12 x86_64-unknown-linux-gnu\n",
            "no checksums to verify\n",
            "installing to /usr/local/bin\n",
            "  uv\n",
            "  uvx\n",
            "everything's installed!\n",
            "\u001b[94m[INFO] Creating Eagle environment with Python 3.13...\u001b[0m\n",
            "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mThe `--system` flag has no effect, a system Python interpreter is always used in `uv venv`\u001b[0m\n",
            "Using CPython \u001b[36m3.13.9\u001b[39m\u001b[36m\u001b[39m\n",
            "Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
            "\u001b[33m?\u001b[0m \u001b[1mA virtual environment already exists at `.venv`. Do you want to replace it?\u001b[0m \u001b[38;5;8m[y/n]\u001b[0m \u001b[38;5;8m›\u001b[0m \u001b[36myes\u001b[0m\n",
            "\n",
            "\u001b[0J\u001b[32m✔\u001b[0m \u001b[1mA virtual environment already exists at `.venv`. Do you want to replace it?\u001b[0m \u001b[38;5;8m·\u001b[0m \u001b[36myes\u001b[0m\n",
            "\u001b[?25hActivate with: \u001b[32msource .venv/bin/activate\u001b[39m\n",
            "\u001b[2mResolved \u001b[1m119 packages\u001b[0m \u001b[2min 0.96ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m113 packages\u001b[0m \u001b[2min 307ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1malbucore\u001b[0m\u001b[2m==0.0.24\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1malbumentations\u001b[0m\u001b[2m==2.0.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1masttokens\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbayesian-optimization\u001b[0m\u001b[2m==3.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbeautifulsoup4\u001b[0m\u001b[2m==4.13.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mboxmot\u001b[0m\u001b[2m==15.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.8.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcolorama\u001b[0m\u001b[2m==0.4.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcomm\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcontourpy\u001b[0m\u001b[2m==1.3.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcycler\u001b[0m\u001b[2m==0.12.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdebugpy\u001b[0m\u001b[2m==1.8.16\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdecorator\u001b[0m\u001b[2m==5.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mexecuting\u001b[0m\u001b[2m==2.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.19.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfilterpy\u001b[0m\u001b[2m==1.4.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfonttools\u001b[0m\u001b[2m==4.59.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mftfy\u001b[0m\u001b[2m==6.3.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgdown\u001b[0m\u001b[2m==5.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgitdb\u001b[0m\u001b[2m==4.0.12\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgitpython\u001b[0m\u001b[2m==3.1.45\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.10\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mipykernel\u001b[0m\u001b[2m==6.30.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mipython\u001b[0m\u001b[2m==9.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mipython-pygments-lexers\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjedi\u001b[0m\u001b[2m==0.19.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjinja2\u001b[0m\u001b[2m==3.1.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjoblib\u001b[0m\u001b[2m==1.5.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjupyter-client\u001b[0m\u001b[2m==8.6.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjupyter-core\u001b[0m\u001b[2m==5.8.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mkiwisolver\u001b[0m\u001b[2m==1.4.9\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlapx\u001b[0m\u001b[2m==0.5.11.post1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mloguru\u001b[0m\u001b[2m==0.7.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmatplotlib\u001b[0m\u001b[2m==3.10.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmatplotlib-inline\u001b[0m\u001b[2m==0.1.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmplcursors\u001b[0m\u001b[2m==0.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmplsoccer\u001b[0m\u001b[2m==1.5.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmpmath\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnest-asyncio\u001b[0m\u001b[2m==1.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnetworkx\u001b[0m\u001b[2m==3.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.3.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.8.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.10.2.21\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.3.83\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufile-cu12\u001b[0m\u001b[2m==1.13.1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.9.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.3.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.27.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopencv-python\u001b[0m\u001b[2m==4.11.0.86\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopencv-python-headless\u001b[0m\u001b[2m==4.11.0.86\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==25.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.3.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mparso\u001b[0m\u001b[2m==0.8.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpexpect\u001b[0m\u001b[2m==4.9.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==11.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mplatformdirs\u001b[0m\u001b[2m==4.3.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mprompt-toolkit\u001b[0m\u001b[2m==3.0.51\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpsutil\u001b[0m\u001b[2m==7.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mptyprocess\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpure-eval\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpy-cpuinfo\u001b[0m\u001b[2m==9.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.11.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.33.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyparsing\u001b[0m\u001b[2m==3.2.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyqt5\u001b[0m\u001b[2m==5.15.11\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyqt5-qt5\u001b[0m\u001b[2m==5.15.17\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyqt5-sip\u001b[0m\u001b[2m==12.17.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpysocks\u001b[0m\u001b[2m==1.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpython-dateutil\u001b[0m\u001b[2m==2.9.0.post0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpytz\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyyaml\u001b[0m\u001b[2m==6.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==27.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mregex\u001b[0m\u001b[2m==2024.11.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mscikit-learn\u001b[0m\u001b[2m==1.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mscipy\u001b[0m\u001b[2m==1.16.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mseaborn\u001b[0m\u001b[2m==0.13.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==80.9.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msimsimd\u001b[0m\u001b[2m==6.5.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msix\u001b[0m\u001b[2m==1.17.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msmmap\u001b[0m\u001b[2m==5.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msoupsieve\u001b[0m\u001b[2m==2.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mstack-data\u001b[0m\u001b[2m==0.6.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mstringzilla\u001b[0m\u001b[2m==3.12.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mthreadpoolctl\u001b[0m\u001b[2m==3.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.8.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.23.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtornado\u001b[0m\u001b[2m==6.5.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtraitlets\u001b[0m\u001b[2m==5.14.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.14.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyping-inspection\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1multralytics\u001b[0m\u001b[2m==8.3.184\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1multralytics-thop\u001b[0m\u001b[2m==2.0.16\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.5.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwcwidth\u001b[0m\u001b[2m==0.2.13\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1myacs\u001b[0m\u001b[2m==0.1.8\u001b[0m\n",
            "\u001b[94m[INFO] Downloading Eagle model weights...\u001b[0m\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1rTArr_3eO35Ynea2HXqPYOxDdkDYLfMI\n",
            "From (redirected): https://drive.google.com/uc?id=1rTArr_3eO35Ynea2HXqPYOxDdkDYLfMI&confirm=t&uuid=b39aa419-5dd7-42cd-a043-157ad218a2ba\n",
            "To: /content/repositories/eagle/eagle/models/weights.zip\n",
            "100% 821M/821M [00:17<00:00, 47.3MB/s]\n",
            "Archive:  weights.zip\n",
            "replace weights/detector_large_hd.pt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "\u001b[92m[SUCCESS] Eagle weights downloaded\u001b[0m\n",
            "\u001b[92m[SUCCESS] Eagle FULL capability wrapper created\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Cell: Setup Eagle with Python 3.13\n",
        "\n",
        "print_status(\"Setting up Eagle with Python 3.13...\", \"INFO\")\n",
        "\n",
        "eagle_dir = REPOS_DIR / \"eagle\"\n",
        "\n",
        "# Install Python 3.13 (Eagle's required version)\n",
        "print_status(\"Installing Python 3.13...\", \"INFO\")\n",
        "!apt-get update -qq\n",
        "!apt-get install -y software-properties-common\n",
        "!add-apt-repository -y ppa:deadsnakes/ppa\n",
        "!apt-get update -qq\n",
        "!apt-get install -y python3.13 python3.13-venv python3.13-dev python3.13-distutils\n",
        "\n",
        "# Install pip for Python 3.13\n",
        "!curl -sS https://bootstrap.pypa.io/get-pip.py | python3.13\n",
        "\n",
        "# Install uv if not already installed\n",
        "print_status(\"Installing uv...\", \"INFO\")\n",
        "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "\n",
        "# Add uv to PATH\n",
        "import os\n",
        "os.environ['PATH'] = f\"/root/.local/bin:{os.environ['PATH']}\"\n",
        "\n",
        "# Create Eagle environment with Python 3.13\n",
        "os.chdir(eagle_dir)\n",
        "print_status(\"Creating Eagle environment with Python 3.13...\", \"INFO\")\n",
        "!uv venv --python python3.13\n",
        "!uv sync\n",
        "\n",
        "# Download model weights\n",
        "print_status(\"Downloading Eagle model weights...\", \"INFO\")\n",
        "models_dir = eagle_dir / \"eagle\" / \"models\"\n",
        "if models_dir.exists():\n",
        "    os.chdir(models_dir)\n",
        "    !bash get_weights.sh\n",
        "    os.chdir(eagle_dir)\n",
        "    print_status(\"Eagle weights downloaded\", \"SUCCESS\")\n",
        "else:\n",
        "    print_status(\"Eagle models directory not found\", \"ERROR\")\n",
        "\n",
        "# Create Eagle wrapper that uses Python 3.13\n",
        "\n",
        "eagle_wrapper = eagle_dir / \"run_eagle.py\"\n",
        "eagle_wrapper.write_text('''\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Clean Eagle wrapper that produces a single output file\n",
        "Consolidates Eagle's multiple outputs into the format expected by the evaluation pipeline\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "\n",
        "def consolidate_eagle_output(eagle_output_dir, output_format=\"tracking\"):\n",
        "    \"\"\"\n",
        "    Consolidate Eagle's output into a single JSON file\n",
        "\n",
        "    Args:\n",
        "        eagle_output_dir: Path to Eagle's output directory\n",
        "        output_format: \"tracking\" for standard format, \"raw\" for Eagle's native format\n",
        "\n",
        "    Returns:\n",
        "        Consolidated data dictionary\n",
        "    \"\"\"\n",
        "    # Look for raw_coordinates folder\n",
        "    coords_dir = eagle_output_dir / \"raw_coordinates\"\n",
        "    if not coords_dir.exists():\n",
        "        coords_dir = eagle_output_dir\n",
        "\n",
        "    # Find the main coordinates file\n",
        "    raw_coords_file = coords_dir / \"raw_coordinates.json\"\n",
        "    raw_data_file = coords_dir / \"raw_data.json\"\n",
        "    processed_file = coords_dir / \"processed_data.json\"\n",
        "\n",
        "    # Try different file options in order of preference\n",
        "    data = None\n",
        "    source_file = None\n",
        "\n",
        "    for file_path in [raw_coords_file, processed_file, raw_data_file]:\n",
        "        if file_path.exists():\n",
        "            with open(file_path, 'r') as f:\n",
        "                data = json.load(f)\n",
        "            source_file = file_path\n",
        "            print(f\"[Eagle] Using {file_path.name} as source\", file=sys.stderr)\n",
        "            break\n",
        "\n",
        "    if data is None:\n",
        "        # Try to find any JSON file\n",
        "        json_files = list(coords_dir.glob(\"*.json\"))\n",
        "        if json_files:\n",
        "            with open(json_files[0], 'r') as f:\n",
        "                data = json.load(f)\n",
        "            source_file = json_files[0]\n",
        "            print(f\"[Eagle] Using {json_files[0].name} as source\", file=sys.stderr)\n",
        "\n",
        "    if data is None:\n",
        "        print(f\"[Eagle] No output files found in {coords_dir}\", file=sys.stderr)\n",
        "        # Signal error to caller\n",
        "        raise FileNotFoundError(f\"No Eagle JSON outputs found in {coords_dir}\")\n",
        "\n",
        "    # Convert to standard tracking format if requested\n",
        "    if output_format == \"tracking\":\n",
        "        return convert_to_tracking_format(data, source_file)\n",
        "    else:\n",
        "        return data\n",
        "\n",
        "\n",
        "def convert_to_tracking_format(eagle_data, source_file):\n",
        "    \"\"\"\n",
        "    Convert Eagle's format to standard tracking format\n",
        "    [{\"frame_id\": N, \"track_id\": M, \"bbox\": [x1,y1,x2,y2], \"score\": S, \"class_id\": C}, ...]\n",
        "    \"\"\"\n",
        "    tracking_data = []\n",
        "\n",
        "    # Handle different Eagle output formats\n",
        "    if isinstance(eagle_data, dict) and all(key.isdigit() for key in eagle_data.keys()):\n",
        "        # Format: {\"0\": {...}, \"1\": {...}, ...} - raw_coordinates.json format\n",
        "        for frame_str, frame_data in eagle_data.items():\n",
        "            frame_id = int(frame_str)\n",
        "\n",
        "            if 'Coordinates' in frame_data:\n",
        "                coords = frame_data['Coordinates']\n",
        "\n",
        "                # Process players\n",
        "                for player_id, player_data in coords.get('Player', {}).items():\n",
        "                    if 'BBox' in player_data:\n",
        "                        tracking_data.append({\n",
        "                            'frame_id': frame_id,\n",
        "                            'track_id': int(player_id),\n",
        "                            'bbox': player_data['BBox'],\n",
        "                            'score': player_data.get('Confidence', 1.0),\n",
        "                            'class_id': 0  # Player\n",
        "                        })\n",
        "\n",
        "                # Process goalkeepers\n",
        "                for gk_id, gk_data in coords.get('Goalkeeper', {}).items():\n",
        "                    if 'BBox' in gk_data:\n",
        "                        tracking_data.append({\n",
        "                            'frame_id': frame_id,\n",
        "                            'track_id': int(gk_id),\n",
        "                            'bbox': gk_data['BBox'],\n",
        "                            'score': gk_data.get('Confidence', 1.0),\n",
        "                            'class_id': 1  # Goalkeeper\n",
        "                        })\n",
        "\n",
        "    elif isinstance(eagle_data, list):\n",
        "        # Format: [{...}, {...}, ...] - raw_data.json format\n",
        "        for frame_id, frame_data in enumerate(eagle_data):\n",
        "            # Process player entries\n",
        "            for key in frame_data:\n",
        "                if key.startswith('Player_') and '_video' in key:\n",
        "                    player_id = int(key.replace('Player_', '').replace('_video', ''))\n",
        "                    coords = frame_data.get(key)\n",
        "\n",
        "                    if coords is not None:\n",
        "                        # Convert center point to bounding box\n",
        "                        cx, cy = coords\n",
        "                        # Estimate bbox (can be adjusted based on typical player size)\n",
        "                        half_width, half_height = 10, 20\n",
        "\n",
        "                        tracking_data.append({\n",
        "                            'frame_id': frame_id,\n",
        "                            'track_id': player_id,\n",
        "                            'bbox': [cx - half_width, cy - half_height,\n",
        "                                   cx + half_width, cy + half_height],\n",
        "                            'score': 1.0,\n",
        "                            'class_id': 0  # Player\n",
        "                        })\n",
        "\n",
        "                elif key.startswith('Goalkeeper_') and '_video' in key:\n",
        "                    gk_id = int(key.replace('Goalkeeper_', '').replace('_video', ''))\n",
        "                    coords = frame_data.get(key)\n",
        "\n",
        "                    if coords is not None:\n",
        "                        cx, cy = coords\n",
        "                        half_width, half_height = 10, 20\n",
        "\n",
        "                        tracking_data.append({\n",
        "                            'frame_id': frame_id,\n",
        "                            'track_id': gk_id,\n",
        "                            'bbox': [cx - half_width, cy - half_height,\n",
        "                                   cx + half_width, cy + half_height],\n",
        "                            'score': 1.0,\n",
        "                            'class_id': 1  # Goalkeeper\n",
        "                        })\n",
        "\n",
        "    return tracking_data\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description='Eagle wrapper for unified output')\n",
        "    parser.add_argument('--video', required=True, help='Path to input video')\n",
        "    parser.add_argument('--output', required=True, help='Path to output JSON file')\n",
        "    parser.add_argument('--fps', default=20, type=int, help='FPS to process (default: 20)')\n",
        "    parser.add_argument('--format', choices=['tracking', 'raw'], default='raw',\n",
        "                       help='Output format: tracking (standard) or raw (Eagle native)')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    video_path = Path(args.video)\n",
        "    output_path = Path(args.output)\n",
        "\n",
        "    if not video_path.exists():\n",
        "        print(f\"Error: Video not found: {video_path}\", file=sys.stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Ensure output directory exists\n",
        "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Set up environment\n",
        "    env = os.environ.copy()\n",
        "    env[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "    # Run Eagle\n",
        "    cmd = [\n",
        "        \"uv\", \"run\", \"--python\", \"python3.13\",\n",
        "        \"main.py\",\n",
        "        \"--video_path\", str(video_path),\n",
        "        \"--fps\", str(args.fps),\n",
        "    ]\n",
        "\n",
        "    print(f\"[Eagle] Processing {video_path.name} at {args.fps} FPS...\", file=sys.stderr)\n",
        "    start = time.time()\n",
        "\n",
        "    eagle_dir = Path(__file__).parent\n",
        "    result = subprocess.run(\n",
        "        cmd,\n",
        "        capture_output=True,\n",
        "        text=True,\n",
        "        cwd=eagle_dir,\n",
        "        env=env,\n",
        "    )\n",
        "\n",
        "    elapsed = time.time() - start\n",
        "    print(f\"[Eagle] Processing took {elapsed:.1f}s\", file=sys.stderr)\n",
        "\n",
        "    if result.returncode != 0:\n",
        "        print(f\"[Eagle] Warning: Process returned {result.returncode}\", file=sys.stderr)\n",
        "        if result.stderr:\n",
        "            print(f\"[Eagle] Stderr: {result.stderr[:500]}\", file=sys.stderr)\n",
        "\n",
        "    # Find Eagle's output directory\n",
        "    video_stem = video_path.stem\n",
        "    eagle_output_base = eagle_dir / \"output\"\n",
        "    eagle_output_dir = eagle_output_base / video_stem\n",
        "\n",
        "    if not eagle_output_dir.exists():\n",
        "        # Try to find directory with video name in it\n",
        "        for d in eagle_output_base.iterdir():\n",
        "            if d.is_dir() and video_stem in d.name:\n",
        "                eagle_output_dir = d\n",
        "                break\n",
        "\n",
        "    if not eagle_output_dir.exists():\n",
        "        print(f\"[Eagle] Error: Could not find output directory for {video_stem}\", file=sys.stderr)\n",
        "        # Write empty output\n",
        "        with open(output_path, 'w') as f:\n",
        "            json.dump([], f)\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Convert Eagle output into single file\n",
        "    try:\n",
        "        print(f\"[Eagle] Consolidating output from {eagle_output_dir}\", file=sys.stderr)\n",
        "        consolidated_data = consolidate_eagle_output(eagle_output_dir, args.format)\n",
        "    except Exception as e:\n",
        "        print(f\"[Eagle] Error while consolidating Eagle output: {e}\", file=sys.stderr)\n",
        "        with open(output_path, \"w\") as f:\n",
        "            json.dump([], f)\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Write converted output\n",
        "    with open(output_path, 'w') as f:\n",
        "        json.dump(consolidated_data, f, indent=2)\n",
        "\n",
        "    # Report statistics\n",
        "    if isinstance(consolidated_data, list):\n",
        "        if consolidated_data and 'frame_id' in consolidated_data[0]:\n",
        "            # Tracking format\n",
        "            frame_ids = set(d['frame_id'] for d in consolidated_data)\n",
        "            track_ids = set(d['track_id'] for d in consolidated_data)\n",
        "            print(f\"[Eagle] Output: {len(consolidated_data)} detections\", file=sys.stderr)\n",
        "            print(f\"[Eagle] Frames: {len(frame_ids)} ({min(frame_ids)}-{max(frame_ids)})\", file=sys.stderr)\n",
        "            print(f\"[Eagle] Tracks: {len(track_ids)} unique IDs\", file=sys.stderr)\n",
        "        else:\n",
        "            print(f\"[Eagle] Output: {len(consolidated_data)} frames\", file=sys.stderr)\n",
        "    elif isinstance(consolidated_data, dict):\n",
        "        print(f\"[Eagle] Output: {len(consolidated_data)} frames (raw format)\", file=sys.stderr)\n",
        "\n",
        "    print(f\"[Eagle] Saved to: {output_path}\", file=sys.stderr)\n",
        "    sys.exit(0)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "''')\n",
        "\n",
        "eagle_wrapper.chmod(0o755)\n",
        "print_status(\"Eagle FULL capability wrapper created\", \"SUCCESS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwKkf9KCsLQY",
        "outputId": "4a37d825-da10-4c97-f326-16bb078cca9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Results will be saved under: /content/drive/MyDrive/tracklab_eval/results\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# Base folder on Drive where all results will go\n",
        "BASE_DIR = Path(\"/content/drive/MyDrive/tracklab_eval\")  # change name if you like\n",
        "OUTPUT_DIR = BASE_DIR / \"results\"\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Results will be saved under:\", OUTPUT_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMRXc5GpkG4d",
        "outputId": "f13e77b3-56c1-44a9-dd9c-7ef8e11d1362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "EVALUATION MODE SELECTION\n",
            "==================================================\n",
            "\n",
            "How do you want to evaluate the videos?\n",
            "  1. Use clips (faster - 60s segments)\n",
            "  2. Use full videos (comprehensive but slower)\n",
            "\n",
            "Enter your choice (1 or 2): 2\n",
            "\u001b[94m[INFO] Mode: FULL VIDEO EVALUATION\u001b[0m\n",
            "STARTING FULL EVALUATION\n",
            "\n",
            "\n",
            "VIDEO: FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p-seg06\n",
            "\n",
            "Processing full video...\n",
            "\u001b[94m[INFO] Running eagle on FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p-seg06 (full video)...\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Cell: Final System Evaluation\n",
        "\n",
        "import time\n",
        "import json\n",
        "import subprocess\n",
        "import os\n",
        "from pathlib import Path\n",
        "\"\"\"\n",
        "SYSTEM_CONFIGS = {\n",
        "        \"eagle\": {\n",
        "        \"path\": REPOS_DIR / \"eagle\",\n",
        "        \"script\": \"run_eagle.py\",\n",
        "        \"python\": \"python3.13\",\n",
        "    },\n",
        "    \"yolo11_botsort\": {\n",
        "        \"path\": REPOS_DIR / \"ultra_trackers\",\n",
        "        \"script\": \"run_ultra_yolo_tracker.py\",\n",
        "        \"args\": [\"--weights\", \"yolo11m.pt\", \"--tracker\", \"botsort\",],\n",
        "    },\n",
        "    \"darkmyter\": {\n",
        "        \"path\": REPOS_DIR / \"darkmyter\",\n",
        "        \"script\": \"run_darkmyter.py\",\n",
        "    },\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# System configurations\n",
        "SYSTEM_CONFIGS = {\n",
        "    \"eagle\": {\n",
        "        \"path\": REPOS_DIR / \"eagle\",\n",
        "        \"script\": \"run_eagle.py\",\n",
        "        \"python\": \"python3.13\",\n",
        "    },\n",
        "    \"yolo11_botsort\": {\n",
        "        \"path\": REPOS_DIR / \"ultra_trackers\",\n",
        "        \"script\": \"run_ultra_yolo_tracker.py\",\n",
        "        \"args\": [\"--weights\", \"yolo11m.pt\", \"--tracker\", \"botsort\",],\n",
        "    },\n",
        "    \"darkmyter\": {\n",
        "        \"path\": REPOS_DIR / \"darkmyter\",\n",
        "        \"script\": \"run_darkmyter.py\",\n",
        "    },\n",
        "}\n",
        "\n",
        "# Ask user for processing mode\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"EVALUATION MODE SELECTION\")\n",
        "print(\"=\"*50)\n",
        "print(\"\\nHow do you want to evaluate the videos?\")\n",
        "print(\"  1. Use clips (faster - 60s segments)\")\n",
        "print(\"  2. Use full videos (comprehensive but slower)\")\n",
        "\n",
        "mode_choice = input(\"\\nEnter your choice (1 or 2): \").strip()\n",
        "USE_CLIPS = mode_choice != '2'\n",
        "\n",
        "if USE_CLIPS:\n",
        "    print_status(\"Mode: CLIP-BASED EVALUATION\", \"INFO\")\n",
        "    ALL_VIDEOS = VIDEO_CLIPS\n",
        "    eval_type = \"clips\"\n",
        "else:\n",
        "    print_status(\"Mode: FULL VIDEO EVALUATION\", \"INFO\")\n",
        "    ALL_VIDEOS = FULL_VIDEOS\n",
        "    eval_type = \"full\"\n",
        "\n",
        "position_to_number = {\"start\": 1, \"middle\": 2, \"end\": 3, \"full\": 1}\n",
        "\n",
        "def run_system_on_video(system_name, system_config, video_name, segment_name, video_path):\n",
        "    \"\"\"Run a tracking system on a video or clip\"\"\"\n",
        "\n",
        "    if USE_CLIPS:\n",
        "        segment_number = position_to_number.get(segment_name, 1)\n",
        "        output_dir = OUTPUT_DIR / video_name / \"clips\" / str(segment_number) / system_name\n",
        "    else:\n",
        "        output_dir = OUTPUT_DIR / video_name / \"full\" / system_name\n",
        "\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if USE_CLIPS:\n",
        "        print_status(f\"Running {system_name} on {video_name}/clip_{segment_number}...\", \"INFO\")\n",
        "    else:\n",
        "        print_status(f\"Running {system_name} on {video_name} (full video)...\", \"INFO\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    output_file = output_dir / f\"{system_name}_output.json\"\n",
        "    system_path = system_config.get(\"path\", REPOS_DIR)\n",
        "\n",
        "    # Build command\n",
        "    if system_name == \"eagle\":\n",
        "        cmd = [\n",
        "            \"uv\", \"run\", \"--python\", system_config.get(\"python\", \"python3.13\"),\n",
        "            \"run_eagle.py\",\n",
        "            \"--video\", str(video_path),\n",
        "            \"--output\", str(output_file),\n",
        "        ]\n",
        "    else:\n",
        "        cmd = [\n",
        "            \"python\", system_config[\"script\"],\n",
        "            \"--video\", str(video_path),\n",
        "            \"--output\", str(output_file),\n",
        "        ] + [str(extra) for extra in system_config.get(\"args\", [])]\n",
        "\n",
        "    try:\n",
        "        #Not using a timeout\n",
        "        timeout = 10000\n",
        "        result = subprocess.run(\n",
        "            cmd,\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            cwd=str(system_path),\n",
        "        )\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        if result.returncode == 0 and output_file.exists():\n",
        "            try:\n",
        "                with open(output_file) as f:\n",
        "                    data = json.load(f)\n",
        "\n",
        "                if isinstance(data, list):\n",
        "                    num_detections = len(data)\n",
        "                elif isinstance(data, dict):\n",
        "                    num_detections = sum(\n",
        "                        len(dets) if isinstance(dets, list) else 0\n",
        "                        for dets in data.values()\n",
        "                    )\n",
        "                else:\n",
        "                    num_detections = 0\n",
        "\n",
        "                print_status(\n",
        "                    f\"{system_name}: SUCCESS - {num_detections} detections in {elapsed:.1f}s\",\n",
        "                    \"SUCCESS\",\n",
        "                )\n",
        "                return {\n",
        "                    \"success\": True,\n",
        "                    \"time\": elapsed,\n",
        "                    \"output\": str(output_file),\n",
        "                    \"detections\": num_detections,\n",
        "                }\n",
        "\n",
        "            except json.JSONDecodeError as e:\n",
        "                print_status(f\"{system_name}: Invalid JSON\", \"ERROR\")\n",
        "                return {\"success\": False, \"time\": elapsed, \"error\": f\"Invalid JSON: {e}\"}\n",
        "        else:\n",
        "            error_msg = result.stderr[-500:] if result.stderr else \"Unknown error\"\n",
        "            print_status(f\"{system_name}: FAILED\", \"ERROR\")\n",
        "            print(f\"Error: {error_msg}\")\n",
        "            return {\"success\": False, \"time\": elapsed, \"error\": error_msg}\n",
        "\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print_status(f\"{system_name}: TIMEOUT\", \"ERROR\")\n",
        "        return {\"success\": False, \"time\": timeout, \"error\": \"Timeout\"}\n",
        "\n",
        "    except Exception as e:\n",
        "        print_status(f\"{system_name}: EXCEPTION - {str(e)}\", \"ERROR\")\n",
        "        return {\"success\": False, \"time\": time.time() - start_time, \"error\": str(e)}\n",
        "\n",
        "def save_progress(all_results, eval_type):\n",
        "    \"Save current progress to disk (in Drive, via OUTPUT_DIR)\"\n",
        "    progress_file = OUTPUT_DIR / f\"progress_{eval_type}.json\"\n",
        "    with open(progress_file, \"w\") as f:\n",
        "        json.dump(all_results, f, indent=2)\n",
        "    return progress_file\n",
        "\n",
        "def load_progress(eval_type):\n",
        "    \"Load existing progress if available\"\n",
        "    progress_file = OUTPUT_DIR / f\"progress_{eval_type}.json\"\n",
        "    if progress_file.exists():\n",
        "        try:\n",
        "            with open(progress_file) as f:\n",
        "                return json.load(f)\n",
        "        except Exception:\n",
        "            return {}\n",
        "    return {}\n",
        "\n",
        "print(f\"STARTING {eval_type.upper()} EVALUATION\\n\")\n",
        "\n",
        "all_results = load_progress(eval_type)\n",
        "if all_results:\n",
        "    print_status(f\"Loaded existing progress with {len(all_results)} videos\", \"INFO\")\n",
        "    print(\"Videos already processed:\")\n",
        "    for video_name in all_results.keys():\n",
        "        print(f\"  - {video_name}\")\n",
        "\n",
        "    # Ask if user wants to continue or restart\n",
        "    print(\"\\nDo you want to:\")\n",
        "    print(\"  1. Continue from where you left off\")\n",
        "    print(\"  2. Start fresh (delete existing progress)\")\n",
        "    continue_choice = input(\"\\nEnter your choice (1 or 2): \").strip()\n",
        "\n",
        "    if continue_choice == '2':\n",
        "        all_results = {}\n",
        "        print_status(\"Starting fresh evaluation\", \"INFO\")\n",
        "\n",
        "for video_name, segments in ALL_VIDEOS.items():\n",
        "    print(f\"\\nVIDEO: {video_name}\")\n",
        "\n",
        "    video_results = all_results.get(video_name, {})\n",
        "\n",
        "    for segment_name, video_path in segments.items():\n",
        "        if USE_CLIPS:\n",
        "            segment_number = position_to_number.get(segment_name, 1)\n",
        "            segment_key = f\"clip_{segment_number}\"\n",
        "            print(f\"\\nProcessing clip {segment_number} ({segment_name})...\")\n",
        "        else:\n",
        "            segment_key = \"full\"\n",
        "            print(f\"\\nProcessing full video...\")\n",
        "\n",
        "        segment_results = video_results.get(segment_key, {})\n",
        "        video_results[segment_key] = segment_results\n",
        "\n",
        "        for system_name, system_config in SYSTEM_CONFIGS.items():\n",
        "            # Skip if already processed successfully\n",
        "            if system_name in segment_results and segment_results[system_name].get(\"success\"):\n",
        "                print_status(f\"{system_name}: Already completed successfully\", \"SKIP\")\n",
        "                continue\n",
        "            elif system_name in segment_results:\n",
        "                print_status(f\"{system_name}: Retrying previous failure\", \"RETRY\")\n",
        "\n",
        "            result = run_system_on_video(\n",
        "                system_name, system_config, video_name, segment_name, video_path\n",
        "            )\n",
        "            segment_results[system_name] = result\n",
        "\n",
        "            # Save progress after each system completes (to Drive)\n",
        "            all_results[video_name] = video_results\n",
        "            progress_file = save_progress(all_results, eval_type)\n",
        "            print_status(f\"Progress saved to {progress_file.name}\", \"SAVE\")\n",
        "\n",
        "        successful = sum(1 for r in segment_results.values() if r.get(\"success\", False))\n",
        "        total = len(segment_results)\n",
        "\n",
        "        if USE_CLIPS:\n",
        "            print(f\"\\nClip summary: {successful}/{total} systems succeeded\")\n",
        "        else:\n",
        "            print(f\"\\nVideo summary: {successful}/{total} systems succeeded\")\n",
        "\n",
        "    # Save per-video summary\n",
        "    summary_file = OUTPUT_DIR / video_name / f\"summary_{eval_type}.json\"\n",
        "    summary_file.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with open(summary_file, \"w\") as f:\n",
        "        json.dump(video_results, f, indent=2)\n",
        "    print_status(f\"Video summary saved to {summary_file.name}\", \"SAVE\")\n",
        "\n",
        "# Save overall summary\n",
        "overall_summary = OUTPUT_DIR / f\"overall_summary_{eval_type}.json\"\n",
        "with open(overall_summary, \"w\") as f:\n",
        "    json.dump(all_results, f, indent=2)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(f\"{eval_type.upper()} EVALUATION COMPLETE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "system_stats = {\n",
        "    sys: {\"success\": 0, \"total\": 0, \"avg_time\": [], \"avg_detections\": []}\n",
        "    for sys in SYSTEM_CONFIGS.keys()\n",
        "}\n",
        "\n",
        "for video_results in all_results.values():\n",
        "    for segment_results in video_results.values():\n",
        "        for system_name, result in segment_results.items():\n",
        "            if system_name in system_stats:\n",
        "                system_stats[system_name][\"total\"] += 1\n",
        "                if result.get(\"success\", False):\n",
        "                    system_stats[system_name][\"success\"] += 1\n",
        "                    if \"time\" in result:\n",
        "                        system_stats[system_name][\"avg_time\"].append(result[\"time\"])\n",
        "                    if \"detections\" in result:\n",
        "                        system_stats[system_name][\"avg_detections\"].append(result[\"detections\"])\n",
        "\n",
        "print(\"\\nSystem Success Rates:\")\n",
        "print(\"-\" * 40)\n",
        "for system_name, stats in system_stats.items():\n",
        "    if stats[\"total\"] > 0:\n",
        "        success_rate = (stats[\"success\"] / stats[\"total\"]) * 100\n",
        "        print(f\"\\n{system_name}:\")\n",
        "        print(f\"  Success Rate: {stats['success']}/{stats['total']} ({success_rate:.1f}%)\")\n",
        "        if stats[\"avg_time\"]:\n",
        "            avg_time = sum(stats[\"avg_time\"]) / len(stats[\"avg_time\"])\n",
        "            print(f\"  Avg Time: {avg_time:.1f}s\")\n",
        "        if stats[\"avg_detections\"]:\n",
        "            avg_det = sum(stats[\"avg_detections\"]) / len(stats[\"avg_detections\"])\n",
        "            print(f\"  Avg Detections: {avg_det:.0f}\")\n",
        "\n",
        "print(f\"\\nResults Directory: {OUTPUT_DIR}\")\n",
        "print(f\"Overall Summary: {overall_summary}\")\n",
        "print(f\"Progress File: {OUTPUT_DIR / f'progress_{eval_type}.json'}\")\n",
        "\n",
        "total_expected = len(ALL_VIDEOS) * len(next(iter(ALL_VIDEOS.values())))\n",
        "total_processed = sum(len(video_results) for video_results in all_results.values())\n",
        "\n",
        "if total_processed == total_expected:\n",
        "    print(\"\\n\")\n",
        "    print(\"ALL VIDEOS PROCESSED SUCCESSFULLY!\")\n",
        "    print(\"Progress file kept for reference.\")\n",
        "else:\n",
        "    print(\"\\n\")\n",
        "    print(f\"PARTIAL COMPLETION: {total_processed}/{total_expected} segments processed\")\n",
        "    print(\"Run the script again to continue from where you left off.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Mcypceex0fH"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssYvFpf4x0sF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WA43PF1PxV32"
      },
      "outputs": [],
      "source": [
        "cd /content/path/to/Eagle  # eagle_dir\n",
        "uv run main.py --video_path /full/path/to/one/clip.mp4 --fps 20\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEQ4BiwHwTq2"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Evaluation Cell for Football Player Tracking Systems\n",
        "\n",
        "\"\"\"\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "from dataclasses import dataclass, field\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print_status(\"Starting comprehensive tracking evaluation...\", \"INFO\")\n",
        "\n",
        "# DATA STRUCTURES\n",
        "\n",
        "@dataclass\n",
        "class Detection:\n",
        "    \"\"\"Universal detection representation\"\"\"\n",
        "    frame_id: int\n",
        "    track_id: int\n",
        "    bbox: List[float]  # [x1, y1, x2, y2]\n",
        "    confidence: float = 1.0\n",
        "    class_id: int = 0\n",
        "\n",
        "    # Eagle-specific\n",
        "    transformed_coords: Optional[Tuple[float, float]] = None\n",
        "    is_goalkeeper: bool = False\n",
        "\n",
        "    # Metadata\n",
        "    source_system: str = \"\"\n",
        "    raw_data: Dict = field(default_factory=dict)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class SystemData:\n",
        "    \"\"\"Container for system tracking data\"\"\"\n",
        "    name: str\n",
        "    frames: Dict[int, List[Detection]]\n",
        "    metadata: Dict[str, Any]\n",
        "    source_file: str\n",
        "    clip_name: str = \"\"\n",
        "\n",
        "\n",
        "\n",
        "# DATA LOADERS\n",
        "\n",
        "\n",
        "class UniversalLoader:\n",
        "    \"\"\"Load tracking data from different systems\"\"\"\n",
        "    @staticmethod\n",
        "    def load_eagle(filepath: Path) -> SystemData:\n",
        "        \"\"\"Load Eagle data (handles both raw_coordinates and standard format)\"\"\"\n",
        "        with open(filepath, \"r\") as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        from collections import defaultdict\n",
        "        frames = defaultdict(list)\n",
        "        metadata = {\"system\": \"Eagle\", \"features\": []}\n",
        "\n",
        "\n",
        "        # CASE 1: Eagle raw_coordinates format\n",
        "        if isinstance(data, dict) and data:\n",
        "            all_keys = list(data.keys())\n",
        "            if all(k.isdigit() for k in all_keys):\n",
        "                metadata[\"features\"] = [\"field_coordinates\", \"goalkeeper_detection\", \"keypoints\"]\n",
        "                metadata[\"format\"] = \"raw_coordinates\"\n",
        "\n",
        "                # iterate all frames, not just one\n",
        "                for frame_str in sorted(all_keys, key=lambda s: int(s)):\n",
        "                    frame_data = data[frame_str]\n",
        "                    frame_id = int(frame_str)\n",
        "\n",
        "                    coords = frame_data.get(\"Coordinates\", {})\n",
        "\n",
        "                    # Players\n",
        "                    for player_id, player_data in coords.get(\"Player\", {}).items():\n",
        "                        if \"BBox\" not in player_data:\n",
        "                            continue\n",
        "\n",
        "                        tc = player_data.get(\"Transformed_Coordinates\")\n",
        "                        if isinstance(tc, (list, tuple)) and len(tc) >= 2:\n",
        "                            transformed_coords = (float(tc[0]), float(tc[1]))\n",
        "                        else:\n",
        "                            transformed_coords = None\n",
        "\n",
        "                        det = Detection(\n",
        "                            frame_id=frame_id,\n",
        "                            track_id=int(player_id),\n",
        "                            bbox=player_data[\"BBox\"],\n",
        "                            confidence=player_data.get(\"Confidence\", 1.0),\n",
        "                            class_id=0,\n",
        "                            transformed_coords=transformed_coords,\n",
        "                            is_goalkeeper=False,\n",
        "                            source_system=\"Eagle\",\n",
        "                            raw_data=player_data,\n",
        "                        )\n",
        "                        frames[frame_id].append(det)\n",
        "\n",
        "                    # Goalkeepers\n",
        "                    for gk_id, gk_data in coords.get(\"Goalkeeper\", {}).items():\n",
        "                        if \"BBox\" not in gk_data:\n",
        "                            continue\n",
        "\n",
        "                        tc = gk_data.get(\"Transformed_Coordinates\")\n",
        "                        if isinstance(tc, (list, tuple)) and len(tc) >= 2:\n",
        "                            transformed_coords = (float(tc[0]), float(tc[1]))\n",
        "                        else:\n",
        "                            transformed_coords = None\n",
        "\n",
        "                        det = Detection(\n",
        "                            frame_id=frame_id,\n",
        "                            track_id=int(gk_id),\n",
        "                            bbox=gk_data[\"BBox\"],\n",
        "                            confidence=gk_data.get(\"Confidence\", 1.0),\n",
        "                            class_id=1,\n",
        "                            transformed_coords=transformed_coords,\n",
        "                            is_goalkeeper=True,\n",
        "                            source_system=\"Eagle\",\n",
        "                            raw_data=gk_data,\n",
        "                        )\n",
        "                        frames[frame_id].append(det)\n",
        "\n",
        "                    # Keypoints metadata\n",
        "                    if \"Keypoints\" in frame_data:\n",
        "                        metadata.setdefault(\"keypoints\", []).append(\n",
        "                            {\"frame\": frame_id, \"points\": frame_data[\"Keypoints\"]}\n",
        "                        )\n",
        "\n",
        "\n",
        "        # CASE 2: already in standard tracking format--\n",
        "        elif isinstance(data, list):\n",
        "            metadata[\"format\"] = \"standard\"\n",
        "            for det_dict in data:\n",
        "                det = Detection(\n",
        "                    frame_id=det_dict[\"frame_id\"],\n",
        "                    track_id=det_dict[\"track_id\"],\n",
        "                    bbox=det_dict[\"bbox\"],\n",
        "                    confidence=det_dict.get(\"score\", 1.0),\n",
        "                    class_id=det_dict.get(\"class_id\", 0),\n",
        "                    source_system=\"Eagle\",\n",
        "                )\n",
        "                frames[det.frame_id].append(det)\n",
        "\n",
        "        return SystemData(\n",
        "            name=\"Eagle\",\n",
        "            frames=dict(frames),\n",
        "            metadata=metadata,\n",
        "            source_file=str(filepath),\n",
        "        )\n",
        "    @staticmethod\n",
        "    def load_darkmyter(filepath: Path) -> SystemData:\n",
        "        \"\"\"Load Darkmyter data (YOLOv8 with ByteTrack)\"\"\"\n",
        "        with open(filepath, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        frames = defaultdict(list)\n",
        "        metadata = {\"system\": \"Darkmyter\"}\n",
        "\n",
        "        # Check if it's the full format with metadata\n",
        "        if isinstance(data, dict) and 'framework' in data:\n",
        "            metadata.update({\n",
        "                \"model\": data.get('model', 'yolov8'),\n",
        "                \"tracker\": data.get('tracker', 'ByteTrack'),\n",
        "                \"features\": data.get('features', {}),\n",
        "                \"statistics\": data.get('statistics', {})\n",
        "            })\n",
        "            detections = data.get('detections', [])\n",
        "        else:\n",
        "            # Simple list format\n",
        "            detections = data if isinstance(data, list) else []\n",
        "\n",
        "        for det_dict in detections:\n",
        "            det = Detection(\n",
        "                frame_id=det_dict['frame_id'],\n",
        "                track_id=det_dict['track_id'],\n",
        "                bbox=det_dict['bbox'],\n",
        "                confidence=det_dict['score'],\n",
        "                class_id=det_dict['class_id'],\n",
        "                source_system=\"Darkmyter\"\n",
        "            )\n",
        "            frames[det.frame_id].append(det)\n",
        "\n",
        "        return SystemData(\n",
        "            name=\"Darkmyter\",\n",
        "            frames=dict(frames),\n",
        "            metadata=metadata,\n",
        "            source_file=str(filepath)\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def load_yolo11(filepath: Path, tracker_name: str = \"YOLO11\") -> SystemData:\n",
        "        \"\"\"Load YOLO11 data (with BotSort or ByteTrack)\"\"\"\n",
        "        with open(filepath, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        frames = defaultdict(list)\n",
        "        metadata = {\n",
        "            \"system\": tracker_name,\n",
        "            \"model\": \"YOLOv11\",\n",
        "            \"tracker\": \"BotSort\" if \"botsort\" in tracker_name.lower() else \"ByteTrack\"\n",
        "        }\n",
        "\n",
        "        # Handle both list and dict formats\n",
        "        detections = data if isinstance(data, list) else data.get('detections', [])\n",
        "\n",
        "        for det_dict in detections:\n",
        "            det = Detection(\n",
        "                frame_id=det_dict['frame_id'],\n",
        "                track_id=det_dict['track_id'],\n",
        "                bbox=det_dict['bbox'],\n",
        "                confidence=det_dict['score'],\n",
        "                class_id=det_dict['class_id'],\n",
        "                source_system=tracker_name\n",
        "            )\n",
        "            frames[det.frame_id].append(det)\n",
        "\n",
        "        return SystemData(\n",
        "            name=tracker_name,\n",
        "            frames=dict(frames),\n",
        "            metadata=metadata,\n",
        "            source_file=str(filepath)\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "# EVALUATION METRICS\n",
        "\n",
        "\n",
        "class TrackingEvaluator:\n",
        "    \"\"\"Evaluate tracking performance\"\"\"\n",
        "\n",
        "    def __init__(self, iou_threshold: float = 0.5):\n",
        "        self.iou_threshold = iou_threshold\n",
        "\n",
        "    def calculate_iou(self, bbox1: List[float], bbox2: List[float]) -> float:\n",
        "        \"\"\"Calculate Intersection over Union\"\"\"\n",
        "        x1_min, y1_min, x1_max, y1_max = bbox1\n",
        "        x2_min, y2_min, x2_max, y2_max = bbox2\n",
        "\n",
        "        x_inter_min = max(x1_min, x2_min)\n",
        "        y_inter_min = max(y1_min, y2_min)\n",
        "        x_inter_max = min(x1_max, x2_max)\n",
        "        y_inter_max = min(y1_max, y2_max)\n",
        "\n",
        "        if x_inter_max < x_inter_min or y_inter_max < y_inter_min:\n",
        "            return 0.0\n",
        "\n",
        "        inter_area = (x_inter_max - x_inter_min) * (y_inter_max - y_inter_min)\n",
        "        area1 = (x1_max - x1_min) * (y1_max - y1_min)\n",
        "        area2 = (x2_max - x2_min) * (y2_max - y2_min)\n",
        "        union_area = area1 + area2 - inter_area\n",
        "\n",
        "        return inter_area / union_area if union_area > 0 else 0.0\n",
        "\n",
        "    def evaluate_system(self, system_data: SystemData) -> Dict:\n",
        "        \"\"\"Evaluate a single system\"\"\"\n",
        "        total_detections = sum(len(dets) for dets in system_data.frames.values())\n",
        "        unique_tracks = set()\n",
        "        confidence_values = []\n",
        "\n",
        "        for detections in system_data.frames.values():\n",
        "            for det in detections:\n",
        "                unique_tracks.add(det.track_id)\n",
        "                confidence_values.append(det.confidence)\n",
        "\n",
        "        # Track continuity analysis\n",
        "        track_lifetimes = defaultdict(list)\n",
        "        for frame_id, detections in system_data.frames.items():\n",
        "            for det in detections:\n",
        "                track_lifetimes[det.track_id].append(frame_id)\n",
        "\n",
        "        # Calculate fragmentations\n",
        "        fragmentations = 0\n",
        "        for track_id, frame_list in track_lifetimes.items():\n",
        "            frame_list = sorted(frame_list)\n",
        "            for i in range(1, len(frame_list)):\n",
        "                if frame_list[i] - frame_list[i-1] > 1:\n",
        "                    fragmentations += 1\n",
        "\n",
        "        # Eagle-specific metrics\n",
        "        eagle_metrics = {}\n",
        "        if system_data.name == \"Eagle\" and system_data.metadata.get('format') == 'raw_coordinates':\n",
        "            goalkeeper_count = sum(1 for dets in system_data.frames.values()\n",
        "                                 for det in dets if det.is_goalkeeper)\n",
        "            with_coords = sum(1 for dets in system_data.frames.values()\n",
        "                             for det in dets if det.transformed_coords)\n",
        "            eagle_metrics = {\n",
        "                'goalkeeper_detections': goalkeeper_count,\n",
        "                'detections_with_field_coords': with_coords,\n",
        "                'has_keypoints': 'keypoints' in system_data.metadata\n",
        "            }\n",
        "\n",
        "        return {\n",
        "            'system': system_data.name,\n",
        "            'clip': system_data.clip_name,\n",
        "            'total_frames': len(system_data.frames),\n",
        "            'total_detections': total_detections,\n",
        "            'unique_tracks': len(unique_tracks),\n",
        "            'avg_detections_per_frame': total_detections / len(system_data.frames) if system_data.frames else 0,\n",
        "            'avg_confidence': np.mean(confidence_values) if confidence_values else 0,\n",
        "            'std_confidence': np.std(confidence_values) if confidence_values else 0,\n",
        "            'fragmentations': fragmentations,\n",
        "            'avg_track_lifetime': np.mean([len(frames) for frames in track_lifetimes.values()]) if track_lifetimes else 0,\n",
        "            **eagle_metrics\n",
        "        }\n",
        "\n",
        "    def compare_systems(self, sys1: SystemData, sys2: SystemData) -> Dict:\n",
        "        \"\"\"Compare two systems on overlapping frames\"\"\"\n",
        "        common_frames = set(sys1.frames.keys()) & set(sys2.frames.keys())\n",
        "\n",
        "        if not common_frames:\n",
        "            return {\n",
        "                'comparison': f\"{sys1.name} vs {sys2.name}\",\n",
        "                'clip': sys1.clip_name,\n",
        "                'common_frames': 0,\n",
        "                'message': 'No overlapping frames'\n",
        "            }\n",
        "\n",
        "        matches = 0\n",
        "        total_iou = 0\n",
        "        sys1_only = 0\n",
        "        sys2_only = 0\n",
        "\n",
        "        for frame_id in common_frames:\n",
        "            dets1 = sys1.frames[frame_id]\n",
        "            dets2 = sys2.frames[frame_id]\n",
        "\n",
        "            matched2 = set()\n",
        "\n",
        "            for d1 in dets1:\n",
        "                best_iou = 0\n",
        "                best_match = None\n",
        "\n",
        "                for i, d2 in enumerate(dets2):\n",
        "                    if i in matched2:\n",
        "                        continue\n",
        "                    iou = self.calculate_iou(d1.bbox, d2.bbox)\n",
        "                    if iou > best_iou:\n",
        "                        best_iou = iou\n",
        "                        best_match = i\n",
        "\n",
        "                if best_iou >= self.iou_threshold:\n",
        "                    matches += 1\n",
        "                    total_iou += best_iou\n",
        "                    matched2.add(best_match)\n",
        "                else:\n",
        "                    sys1_only += 1\n",
        "\n",
        "            sys2_only += len(dets2) - len(matched2)\n",
        "\n",
        "        return {\n",
        "            'comparison': f\"{sys1.name} vs {sys2.name}\",\n",
        "            'clip': sys1.clip_name,\n",
        "            'common_frames': len(common_frames),\n",
        "            'matched_detections': matches,\n",
        "            'avg_iou': total_iou / matches if matches > 0 else 0,\n",
        "            f'{sys1.name}_only': sys1_only,\n",
        "            f'{sys2.name}_only': sys2_only,\n",
        "            'match_rate': matches / (matches + sys1_only + sys2_only) if (matches + sys1_only + sys2_only) > 0 else 0\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "# LOAD DATA FROM YOUR EXACT STRUCTURE\n",
        "\n",
        "\n",
        "def load_tracking_outputs_from_structure(base_dir: Path):\n",
        "    \"\"\"\n",
        "    Load tracking outputs from your directory structure:\n",
        "\n",
        "    /content/output/\n",
        "        <MATCH_NAME>/\n",
        "            clips/\n",
        "                1/\n",
        "                    darkmyter/darkmyter_output.json\n",
        "                    eagle/eagle_output.json\n",
        "                    yolo11_botsort/yolo11_botsort_output.json\n",
        "                    yolo11_bytetrack/yolo11_bytetrack_output.json\n",
        "    \"\"\"\n",
        "    systems = []\n",
        "    loader = UniversalLoader()\n",
        "\n",
        "    if not base_dir.exists():\n",
        "        print_status(f\"Base directory does not exist: {base_dir}\", \"ERROR\")\n",
        "        return systems\n",
        "\n",
        "    print_status(f\"Scanning directory: {base_dir}\", \"INFO\")\n",
        "\n",
        "    # Treat *every* subdirectory of base_dir as a match directory\n",
        "    for match_dir in sorted(base_dir.iterdir()):\n",
        "        if not match_dir.is_dir():\n",
        "            continue\n",
        "\n",
        "        match_name = match_dir.name\n",
        "        print_status(f\"Found match: {match_name}\", \"INFO\")\n",
        "\n",
        "        clips_dir = match_dir / \"clips\"\n",
        "        if not clips_dir.exists():\n",
        "            print_status(f\"  No clips directory in {match_name}\", \"WARNING\")\n",
        "            continue\n",
        "\n",
        "        # Process each clip folder (e.g., \"1\", \"2\", ...)\n",
        "        for clip_dir in sorted(clips_dir.iterdir()):\n",
        "            if not clip_dir.is_dir():\n",
        "                continue\n",
        "\n",
        "            clip_name = clip_dir.name\n",
        "            print_status(f\"  Processing clip {clip_name}...\", \"INFO\")\n",
        "\n",
        "            # Eagle\n",
        "            eagle_dir = clip_dir / \"eagle\"\n",
        "            if eagle_dir.exists():\n",
        "                eagle_file = eagle_dir / \"eagle_output.json\"\n",
        "                if eagle_file.exists():\n",
        "                    try:\n",
        "                        system_data = loader.load_eagle(eagle_file)\n",
        "                        system_data.clip_name = f\"{match_name}_clip_{clip_name}\"\n",
        "                        systems.append(system_data)\n",
        "                        print_status(\n",
        "                            f\"    ✓ Eagle: {len(system_data.frames)} frames\",\n",
        "                            \"SUCCESS\"\n",
        "                        )\n",
        "                    except Exception as e:\n",
        "                        print_status(f\"    ✗ Eagle failed: {e}\", \"ERROR\")\n",
        "\n",
        "            #  Darkmyter\n",
        "            darkmyter_dir = clip_dir / \"darkmyter\"\n",
        "            if darkmyter_dir.exists():\n",
        "                darkmyter_file = darkmyter_dir / \"darkmyter_output.json\"\n",
        "                if darkmyter_file.exists():\n",
        "                    try:\n",
        "                        system_data = loader.load_darkmyter(darkmyter_file)\n",
        "                        system_data.clip_name = f\"{match_name}_clip_{clip_name}\"\n",
        "                        systems.append(system_data)\n",
        "                        print_status(\n",
        "                            f\"    ✓ Darkmyter: {len(system_data.frames)} frames\",\n",
        "                            \"SUCCESS\"\n",
        "                        )\n",
        "                    except Exception as e:\n",
        "                        print_status(f\"    ✗ Darkmyter failed: {e}\", \"ERROR\")\n",
        "\n",
        "            #  YOLO11 BotSort\n",
        "            yolo11_botsort_dir = clip_dir / \"yolo11_botsort\"\n",
        "            if yolo11_botsort_dir.exists():\n",
        "                yolo11_botsort_file = yolo11_botsort_dir / \"yolo11_botsort_output.json\"\n",
        "                if yolo11_botsort_file.exists():\n",
        "                    try:\n",
        "                        system_data = loader.load_yolo11(\n",
        "                            yolo11_botsort_file,\n",
        "                            \"YOLO11-BotSort\"\n",
        "                        )\n",
        "                        system_data.clip_name = f\"{match_name}_clip_{clip_name}\"\n",
        "                        systems.append(system_data)\n",
        "                        print_status(\n",
        "                            f\"    ✓ YOLO11-BotSort: {len(system_data.frames)} frames\",\n",
        "                            \"SUCCESS\"\n",
        "                        )\n",
        "                    except Exception as e:\n",
        "                        print_status(f\"    ✗ YOLO11-BotSort failed: {e}\", \"ERROR\")\n",
        "\n",
        "            #  YOLO11 ByteTrack\n",
        "            yolo11_bytetrack_dir = clip_dir / \"yolo11_bytetrack\"\n",
        "            if yolo11_bytetrack_dir.exists():\n",
        "                yolo11_bytetrack_file = (\n",
        "                    yolo11_bytetrack_dir / \"yolo11_bytetrack_output.json\"\n",
        "                )\n",
        "                if yolo11_bytetrack_file.exists():\n",
        "                    try:\n",
        "                        system_data = loader.load_yolo11(\n",
        "                            yolo11_bytetrack_file,\n",
        "                            \"YOLO11-ByteTrack\"\n",
        "                        )\n",
        "                        system_data.clip_name = f\"{match_name}_clip_{clip_name}\"\n",
        "                        systems.append(system_data)\n",
        "                        print_status(\n",
        "                            f\"    ✓ YOLO11-ByteTrack: {len(system_data.frames)} frames\",\n",
        "                            \"SUCCESS\"\n",
        "                        )\n",
        "                    except Exception as e:\n",
        "                        print_status(f\"    ✗ YOLO11-ByteTrack failed: {e}\", \"ERROR\")\n",
        "\n",
        "    return systems\n",
        "\n",
        "\n",
        "    # Summary Statistics Table\n",
        "    ax6 = plt.subplot(2, 4, 6)\n",
        "    ax6.axis('tight')\n",
        "    ax6.axis('off')\n",
        "\n",
        "    if not eval_df.empty:\n",
        "        summary_data = []\n",
        "        for _, row in system_summary.iterrows():\n",
        "            summary_data.append([\n",
        "                row['system'],\n",
        "                f\"{int(row['total_frames'])}\",\n",
        "                f\"{int(row['total_detections'])}\",\n",
        "                f\"{row['unique_tracks']:.0f}\",\n",
        "                f\"{row['avg_confidence']:.3f}\"\n",
        "            ])\n",
        "\n",
        "        table = ax6.table(cellText=summary_data,\n",
        "                         colLabels=['System', 'Frames', 'Detections', 'Avg Tracks', 'Avg Conf'],\n",
        "                         cellLoc='center',\n",
        "                         loc='center')\n",
        "        table.auto_set_font_size(False)\n",
        "        table.set_fontsize(10)\n",
        "        table.scale(1, 1.5)\n",
        "\n",
        "    ax6.set_title('Aggregated Summary Statistics', pad=20)\n",
        "\n",
        "    plt.suptitle('Football Tracking Systems Evaluation', fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return fig\n",
        "\n",
        "\n",
        "\n",
        "# MAIN EVALUATION EXECUTION\n",
        "\n",
        "\n",
        "# Set your base output directory\n",
        "OUTPUT_DIR = Path(\"/content/output\")  # Adjust this to your path\n",
        "\n",
        "# Load tracking data from your structure\n",
        "print_status(\"Loading tracking outputs...\", \"INFO\")\n",
        "systems = load_tracking_outputs_from_structure(OUTPUT_DIR)\n",
        "\n",
        "if not systems:\n",
        "    print_status(\"No tracking data found! Please check your output directory.\", \"ERROR\")\n",
        "    print_status(f\"Expected structure: {OUTPUT_DIR}/FULL_MATCH_*/clips/*/system_name/\", \"INFO\")\n",
        "else:\n",
        "    print_status(f\"Successfully loaded {len(systems)} system outputs\", \"SUCCESS\")\n",
        "\n",
        "    # Evaluate each system\n",
        "    evaluator = TrackingEvaluator(iou_threshold=0.5)\n",
        "    evaluation_results = []\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"INDIVIDUAL SYSTEM EVALUATION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for system in systems:\n",
        "        metrics = evaluator.evaluate_system(system)\n",
        "        evaluation_results.append(metrics)\n",
        "\n",
        "        print(f\"\\n{system.name} - {system.clip_name}:\")\n",
        "        print(f\"  Frames: {metrics['total_frames']}\")\n",
        "        print(f\"  Detections: {metrics['total_detections']}\")\n",
        "        print(f\"  Unique tracks: {metrics['unique_tracks']}\")\n",
        "        print(f\"  Avg confidence: {metrics['avg_confidence']:.3f}\")\n",
        "\n",
        "    # Pairwise comparisons within each clip\n",
        "    comparison_results = []\n",
        "\n",
        "    # Group systems by clip\n",
        "    clips = defaultdict(list)\n",
        "    for system in systems:\n",
        "        clips[system.clip_name].append(system)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"PAIRWISE SYSTEM COMPARISON\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for clip_name, clip_systems in clips.items():\n",
        "        if len(clip_systems) > 1:\n",
        "            print(f\"\\nClip: {clip_name}\")\n",
        "\n",
        "            for i in range(len(clip_systems)):\n",
        "                for j in range(i+1, len(clip_systems)):\n",
        "                    comparison = evaluator.compare_systems(clip_systems[i], clip_systems[j])\n",
        "                    comparison_results.append(comparison)\n",
        "\n",
        "                    if comparison['common_frames'] > 0:\n",
        "                        print(f\"  {comparison['comparison']}:\")\n",
        "                        print(f\"    Common frames: {comparison['common_frames']}\")\n",
        "                        print(f\"    Match rate: {comparison['match_rate']:.3f}\")\n",
        "\n",
        "    # Create visualizations\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"GENERATING EVALUATION PLOTS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    fig = create_evaluation_plots(evaluation_results, comparison_results)\n",
        "\n",
        "    # Save results\n",
        "    eval_df = pd.DataFrame(evaluation_results)\n",
        "    eval_df.to_csv('tracking_evaluation_results.csv', index=False)\n",
        "    print_status(\"Results saved to tracking_evaluation_results.csv\", \"SUCCESS\")\n",
        "\n",
        "    if comparison_results:\n",
        "        comp_df = pd.DataFrame(comparison_results)\n",
        "        comp_df.to_csv('tracking_comparison_results.csv', index=False)\n",
        "        print_status(\"Comparisons saved to tracking_comparison_results.csv\", \"SUCCESS\")\n",
        "\n",
        "    # Display summary\n",
        "    print(\"\\n\")\n",
        "    print(\"EVALUATION SUMMARY\")\n",
        "\n",
        "    # Aggregate by system\n",
        "    system_avg = eval_df.groupby('system').agg({\n",
        "        'avg_confidence': 'mean',\n",
        "        'unique_tracks': 'mean',\n",
        "        'fragmentations': 'sum'\n",
        "    }).reset_index()\n",
        "\n",
        "    if not system_avg.empty:\n",
        "        best_confidence = system_avg.loc[system_avg['avg_confidence'].idxmax()]\n",
        "        best_tracks = system_avg.loc[system_avg['unique_tracks'].idxmax()]\n",
        "        best_continuity = system_avg.loc[system_avg['fragmentations'].idxmin()]\n",
        "\n",
        "        print(f\"\\nBest confidence: {best_confidence['system']} ({best_confidence['avg_confidence']:.3f})\")\n",
        "        print(f\"Most tracks: {best_tracks['system']} ({best_tracks['unique_tracks']:.0f} avg tracks)\")\n",
        "        print(f\"Best continuity: {best_continuity['system']} ({best_continuity['fragmentations']:.0f} total fragmentations)\")\n",
        "\n",
        "print_status(\"Evaluation complete!\", \"SUCCESS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsnEjpBL8Ilc"
      },
      "outputs": [],
      "source": [
        "# ===================== DEBUG EAGLE OUTPUT FOR ONE CLIP ===================== #\n",
        "\n",
        "from pathlib import Path\n",
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "# --- Configure which match + clip to inspect ---\n",
        "MATCH_NAME = \"FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720\"\n",
        "CLIP_ID = \"2\"   # e.g. \"1\", \"2\", \"3\", ...\n",
        "\n",
        "BASE_OUTPUT_DIR = Path(\"/content/output\")\n",
        "eagle_json = BASE_OUTPUT_DIR / MATCH_NAME / \"clips\" / CLIP_ID / \"eagle\" / \"eagle_output.json\"\n",
        "\n",
        "print(\"=== PATH CHECK ===\")\n",
        "print(\"Eagle JSON path:\", eagle_json)\n",
        "print(\"Exists:\", eagle_json.exists())\n",
        "if not eagle_json.exists():\n",
        "    raise FileNotFoundError(eagle_json)\n",
        "\n",
        "# --- Inspect raw JSON structure ------------------------------------------- #\n",
        "with eagle_json.open(\"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(\"\\n=== RAW JSON STRUCTURE ===\")\n",
        "print(\"Top-level type:\", type(data))\n",
        "\n",
        "if isinstance(data, dict):\n",
        "    # Expect raw_coordinates.json style: {\"0\": {...}, \"1\": {...}, ...}\n",
        "    keys = list(data.keys())\n",
        "    print(\"Number of top-level keys (frames):\", len(keys))\n",
        "    print(\"First 10 keys:\", keys[:10])\n",
        "\n",
        "    frame_ids = []\n",
        "    det_per_frame = []\n",
        "    for frame_str, frame_data in data.items():\n",
        "        frame_id = int(frame_str)\n",
        "        frame_ids.append(frame_id)\n",
        "\n",
        "        coords = frame_data.get(\"Coordinates\", {})\n",
        "        n_players = len(coords.get(\"Player\", {}))\n",
        "        n_gks = len(coords.get(\"Goalkeeper\", {}))\n",
        "        det_per_frame.append(n_players + n_gks)\n",
        "\n",
        "    print(\"Frame id range:\", min(frame_ids), \"to\", max(frame_ids))\n",
        "    print(\"Detections per frame: min =\", min(det_per_frame),\n",
        "          \"max =\", max(det_per_frame),\n",
        "          \"mean =\", sum(det_per_frame) / len(det_per_frame))\n",
        "\n",
        "elif isinstance(data, list):\n",
        "    print(\"List length:\", len(data))\n",
        "    if data and isinstance(data[0], dict) and \"frame_id\" in data[0]:\n",
        "        # Our tracking format: [{\"frame_id\": ..., \"track_id\": ..., ...}, ...]\n",
        "        frame_ids = [d[\"frame_id\"] for d in data]\n",
        "        counts = Counter(frame_ids)\n",
        "        print(\"Number of distinct frame_ids:\", len(counts))\n",
        "        print(\"First 10 (frame_id: count):\", list(counts.items())[:10])\n",
        "\n",
        "print(\"\\n=== LOADER VIEW (UniversalLoader.load_eagle) ===\")\n",
        "try:\n",
        "    loader = UniversalLoader()\n",
        "except NameError:\n",
        "    raise RuntimeError(\"UniversalLoader is not defined. Run the evaluation cell first.\")\n",
        "\n",
        "system_data = loader.load_eagle(eagle_json)\n",
        "system_data.clip_name = f\"{MATCH_NAME}_clip_{CLIP_ID}\"\n",
        "\n",
        "print(\"System name:\", system_data.name)\n",
        "print(\"Number of frame entries in system_data.frames:\", len(system_data.frames))\n",
        "\n",
        "if system_data.frames:\n",
        "    frame_ids_loaded = sorted(system_data.frames.keys())\n",
        "    print(\"First 10 frame ids in loader:\", frame_ids_loaded[:10])\n",
        "\n",
        "    total_dets = sum(len(v) for v in system_data.frames.values())\n",
        "    print(\"Total detections (loader):\", total_dets)\n",
        "\n",
        "    unique_tracks = sorted({d.track_id for lst in system_data.frames.values() for d in lst})\n",
        "    print(\"Number of unique tracks:\", len(unique_tracks))\n",
        "    print(\"Sample of track_ids:\", unique_tracks[:20])\n",
        "\n",
        "print(\"\\n=== EVALUATOR METRICS FOR THIS CLIP (EAGLE ONLY) ===\")\n",
        "try:\n",
        "    evaluator = TrackingEvaluator()\n",
        "    metrics = evaluator.evaluate_system(system_data)\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "except NameError:\n",
        "    print(\"TrackingEvaluator not defined. Run the evaluation cell first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download"
      },
      "outputs": [],
      "source": [
        "# Cell 9: Download results\n",
        "\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "print_status(\"Creating archive...\", \"INFO\")\n",
        "\n",
        "archive_name = \"tracking_results\"\n",
        "archive_path = BASE_DIR / archive_name\n",
        "\n",
        "shutil.make_archive(str(archive_path), 'zip', OUTPUT_DIR)\n",
        "\n",
        "print_status(\"Downloading...\", \"SUCCESS\")\n",
        "files.download(f\"{archive_path}.zip\")\n",
        "\n",
        "print_status(\"Complete!\", \"SUCCESS\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}