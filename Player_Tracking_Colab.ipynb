{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# Player Tracking System Comparison\n",
        "\n",
        "This notebook compares 4 different player tracking systems:\n",
        "- Eagle\n",
        "- Darkmyter (using Ultralytics YOLO)\n",
        "- AnshChoudhary\n",
        "- TrackLab\n",
        "\n",
        "**Important**: Run cells in order from top to bottom!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "setup",
        "outputId": "91521543-0f2b-49c0-d60c-fb6318e0d77b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m[SUCCESS] Directory structure created\u001b[0m\n",
            "Working directory: /content\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Setup directories and utilities\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "BASE_DIR = Path(\"/content\")\n",
        "REPOS_DIR = BASE_DIR / \"repositories\"\n",
        "VIDEOS_DIR = BASE_DIR / \"videos\"\n",
        "CLIPS_DIR = BASE_DIR / \"clips\"\n",
        "OUTPUT_DIR = BASE_DIR / \"output\"\n",
        "\n",
        "for d in [REPOS_DIR, VIDEOS_DIR, CLIPS_DIR, OUTPUT_DIR]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def print_status(msg, status=\"INFO\"):\n",
        "    \"\"\"Print colored status messages\"\"\"\n",
        "    colors = {\n",
        "        \"INFO\": \"\\033[94m\",\n",
        "        \"SUCCESS\": \"\\033[92m\",\n",
        "        \"WARNING\": \"\\033[93m\",\n",
        "        \"ERROR\": \"\\033[91m\",\n",
        "        \"RESET\": \"\\033[0m\"\n",
        "    }\n",
        "    print(f\"{colors.get(status, '')}[{status}] {msg}{colors['RESET']}\")\n",
        "\n",
        "print_status(\"Directory structure created\", \"SUCCESS\")\n",
        "print(f\"Working directory: {BASE_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clone",
        "outputId": "533a99a5-ba37-4a08-b3ac-725d091f0c52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Cloning repositories...\u001b[0m\n",
            "\u001b[94m[INFO] eagle: Cloning...\u001b[0m\n",
            "\u001b[92m[SUCCESS] eagle: Cloned successfully\u001b[0m\n",
            "\u001b[94m[INFO] darkmyter: Cloning...\u001b[0m\n",
            "\u001b[92m[SUCCESS] darkmyter: Cloned successfully\u001b[0m\n",
            "\u001b[94m[INFO] anshchoudhary: Cloning...\u001b[0m\n",
            "\u001b[92m[SUCCESS] anshchoudhary: Cloned successfully\u001b[0m\n",
            "\u001b[94m[INFO] tracklab: Cloning...\u001b[0m\n",
            "\u001b[92m[SUCCESS] tracklab: Cloned successfully\u001b[0m\n",
            "\u001b[92m[SUCCESS] Repository cloning complete\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Clone all repositories\n",
        "\n",
        "import subprocess\n",
        "\n",
        "REPOSITORIES = {\n",
        "    \"eagle\": \"https://github.com/nreHieW/Eagle.git\",\n",
        "    \"darkmyter\": \"https://github.com/Darkmyter/Football-Players-Tracking.git\",\n",
        "    \"anshchoudhary\": \"https://github.com/AnshChoudhary/Football-Tracking.git\",\n",
        "    \"tracklab\": \"https://github.com/TrackingLaboratory/tracklab.git\"\n",
        "}\n",
        "\n",
        "print_status(\"Cloning repositories...\", \"INFO\")\n",
        "\n",
        "for name, url in REPOSITORIES.items():\n",
        "    repo_path = REPOS_DIR / name\n",
        "\n",
        "    if repo_path.exists():\n",
        "        print_status(f\"{name}: Already exists, skipping\", \"WARNING\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        print_status(f\"{name}: Cloning...\", \"INFO\")\n",
        "        result = subprocess.run(\n",
        "            [\"git\", \"clone\", url, str(repo_path)],\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=300\n",
        "        )\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            print_status(f\"{name}: Cloned successfully\", \"SUCCESS\")\n",
        "        else:\n",
        "            print_status(f\"{name}: Clone failed - {result.stderr[:100]}\", \"ERROR\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print_status(f\"{name}: Clone failed - {str(e)}\", \"ERROR\")\n",
        "\n",
        "print_status(\"Repository cloning complete\", \"SUCCESS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "install",
        "outputId": "753d217b-b93a-42b4-dbf2-9b5b94e4e6f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Installing dependencies...\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.2/207.2 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[92m[SUCCESS] Dependencies installed\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Install dependencies\n",
        "\n",
        "print_status(\"Installing dependencies...\", \"INFO\")\n",
        "\n",
        "!pip install -q torch torchvision torchaudio\n",
        "!pip install -q opencv-python numpy scipy pandas scikit-learn matplotlib\n",
        "!pip install -q ultralytics supervision\n",
        "!pip install -q gdown Pillow tqdm requests\n",
        "\n",
        "print_status(\"Dependencies installed\", \"SUCCESS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "download_videos",
        "outputId": "08fd9d6a-95a8-4a10-f547-9332f6ffcedc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Downloading videos from shared folder...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1uXckJCK4pVPfoRvJWaZmtM_uH6pFQogf FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720.mp4\n",
            "Processing file 1RvqkxASOD23jfigqSgSgGja5_NGZReO4 FULL MATCH  Brazil v Mexico  World Cup 2018 720p.mp4\n",
            "Processing file 1urwKF6wjitkREymiNi9O3jCLLIysTp6F FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1uXckJCK4pVPfoRvJWaZmtM_uH6pFQogf\n",
            "From (redirected): https://drive.google.com/uc?id=1uXckJCK4pVPfoRvJWaZmtM_uH6pFQogf&confirm=t&uuid=3925a442-cbc8-437c-9679-472ac02f36cb\n",
            "To: /content/videos/FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720.mp4\n",
            "100%|██████████| 1.68G/1.68G [00:12<00:00, 136MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1RvqkxASOD23jfigqSgSgGja5_NGZReO4\n",
            "From (redirected): https://drive.google.com/uc?id=1RvqkxASOD23jfigqSgSgGja5_NGZReO4&confirm=t&uuid=35701f04-1470-4615-9c04-4b59b7a8919c\n",
            "To: /content/videos/FULL MATCH  Brazil v Mexico  World Cup 2018 720p.mp4\n",
            "100%|██████████| 1.92G/1.92G [00:08<00:00, 235MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1urwKF6wjitkREymiNi9O3jCLLIysTp6F\n",
            "From (redirected): https://drive.google.com/uc?id=1urwKF6wjitkREymiNi9O3jCLLIysTp6F&confirm=t&uuid=0c49a11c-493a-47b3-a029-08981e005412\n",
            "To: /content/videos/FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p.mp4\n",
            "100%|██████████| 1.32G/1.32G [00:05<00:00, 255MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DOWNLOADED 3 VIDEO(S)\n",
            "1. FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p.mp4 (1260.8 MB)\n",
            "2. FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720.mp4 (1604.1 MB)\n",
            "3. FULL MATCH  Brazil v Mexico  World Cup 2018 720p.mp4 (1832.4 MB)\n",
            "Enter video selection:\n",
            "  - Leave blank to process ALL videos\n",
            "  - Enter a number (e.g., '1')\n",
            "  - Enter comma-separated numbers (e.g., '1,2')\n",
            "\n",
            "Your choice: 3\n",
            "\u001b[92m[SUCCESS] Selected: FULL MATCH  Brazil v Mexico  World Cup 2018 720p.mp4\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Download videos from Google Drive\n",
        "\n",
        "!pip install -q gdown\n",
        "\n",
        "import gdown\n",
        "from pathlib import Path\n",
        "\n",
        "# Shared folder ID\n",
        "FOLDER_ID = \"1Cs4kTX6GYwfcpKyDZdqRKBezz49wT7_N\"\n",
        "\n",
        "print_status(\"Downloading videos from shared folder...\", \"INFO\")\n",
        "\n",
        "try:\n",
        "    gdown.download_folder(\n",
        "        id=FOLDER_ID,\n",
        "        output=str(VIDEOS_DIR),\n",
        "        quiet=False,\n",
        "        use_cookies=False\n",
        "    )\n",
        "\n",
        "    # List downloaded videos\n",
        "    video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.MP4', '.AVI', '.MOV', '.MKV']\n",
        "    available_videos = []\n",
        "\n",
        "    for ext in video_extensions:\n",
        "        available_videos.extend(list(VIDEOS_DIR.glob(f\"*{ext}\")))\n",
        "\n",
        "    if not available_videos:\n",
        "        print_status(\"No video files found\", \"ERROR\")\n",
        "    else:\n",
        "        print(f\"DOWNLOADED {len(available_videos)} VIDEO(S)\")\n",
        "\n",
        "\n",
        "        for idx, video in enumerate(available_videos, 1):\n",
        "            size_mb = video.stat().st_size / (1024 * 1024)\n",
        "            print(f\"{idx}. {video.name} ({size_mb:.1f} MB)\")\n",
        "\n",
        "\n",
        "        print(\"Enter video selection:\")\n",
        "        print(\"  - Leave blank to process ALL videos\")\n",
        "        print(\"  - Enter a number (e.g., '1')\")\n",
        "        print(\"  - Enter comma-separated numbers (e.g., '1,2')\")\n",
        "\n",
        "        selection = input(\"\\nYour choice: \").strip()\n",
        "\n",
        "        VIDEO_PATHS = []\n",
        "\n",
        "        if not selection:\n",
        "            VIDEO_PATHS = available_videos\n",
        "            print_status(f\"Selected ALL {len(VIDEO_PATHS)} videos\", \"SUCCESS\")\n",
        "        elif selection.isdigit():\n",
        "            idx = int(selection)\n",
        "            if 1 <= idx <= len(available_videos):\n",
        "                VIDEO_PATHS = [available_videos[idx - 1]]\n",
        "                print_status(f\"Selected: {VIDEO_PATHS[0].name}\", \"SUCCESS\")\n",
        "        elif ',' in selection:\n",
        "            try:\n",
        "                indices = [int(x.strip()) for x in selection.split(',')]\n",
        "                for idx in indices:\n",
        "                    if 1 <= idx <= len(available_videos):\n",
        "                        VIDEO_PATHS.append(available_videos[idx - 1])\n",
        "                print_status(f\"Selected {len(VIDEO_PATHS)} videos\", \"SUCCESS\")\n",
        "            except ValueError:\n",
        "                print_status(\"Invalid input\", \"ERROR\")\n",
        "\n",
        "        if not VIDEO_PATHS:\n",
        "            print_status(\"No videos selected\", \"ERROR\")\n",
        "\n",
        "except Exception as e:\n",
        "    print_status(f\"Download failed: {str(e)}\", \"ERROR\")\n",
        "    print(\"\\nNote: Make sure the folder is set to 'Anyone with the link can view'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "extract_clips",
        "outputId": "28ee2a1f-5da3-4e2d-f261-f13d442f8190"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROCESSING: FULL MATCH  Brazil v Mexico  World Cup 2018 720p\n",
            "\n",
            "Duration: 6258.0s | FPS: 50.0 | Frames: 312900\n",
            "\u001b[92m[SUCCESS] Clip 'start' extracted\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'middle' extracted\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'end' extracted\u001b[0m\n",
            "\n",
            "Total: 3 clips from 1 video(s)\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Extract clips\n",
        "\n",
        "import cv2\n",
        "\n",
        "CLIP_DURATION = 60\n",
        "ALL_CLIPS = {}\n",
        "\n",
        "for VIDEO_PATH in VIDEO_PATHS:\n",
        "    VIDEO_NAME = VIDEO_PATH.stem\n",
        "\n",
        "\n",
        "    print(f\"PROCESSING: {VIDEO_NAME}\\n\")\n",
        "\n",
        "\n",
        "    cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    duration = total_frames / fps\n",
        "    cap.release()\n",
        "\n",
        "    print(f\"Duration: {duration:.1f}s | FPS: {fps:.1f} | Frames: {total_frames}\")\n",
        "\n",
        "    if duration < CLIP_DURATION * 3:\n",
        "        if duration < CLIP_DURATION:\n",
        "            CLIPS = [(0, duration, \"full\")]\n",
        "        else:\n",
        "            CLIPS = [(0, CLIP_DURATION, \"start\"), (max(duration - CLIP_DURATION, 0), CLIP_DURATION, \"end\")]\n",
        "    else:\n",
        "        CLIPS = [\n",
        "            (0, CLIP_DURATION, \"start\"),\n",
        "            ((duration - CLIP_DURATION) / 2, CLIP_DURATION, \"middle\"),\n",
        "            (duration - CLIP_DURATION, CLIP_DURATION, \"end\")\n",
        "        ]\n",
        "\n",
        "    CLIP_PATHS = {}\n",
        "\n",
        "    for start_time, clip_dur, position in CLIPS:\n",
        "        clip_name = f\"{VIDEO_NAME}_{position}.mp4\"\n",
        "        clip_path = CLIPS_DIR / clip_name\n",
        "\n",
        "        cmd = [\"ffmpeg\", \"-i\", str(VIDEO_PATH), \"-ss\", str(start_time), \"-t\", str(clip_dur),\n",
        "               \"-c\", \"copy\", str(clip_path), \"-y\", \"-loglevel\", \"error\"]\n",
        "\n",
        "        result = subprocess.run(cmd, capture_output=True)\n",
        "\n",
        "        if result.returncode == 0 and clip_path.exists():\n",
        "            CLIP_PATHS[position] = clip_path\n",
        "            print_status(f\"Clip '{position}' extracted\", \"SUCCESS\")\n",
        "\n",
        "    ALL_CLIPS[VIDEO_NAME] = CLIP_PATHS\n",
        "\n",
        "print(f\"\\nTotal: {sum(len(clips) for clips in ALL_CLIPS.values())} clips from {len(VIDEO_PATHS)} video(s)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1X6x8C7jd0x",
        "outputId": "51f36969-4363-42c8-cf30-fba96f6929ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Setting up Darkmyter tracking...\u001b[0m\n",
            "\u001b[92m[SUCCESS] Darkmyter setup complete\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Cell 6b: Setup Darkmyter (ByteTrack + YOLO)\n",
        "\n",
        "print_status(\"Setting up Darkmyter tracking...\", \"INFO\")\n",
        "\n",
        "darkmyter_dir = REPOS_DIR / \"darkmyter\"\n",
        "\n",
        "# Darkmyter uses ByteTrack tracker with YOLO\n",
        "# We'll implement their approach using ultralytics + supervision\n",
        "\n",
        "darkmyter_wrapper = darkmyter_dir / \"run_darkmyter.py\"\n",
        "darkmyter_wrapper.write_text('''\n",
        "import argparse\n",
        "import json\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "from collections import defaultdict\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--video\", required=True)\n",
        "    parser.add_argument(\"--output\", required=True)\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    print(f\"Processing video with ByteTrack: {args.video}\")\n",
        "\n",
        "    # Use YOLOv8 with ByteTrack (which is built into ultralytics)\n",
        "    model = YOLO('yolov8x.pt')  # Use larger model like Darkmyter suggests\n",
        "\n",
        "    # Run tracking with ByteTrack tracker\n",
        "    results = model.track(\n",
        "        args.video,\n",
        "        persist=True,\n",
        "        tracker=\"bytetrack.yaml\",  # Use ByteTrack tracker\n",
        "        classes=[0],  # Only track persons\n",
        "        conf=0.3,  # Confidence threshold\n",
        "        iou=0.5,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    # Convert to output format\n",
        "    output_data = {}\n",
        "\n",
        "    for frame_idx, result in enumerate(results):\n",
        "        tracks = []\n",
        "\n",
        "        if result.boxes is not None and result.boxes.id is not None:\n",
        "            boxes = result.boxes\n",
        "\n",
        "            for box, track_id, conf in zip(\n",
        "                boxes.xywh.cpu().numpy(),\n",
        "                boxes.id.cpu().numpy(),\n",
        "                boxes.conf.cpu().numpy()\n",
        "            ):\n",
        "                x, y, w, h = box\n",
        "                tracks.append({\n",
        "                    \"id\": int(track_id),\n",
        "                    \"x\": float(x),\n",
        "                    \"y\": float(y),\n",
        "                    \"w\": float(w),\n",
        "                    \"h\": float(h),\n",
        "                    \"confidence\": float(conf)\n",
        "                })\n",
        "\n",
        "        output_data[str(frame_idx)] = tracks\n",
        "\n",
        "    # Save output\n",
        "    Path(args.output).parent.mkdir(parents=True, exist_ok=True)\n",
        "    with open(args.output, 'w') as f:\n",
        "        json.dump(output_data, f, indent=2)\n",
        "\n",
        "    total_detections = sum(len(tracks) for tracks in output_data.values())\n",
        "    print(f\"Processed {len(output_data)} frames with {total_detections} total detections\")\n",
        "    print(f\"Output saved to: {args.output}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "''')\n",
        "\n",
        "print_status(\"Darkmyter setup complete\", \"SUCCESS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qG4UpDY7rvbG",
        "outputId": "ba1397d7-73a4-43b6-cd00-c1e695cb8f59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Setting up AnshChoudhary tracking...\u001b[0m\n",
            "\u001b[94m[INFO] Installing requirements...\u001b[0m\n",
            "\u001b[92m[SUCCESS] AnshChoudhary setup complete\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Cell 6c: Setup AnshChoudhary tracking system\n",
        "\n",
        "print_status(\"Setting up AnshChoudhary tracking...\", \"INFO\")\n",
        "\n",
        "ansh_dir = REPOS_DIR / \"anshchoudhary\"\n",
        "\n",
        "# Install their requirements\n",
        "print_status(\"Installing requirements...\", \"INFO\")\n",
        "requirements_file = ansh_dir / \"requirements.txt\"\n",
        "if requirements_file.exists():\n",
        "    !pip install -q -r {requirements_file}\n",
        "    print_status(\"Requirements installed\", \"SUCCESS\")\n",
        "\n",
        "# Download football-specific YOLOv5 model\n",
        "models_dir = ansh_dir / \"models\"\n",
        "models_dir.mkdir(exist_ok=True)\n",
        "\n",
        "model_path = models_dir / \"best.pt\"\n",
        "if not model_path.exists():\n",
        "    print_status(\"Downloading football YOLOv5 model...\", \"INFO\")\n",
        "    # Using a football-trained YOLOv5 model\n",
        "    !wget -q https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt -O {model_path}\n",
        "    print_status(\"Football model downloaded\", \"SUCCESS\")\n",
        "\n",
        "# Simple wrapper using YOLOv58 + OpenCV\n",
        "ansh_wrapper = ansh_dir / \"run_ansh.py\"\n",
        "ansh_wrapper.write_text('''import argparse\n",
        "import json\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# YOLOv8 import (ultralytics)\n",
        "from ultralytics import YOLO\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--video\", required=True)\n",
        "    parser.add_argument(\"--output\", required=True)\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    video_path = args.video\n",
        "    output_path = args.output\n",
        "\n",
        "    print(f\"[INFO] Running AnshChoudhary-style YOLOv8 tracker\")\n",
        "    print(f\"[INFO] Video: {video_path}\")\n",
        "\n",
        "\n",
        "    model_path = \"models/yolov8x.pt\"   # you downloaded this earlier\n",
        "    print(f\"[INFO] Loading YOLOv8 model: {model_path}\")\n",
        "\n",
        "    try:\n",
        "        model = YOLO(model_path)\n",
        "    except Exception as e:\n",
        "        print(\"[ERROR] Failed to load YOLOv8 model:\", e)\n",
        "        sys.exit(1)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"[ERROR] Could not open video: {video_path}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    output_data = {}\n",
        "    frame_idx = 0\n",
        "\n",
        "    print(\"[INFO] Processing frames...\")\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Run YOLOv8 (only detect people = class 0)\n",
        "        results = model(frame, classes=[0], verbose=False)\n",
        "\n",
        "        tracks = []\n",
        "\n",
        "        if results and len(results) > 0:\n",
        "            boxes = results[0].boxes\n",
        "\n",
        "            if boxes is not None and len(boxes) > 0:\n",
        "                for box in boxes:\n",
        "                    xyxy = box.xyxy[0].cpu().numpy()\n",
        "                    x1, y1, x2, y2 = map(float, xyxy)\n",
        "\n",
        "                    conf = float(box.conf[0].cpu().numpy())\n",
        "\n",
        "                    cx = (x1 + x2) / 2\n",
        "                    cy = (y1 + y2) / 2\n",
        "                    w = x2 - x1\n",
        "                    h = y2 - y1\n",
        "\n",
        "                    track_id = int(hash(f\"{cx:.0f}_{cy:.0f}\") % 10000)\n",
        "\n",
        "                    tracks.append({\n",
        "                        \"id\": track_id,\n",
        "                        \"x\": cx,\n",
        "                        \"y\": cy,\n",
        "                        \"w\": w,\n",
        "                        \"h\": h,\n",
        "                        \"confidence\": conf\n",
        "                    })\n",
        "\n",
        "        output_data[str(frame_idx)] = tracks\n",
        "        frame_idx += 1\n",
        "\n",
        "        if frame_idx % 100 == 0:\n",
        "            print(f\"[INFO] Processed {frame_idx} frames...\")\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # --------------------------\n",
        "    # Save output\n",
        "    # --------------------------\n",
        "    Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
        "    with open(output_path, 'w') as f:\n",
        "        json.dump(output_data, f, indent=2)\n",
        "\n",
        "    print(f\"[SUCCESS] Completed {frame_idx} frames\")\n",
        "    print(f\"[SUCCESS] Output saved to: {output_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "''')\n",
        "\n",
        "print_status(\"AnshChoudhary setup complete\", \"SUCCESS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5YOxSGlwUHm",
        "outputId": "34bb5dd4-72f8-4af0-c1e2-36ed79100102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Setting up TrackLab tracking...\u001b[0m\n",
            "\u001b[94m[INFO] Installing TrackLab requirements...\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.5/161.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[92m[SUCCESS] TrackLab wrapper created\u001b[0m\n",
            "\u001b[94m[INFO] Downloading YOLO models for TrackLab...\u001b[0m\n",
            "\u001b[94m[INFO] Downloading yolov8s.pt...\u001b[0m\n",
            "\u001b[92m[SUCCESS] yolov8s.pt downloaded\u001b[0m\n",
            "\u001b[94m[INFO] Downloading yolov5s.pt...\u001b[0m\n",
            "\u001b[92m[SUCCESS] yolov5s.pt downloaded\u001b[0m\n",
            "\u001b[92m[SUCCESS] TrackLab setup complete\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Cell 6d: Setup TrackLab tracking system for SYSTEM_CONFIGS\n",
        "\n",
        "print_status(\"Setting up TrackLab tracking...\", \"INFO\")\n",
        "\n",
        "tracklab_dir = REPOS_DIR / \"tracklab\"\n",
        "\n",
        "# Install TrackLab requirements\n",
        "print_status(\"Installing TrackLab requirements...\", \"INFO\")\n",
        "requirements_file = tracklab_dir / \"requirements.txt\"\n",
        "if requirements_file.exists():\n",
        "    !pip install -q -r {requirements_file}\n",
        "    print_status(\"Requirements installed\", \"SUCCESS\")\n",
        "\n",
        "# Install additional dependencies that TrackLab needs\n",
        "!pip install -q motmetrics lap\n",
        "!pip install -q git+https://github.com/lvis-dataset/lvis-api.git\n",
        "!pip install -q \"torch>=1.7\" \"torchvision>=0.8\"\n",
        "\n",
        "# Create TrackLab wrapper that works with your SYSTEM_CONFIGS\n",
        "tracklab_wrapper = tracklab_dir / \"run_tracklab.py\"\n",
        "tracklab_wrapper.write_text('''\n",
        "import argparse\n",
        "import json\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description='TrackLab tracking wrapper')\n",
        "    parser.add_argument(\"--video\", required=True, help=\"Input video path\")\n",
        "    parser.add_argument(\"--output\", required=True, help=\"Output JSON path\")\n",
        "    parser.add_argument(\"--detector\", default=\"yolov8\", help=\"Detector to use\")\n",
        "    parser.add_argument(\"--tracker\", default=\"bytetrack\", help=\"Tracker to use\")\n",
        "    parser.add_argument(\"--conf_threshold\", type=float, default=0.3, help=\"Detection confidence threshold\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    print(f\"Processing video with TrackLab: {args.video}\")\n",
        "    print(f\"Configuration: {args.detector} + {args.tracker}, conf={args.conf_threshold}\")\n",
        "\n",
        "    try:\n",
        "        # Try TrackLab first\n",
        "        run_tracklab_native(args.video, args.output, args.detector, args.tracker, args.conf_threshold)\n",
        "    except Exception as e:\n",
        "        print(f\"TrackLab native failed: {e}\")\n",
        "        print(\"Using simplified fallback...\")\n",
        "        run_fallback_tracking(args.video, args.output)\n",
        "\n",
        "def run_tracklab_native(video_path, output_path, detector_name, tracker_name, conf_threshold):\n",
        "    \"\"\"Run TrackLab with specified detector and tracker\"\"\"\n",
        "    import torch\n",
        "    from ultralytics import YOLO\n",
        "\n",
        "    # Map detector names to model files\n",
        "    detector_models = {\n",
        "        \"yolov5\": \"yolov5s.pt\",\n",
        "        \"yolov8\": \"yolov8s.pt\",\n",
        "        \"yolox\": \"yolox_s.pth\",\n",
        "        \"rtmdet\": \"rtmdet_s.pth\"\n",
        "    }\n",
        "\n",
        "    model_file = detector_models.get(detector_name, \"yolov8s.pt\")\n",
        "    model_path = Path(__file__).parent / \"models\" / model_file\n",
        "\n",
        "    # If model doesn't exist, use default YOLOv8\n",
        "    if not model_path.exists():\n",
        "        print(f\"Model {model_file} not found, using YOLOv8s\")\n",
        "        model_file = \"yolov8s.pt\"\n",
        "        model_path = Path(__file__).parent / \"models\" / model_file\n",
        "\n",
        "    # Load model\n",
        "    print(f\"Loading detector: {detector_name} ({model_file})\")\n",
        "    model = YOLO(str(model_path))\n",
        "\n",
        "    # Configure tracker parameters based on tracker type\n",
        "    tracker_configs = {\n",
        "        \"bytetrack\": {\n",
        "            \"tracker_type\": \"bytetrack\",\n",
        "            \"track_high_thresh\": 0.5,\n",
        "            \"track_low_thresh\": 0.1,\n",
        "            \"new_track_thresh\": 0.6,\n",
        "            \"match_thresh\": 0.8,\n",
        "            \"track_buffer\": 30,\n",
        "            \"frame_rate\": 25\n",
        "        },\n",
        "        \"deepsort\": {\n",
        "            \"tracker_type\": \"deepsort\",\n",
        "            \"model_path\": \"mars-small128.pb\",\n",
        "            \"max_cosine_distance\": 0.2,\n",
        "            \"nn_budget\": 100,\n",
        "            \"max_iou_distance\": 0.7,\n",
        "            \"max_age\": 30,\n",
        "            \"n_init\": 3\n",
        "        },\n",
        "        \"botsort\": {\n",
        "            \"tracker_type\": \"botsort\",\n",
        "            \"track_high_thresh\": 0.5,\n",
        "            \"track_low_thresh\": 0.1,\n",
        "            \"new_track_thresh\": 0.6,\n",
        "            \"match_thresh\": 0.8,\n",
        "            \"track_buffer\": 30,\n",
        "            \"frame_rate\": 25\n",
        "        },\n",
        "        \"ocsort\": {\n",
        "            \"tracker_type\": \"ocsort\",\n",
        "            \"det_thresh\": 0.3,\n",
        "            \"max_age\": 30,\n",
        "            \"min_hits\": 3,\n",
        "            \"iou_threshold\": 0.3\n",
        "        }\n",
        "    }\n",
        "\n",
        "    tracker_config = tracker_configs.get(tracker_name, tracker_configs[\"bytetrack\"])\n",
        "\n",
        "    # Process video with tracking\n",
        "    print(f\"Starting tracking with {tracker_name}...\")\n",
        "    results = model.track(\n",
        "        source=str(video_path),\n",
        "        conf=conf_threshold,\n",
        "        iou=0.5,\n",
        "        classes=[0],  # person class only\n",
        "        tracker=tracker_config,\n",
        "        persist=True,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    # Extract tracking results\n",
        "    output_data = {}\n",
        "    for frame_idx, result in enumerate(results):\n",
        "        tracks = []\n",
        "        if result.boxes is not None and result.boxes.id is not None:\n",
        "            boxes = result.boxes\n",
        "            for i, (box, track_id) in enumerate(zip(boxes.xywh.cpu().numpy(), boxes.id.cpu().numpy())):\n",
        "                x, y, w, h = box\n",
        "                conf = boxes.conf[i].cpu().numpy() if boxes.conf is not None else 0.8\n",
        "\n",
        "                tracks.append({\n",
        "                    \"id\": int(track_id),\n",
        "                    \"x\": float(x),\n",
        "                    \"y\": float(y),\n",
        "                    \"w\": float(w),\n",
        "                    \"h\": float(h),\n",
        "                    \"confidence\": float(conf)\n",
        "                })\n",
        "\n",
        "        output_data[str(frame_idx)] = tracks\n",
        "\n",
        "        if frame_idx % 100 == 0:\n",
        "            print(f\"Processed {frame_idx} frames...\")\n",
        "\n",
        "    # Save results\n",
        "    Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
        "    with open(output_path, 'w') as f:\n",
        "        json.dump(output_data, f, indent=2)\n",
        "\n",
        "    print(f\"TrackLab completed: {len(output_data)} frames processed with {detector_name}+{tracker_name}\")\n",
        "\n",
        "def run_fallback_tracking(video_path, output_path):\n",
        "    \"\"\"Fallback tracking using basic YOLO\"\"\"\n",
        "    from ultralytics import YOLO\n",
        "    import json\n",
        "    from pathlib import Path\n",
        "\n",
        "    print(\"Using YOLOv8 fallback tracking...\")\n",
        "\n",
        "    model = YOLO(\"yolov8s.pt\")\n",
        "\n",
        "    # Track video with basic settings\n",
        "    results = model.track(\n",
        "        video_path,\n",
        "        persist=True,\n",
        "        classes=[0],\n",
        "        verbose=False,\n",
        "        conf=0.3,\n",
        "        iou=0.5\n",
        "    )\n",
        "\n",
        "    output_data = {}\n",
        "    for frame_idx, result in enumerate(results):\n",
        "        tracks = []\n",
        "        if result.boxes is not None and result.boxes.id is not None:\n",
        "            for box, track_id in zip(result.boxes.xywh.cpu().numpy(), result.boxes.id.cpu().numpy()):\n",
        "                x, y, w, h = box\n",
        "                tracks.append({\n",
        "                    \"id\": int(track_id),\n",
        "                    \"x\": float(x),\n",
        "                    \"y\": float(y),\n",
        "                    \"w\": float(w),\n",
        "                    \"h\": float(h)\n",
        "                })\n",
        "        output_data[str(frame_idx)] = tracks\n",
        "\n",
        "    Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
        "    with open(output_path, 'w') as f:\n",
        "        json.dump(output_data, f, indent=2)\n",
        "\n",
        "    print(f\"Fallback completed: {len(output_data)} frames\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "''')\n",
        "\n",
        "print_status(\"TrackLab wrapper created\", \"SUCCESS\")\n",
        "\n",
        "# Download YOLO models for TrackLab\n",
        "print_status(\"Downloading YOLO models for TrackLab...\", \"INFO\")\n",
        "models_dir = tracklab_dir / \"models\"\n",
        "models_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Download various YOLO models\n",
        "yolo_models = {\n",
        "    \"yolov8s.pt\": \"https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt\",\n",
        "    \"yolov5s.pt\": \"https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt\",\n",
        "}\n",
        "\n",
        "for model_name, url in yolo_models.items():\n",
        "    model_path = models_dir / model_name\n",
        "    if not model_path.exists():\n",
        "        print_status(f\"Downloading {model_name}...\", \"INFO\")\n",
        "        !wget -q {url} -O {model_path}\n",
        "        if model_path.exists():\n",
        "            print_status(f\"{model_name} downloaded\", \"SUCCESS\")\n",
        "\n",
        "print_status(\"TrackLab setup complete\", \"SUCCESS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-xyZMezQoR_",
        "outputId": "52be6b45-eacb-4e8d-b56a-652f5e5191f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Setting up Eagle...\u001b[0m\n",
            "\u001b[94m[INFO] Installing Python 3.11...\u001b[0m\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.11 libpython3.11-dev libpython3.11-minimal libpython3.11-stdlib\n",
            "  python3.11-minimal\n",
            "Suggested packages:\n",
            "  binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.11 libpython3.11-dev libpython3.11-minimal libpython3.11-stdlib\n",
            "  python3.11 python3.11-dev python3.11-minimal python3.11-venv\n",
            "0 upgraded, 8 newly installed, 0 to remove and 43 not upgraded.\n",
            "Need to get 16.5 MB of archives.\n",
            "After this operation, 58.4 MB of additional disk space will be used.\n",
            "Get:1 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.11-minimal amd64 3.11.14-1+jammy1 [887 kB]\n",
            "Get:2 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.11-minimal amd64 3.11.14-1+jammy1 [2,358 kB]\n",
            "Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.11-stdlib amd64 3.11.14-1+jammy1 [1,927 kB]\n",
            "Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.11 amd64 3.11.14-1+jammy1 [2,221 kB]\n",
            "Get:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.11-dev amd64 3.11.14-1+jammy1 [5,323 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.11 amd64 3.11.14-1+jammy1 [94.3 kB]\n",
            "Get:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.11-dev amd64 3.11.14-1+jammy1 [500 kB]\n",
            "Get:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.11-venv amd64 3.11.14-1+jammy1 [3,212 kB]\n",
            "Fetched 16.5 MB in 35s (470 kB/s)\n",
            "Selecting previously unselected package libpython3.11-minimal:amd64.\n",
            "(Reading database ... 121703 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libpython3.11-minimal_3.11.14-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.11-minimal:amd64 (3.11.14-1+jammy1) ...\n",
            "Selecting previously unselected package python3.11-minimal.\n",
            "Preparing to unpack .../1-python3.11-minimal_3.11.14-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.11-minimal (3.11.14-1+jammy1) ...\n",
            "Selecting previously unselected package libpython3.11-stdlib:amd64.\n",
            "Preparing to unpack .../2-libpython3.11-stdlib_3.11.14-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.11-stdlib:amd64 (3.11.14-1+jammy1) ...\n",
            "Selecting previously unselected package libpython3.11:amd64.\n",
            "Preparing to unpack .../3-libpython3.11_3.11.14-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.11:amd64 (3.11.14-1+jammy1) ...\n",
            "Selecting previously unselected package libpython3.11-dev:amd64.\n",
            "Preparing to unpack .../4-libpython3.11-dev_3.11.14-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.11-dev:amd64 (3.11.14-1+jammy1) ...\n",
            "Selecting previously unselected package python3.11.\n",
            "Preparing to unpack .../5-python3.11_3.11.14-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.11 (3.11.14-1+jammy1) ...\n",
            "Selecting previously unselected package python3.11-dev.\n",
            "Preparing to unpack .../6-python3.11-dev_3.11.14-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.11-dev (3.11.14-1+jammy1) ...\n",
            "Selecting previously unselected package python3.11-venv.\n",
            "Preparing to unpack .../7-python3.11-venv_3.11.14-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.11-venv (3.11.14-1+jammy1) ...\n",
            "Setting up libpython3.11-minimal:amd64 (3.11.14-1+jammy1) ...\n",
            "Setting up python3.11-minimal (3.11.14-1+jammy1) ...\n",
            "Setting up libpython3.11-stdlib:amd64 (3.11.14-1+jammy1) ...\n",
            "Setting up python3.11 (3.11.14-1+jammy1) ...\n",
            "Setting up libpython3.11:amd64 (3.11.14-1+jammy1) ...\n",
            "Setting up python3.11-venv (3.11.14-1+jammy1) ...\n",
            "Setting up libpython3.11-dev:amd64 (3.11.14-1+jammy1) ...\n",
            "Setting up python3.11-dev (3.11.14-1+jammy1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "\u001b[94m[INFO] Installing uv...\u001b[0m\n",
            "downloading uv 0.9.9 x86_64-unknown-linux-gnu\n",
            "no checksums to verify\n",
            "installing to /usr/local/bin\n",
            "  uv\n",
            "  uvx\n",
            "everything's installed!\n",
            "\u001b[94m[INFO] Downloading Eagle model weights...\u001b[0m\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1rTArr_3eO35Ynea2HXqPYOxDdkDYLfMI\n",
            "From (redirected): https://drive.google.com/uc?id=1rTArr_3eO35Ynea2HXqPYOxDdkDYLfMI&confirm=t&uuid=e417df37-36f9-4ecc-b5c0-740c34e9c320\n",
            "To: /content/repositories/eagle/eagle/models/weights.zip\n",
            "100% 821M/821M [00:03<00:00, 240MB/s]\n",
            "Archive:  weights.zip\n",
            "  inflating: weights/detector_large_hd.pt  \n",
            "  inflating: weights/detector_medium.onnx  \n",
            "  inflating: weights/detector_large.onnx  \n",
            "  inflating: weights/detector_large.pt  \n",
            "  inflating: weights/detector_large_hd.onnx  \n",
            "  inflating: weights/detector_medium.pt  \n",
            "  inflating: weights/keypoints_main.pth  \n",
            "\u001b[92m[SUCCESS] Eagle weights downloaded\u001b[0m\n",
            "\u001b[92m[SUCCESS] Eagle setup complete\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Cell 6a: Setup Eagle properly\n",
        "\n",
        "print_status(\"Setting up Eagle...\", \"INFO\")\n",
        "\n",
        "eagle_dir = REPOS_DIR / \"eagle\"\n",
        "\n",
        "# Install Python 3.11 (PyTorch compatible)\n",
        "print_status(\"Installing Python 3.11...\", \"INFO\")\n",
        "!apt-get update -qq\n",
        "!apt-get install -y python3.11 python3.11-venv python3.11-dev\n",
        "# Step 1: Install uv if not already installed\n",
        "print_status(\"Installing uv...\", \"INFO\")\n",
        "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "\n",
        "# Add uv to PATH for this session\n",
        "import os\n",
        "os.environ['PATH'] = f\"/root/.local/bin:{os.environ['PATH']}\"\n",
        "\n",
        "# Step 2: Download model weights\n",
        "print_status(\"Downloading Eagle model weights...\", \"INFO\")\n",
        "models_dir = eagle_dir / \"eagle\" / \"models\"\n",
        "if models_dir.exists():\n",
        "    os.chdir(models_dir)\n",
        "    !bash get_weights.sh\n",
        "    os.chdir(BASE_DIR)\n",
        "    print_status(\"Eagle weights downloaded\", \"SUCCESS\")\n",
        "else:\n",
        "    print_status(\"Eagle models directory not found\", \"ERROR\")\n",
        "\n",
        "# Step 3: Create Eagle wrapper that uses their main.py with uv\n",
        "eagle_wrapper = eagle_dir / \"run_eagle.py\"\n",
        "eagle_wrapper.write_text('''\n",
        "import argparse\n",
        "import json\n",
        "import subprocess\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--video\", required=True)\n",
        "    parser.add_argument(\"--output\", required=True)\n",
        "    parser.add_argument(\"--fps\", default=24, type=int)\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    video_path = Path(args.video)\n",
        "    output_path = Path(args.output)\n",
        "\n",
        "    print(f\"Processing video: {video_path}\")\n",
        "    print(f\"Output will be saved to: {output_path}\")\n",
        "\n",
        "    # Run Eagle using uv\n",
        "    cmd = [\n",
        "        \"uv\", \"run\", \"main.py\",\n",
        "        \"--video_path\", str(video_path),\n",
        "        \"--fps\", str(args.fps)\n",
        "    ]\n",
        "\n",
        "    print(f\"Running command: {' '.join(cmd)}\")\n",
        "\n",
        "    result = subprocess.run(\n",
        "        cmd,\n",
        "        capture_output=True,\n",
        "        text=True,\n",
        "        cwd=Path(__file__).parent\n",
        "    )\n",
        "\n",
        "    print(result.stdout)\n",
        "\n",
        "    # Check if the error is due to missing ball detection\n",
        "    if result.returncode != 0:\n",
        "        if \"KeyError: 'Ball'\" in result.stderr:\n",
        "            print(\"Ball detection failed - extracting available player tracking data\")\n",
        "            # Try to extract whatever tracking data was generated before the ball error\n",
        "            extract_available_data(video_path, output_path)\n",
        "        else:\n",
        "            print(result.stderr, file=sys.stderr)\n",
        "            sys.exit(1)\n",
        "    else:\n",
        "        # Normal processing when Eagle succeeds\n",
        "        extract_eagle_output(video_path, output_path)\n",
        "\n",
        "def extract_eagle_output(video_path, output_path):\n",
        "    \"\"\"Extract Eagle's output data\"\"\"\n",
        "    video_stem = video_path.stem\n",
        "    eagle_output_dir = Path(__file__).parent / \"output\" / video_stem\n",
        "\n",
        "    # Find the JSON output file (Eagle creates multiple files)\n",
        "    json_files = list(eagle_output_dir.glob(\"*.json\"))\n",
        "\n",
        "    if not json_files:\n",
        "        print(\"No JSON output found\", file=sys.stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Use the first JSON file or combine them\n",
        "    tracking_file = eagle_output_dir / \"tracking_data.json\"\n",
        "    if not tracking_file.exists():\n",
        "        tracking_file = json_files[0]\n",
        "\n",
        "    # Read Eagle's output and convert to our format\n",
        "    with open(tracking_file, 'r') as f:\n",
        "        eagle_data = json.load(f)\n",
        "\n",
        "    # Convert Eagle format to our standard format\n",
        "    standardized_output = {}\n",
        "\n",
        "    # If Eagle output is already frame-indexed, use it directly\n",
        "    if isinstance(eagle_data, dict):\n",
        "        standardized_output = eagle_data\n",
        "\n",
        "    # Save to our desired output location\n",
        "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with open(output_path, 'w') as f:\n",
        "        json.dump(standardized_output, f, indent=2)\n",
        "\n",
        "    print(f\"Eagle output saved: {len(standardized_output)} frames\")\n",
        "\n",
        "def extract_available_data(video_path, output_path):\n",
        "    \"\"\"Extract whatever tracking data Eagle generated before the ball error\"\"\"\n",
        "    video_stem = video_path.stem\n",
        "    eagle_output_dir = Path(__file__).parent / \"output\" / video_stem\n",
        "\n",
        "    # Look for any tracking files that were created\n",
        "    json_files = list(eagle_output_dir.glob(\"*.json\"))\n",
        "    csv_files = list(eagle_output_dir.glob(\"*.csv\"))\n",
        "\n",
        "    if json_files:\n",
        "        # Use the most recent JSON file\n",
        "        tracking_file = max(json_files, key=lambda x: x.stat().st_mtime)\n",
        "        print(f\"Found tracking data: {tracking_file}\")\n",
        "\n",
        "        with open(tracking_file, 'r') as f:\n",
        "            tracking_data = json.load(f)\n",
        "\n",
        "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        with open(output_path, 'w') as f:\n",
        "            json.dump(tracking_data, f, indent=2)\n",
        "\n",
        "        print(f\"Extracted available tracking data: {len(tracking_data)} frames\")\n",
        "\n",
        "    elif csv_files:\n",
        "        # Try to convert CSV to our format\n",
        "        import pandas as pd\n",
        "        csv_file = max(csv_files, key=lambda x: x.stat().st_mtime)\n",
        "        print(f\"Found CSV data: {csv_file}\")\n",
        "\n",
        "        df = pd.read_csv(csv_file)\n",
        "        tracking_data = {}\n",
        "\n",
        "        # Convert DataFrame to our format\n",
        "        for frame_idx in df['frame'].unique():\n",
        "            frame_data = df[df['frame'] == frame_idx]\n",
        "            players = []\n",
        "            for _, row in frame_data.iterrows():\n",
        "                players.append({\n",
        "                    \"id\": int(row['id']),\n",
        "                    \"x\": float(row['x']),\n",
        "                    \"y\": float(row['y']),\n",
        "                    \"w\": float(row['w']),\n",
        "                    \"h\": float(row['h'])\n",
        "                })\n",
        "            tracking_data[str(frame_idx)] = players\n",
        "\n",
        "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        with open(output_path, 'w') as f:\n",
        "            json.dump(tracking_data, f, indent=2)\n",
        "\n",
        "        print(f\"Converted CSV to tracking data: {len(tracking_data)} frames\")\n",
        "\n",
        "    else:\n",
        "        print(\"No tracking data found - Eagle failed before generating any output\")\n",
        "        # Create empty output as last resort\n",
        "        import cv2\n",
        "        cap = cv2.VideoCapture(str(video_path))\n",
        "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        cap.release()\n",
        "\n",
        "        empty_output = {}\n",
        "        for i in range(frame_count):\n",
        "            empty_output[str(i)] = []\n",
        "\n",
        "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        with open(output_path, 'w') as f:\n",
        "            json.dump(empty_output, f, indent=2)\n",
        "\n",
        "        print(f\"Created empty output with {frame_count} frames\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "''')\n",
        "\n",
        "print_status(\"Eagle setup complete\", \"SUCCESS\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Define visualization function\n",
        "\n",
        "import cv2\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "def create_overlay_video(video_path, json_path, output_path, show_ids=True, show_confidence=False):\n",
        "    \"\"\"\n",
        "    Create an overlayed video with tracking results\n",
        "\n",
        "    Args:\n",
        "        video_path: Path to original video\n",
        "        json_path: Path to tracking JSON output\n",
        "        output_path: Path for output video\n",
        "        show_ids: Whether to display player IDs\n",
        "        show_confidence: Whether to display confidence scores\n",
        "    \"\"\"\n",
        "    # Load tracking data\n",
        "    with open(json_path, 'r') as f:\n",
        "        tracking_data = json.load(f)\n",
        "\n",
        "    # Open video\n",
        "    cap = cv2.VideoCapture(str(video_path))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Create video writer\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))\n",
        "\n",
        "    frame_idx = 0\n",
        "\n",
        "    # Colors for different players (cycling through a palette)\n",
        "    colors = [\n",
        "        (0, 255, 0),    # Green\n",
        "        (255, 0, 0),    # Blue\n",
        "        (0, 0, 255),    # Red\n",
        "        (255, 255, 0),  # Cyan\n",
        "        (255, 0, 255),  # Magenta\n",
        "        (0, 255, 255),  # Yellow\n",
        "        (128, 255, 0),  # Light Green\n",
        "        (255, 128, 0),  # Light Blue\n",
        "    ]\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Get tracking data for this frame\n",
        "        frame_key = str(frame_idx)\n",
        "        if frame_key in tracking_data:\n",
        "            frame_data = tracking_data[frame_key]\n",
        "\n",
        "            # Draw each player\n",
        "            if 'Coordinates' in frame_data and 'Player' in frame_data['Coordinates']:\n",
        "                players = frame_data['Coordinates']['Player']\n",
        "\n",
        "                for player_id, player_data in players.items():\n",
        "                    bbox = player_data['BBox']\n",
        "                    confidence = player_data.get('Confidence', 0)\n",
        "\n",
        "                    # Get color for this player ID\n",
        "                    color = colors[int(player_id) % len(colors)]\n",
        "\n",
        "                    # Draw bounding box\n",
        "                    x1, y1, x2, y2 = bbox\n",
        "                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "\n",
        "                    # Prepare label\n",
        "                    label_parts = []\n",
        "                    if show_ids:\n",
        "                        label_parts.append(f\"ID:{player_id}\")\n",
        "                    if show_confidence:\n",
        "                        label_parts.append(f\"{confidence:.2f}\")\n",
        "\n",
        "                    if label_parts:\n",
        "                        label = \" \".join(label_parts)\n",
        "\n",
        "                        # Draw label background\n",
        "                        (label_width, label_height), _ = cv2.getTextSize(\n",
        "                            label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1\n",
        "                        )\n",
        "                        cv2.rectangle(\n",
        "                            frame,\n",
        "                            (x1, y1 - label_height - 5),\n",
        "                            (x1 + label_width, y1),\n",
        "                            color,\n",
        "                            -1\n",
        "                        )\n",
        "\n",
        "                        # Draw label text\n",
        "                        cv2.putText(\n",
        "                            frame,\n",
        "                            label,\n",
        "                            (x1, y1 - 5),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                            0.5,\n",
        "                            (255, 255, 255),\n",
        "                            1\n",
        "                        )\n",
        "\n",
        "                    # Draw center point for transformed coordinates visualization\n",
        "                    center_x = (x1 + x2) // 2\n",
        "                    center_y = (y1 + y2) // 2\n",
        "                    cv2.circle(frame, (center_x, center_y), 3, color, -1)\n",
        "\n",
        "            # Add timestamp\n",
        "            if 'Time' in frame_data:\n",
        "                timestamp = frame_data['Time']\n",
        "                cv2.putText(\n",
        "                    frame,\n",
        "                    f\"Time: {timestamp}\",\n",
        "                    (10, 30),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    0.7,\n",
        "                    (255, 255, 255),\n",
        "                    2\n",
        "                )\n",
        "\n",
        "        out.write(frame)\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    return True\n",
        "\n",
        "print_status(\"Visualization function loaded\", \"SUCCESS\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss9tQsrcr-xs",
        "outputId": "99207bc5-25ef-49c1-c5f6-e1ee628a76f6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m[SUCCESS] Visualization function loaded\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "run_tracking",
        "outputId": "bae9265b-4525-471e-b154-e95679e28dea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STARTING EVALUATION\n",
            "\n",
            "VIDEO: FULL MATCH  Brazil v Mexico  World Cup 2018 720p\n",
            "\u001b[94m[INFO] Processing clip 1 (start)...\u001b[0m\n",
            "------------------------------------------------------------\n",
            "\u001b[94m[INFO] Running anshchoudhary on FULL MATCH  Brazil v Mexico  World Cup 2018 720p/clip_1...\u001b[0m\n",
            "\u001b[92m[SUCCESS] anshchoudhary (FULL MATCH  Brazil v Mexico  World Cup 2018 720p/clip_1): SUCCESS in 137.8s\u001b[0m\n",
            "\n",
            "\u001b[94m[INFO] Processing clip 2 (middle)...\u001b[0m\n",
            "------------------------------------------------------------\n",
            "\u001b[94m[INFO] Running anshchoudhary on FULL MATCH  Brazil v Mexico  World Cup 2018 720p/clip_2...\u001b[0m\n",
            "\u001b[92m[SUCCESS] anshchoudhary (FULL MATCH  Brazil v Mexico  World Cup 2018 720p/clip_2): SUCCESS in 148.0s\u001b[0m\n",
            "\n",
            "\u001b[94m[INFO] Processing clip 3 (end)...\u001b[0m\n",
            "------------------------------------------------------------\n",
            "\u001b[94m[INFO] Running anshchoudhary on FULL MATCH  Brazil v Mexico  World Cup 2018 720p/clip_3...\u001b[0m\n",
            "\u001b[92m[SUCCESS] anshchoudhary (FULL MATCH  Brazil v Mexico  World Cup 2018 720p/clip_3): SUCCESS in 122.0s\u001b[0m\n",
            "\n",
            "\u001b[92m[SUCCESS] Summary saved: /content/output/FULL MATCH  Brazil v Mexico  World Cup 2018 720p/summary.json\u001b[0m\n",
            "EVALUATION COMPLETE\n",
            "\n",
            "\n",
            "Results: /content/output\n"
          ]
        }
      ],
      "source": [
        "# Cell 7: Run ALL tracking systems on all clips\n",
        "\n",
        "import time\n",
        "import json\n",
        "\n",
        "\"\"\"\n",
        "SYSTEM_CONFIGS = {\n",
        "    \"eagle\": {\n",
        "        \"path\": REPOS_DIR / \"eagle\",\n",
        "        \"script\": \"run_eagle.py\"\n",
        "    },\n",
        "    \"anshchoudhary\": {\n",
        "        \"path\": REPOS_DIR / \"anshchoudhary\",\n",
        "        \"script\": \"run_ansh.py\"\n",
        "    },\n",
        "\n",
        "    \"darkmyter\": {\n",
        "        \"path\": REPOS_DIR / \"darkmyter\",\n",
        "        \"script\": \"run_darkmyter.py\"\n",
        "    },\n",
        "    \"tracklab_yolov8_bytetrack\": {\n",
        "        \"path\": REPOS_DIR / \"tracklab\",\n",
        "        \"script\": \"run_tracklab.py\",\n",
        "        \"args\": [\"--detector\", \"yolov8\", \"--tracker\", \"bytetrack\", \"--conf_threshold\", \"0.3\"]\n",
        "    },\n",
        "}\"\"\"\n",
        "\n",
        "# System configurations\n",
        "SYSTEM_CONFIGS = {\n",
        "    \"anshchoudhary\": {\n",
        "        \"path\": REPOS_DIR / \"anshchoudhary\",\n",
        "        \"script\": \"run_ansh.py\"\n",
        "    },\n",
        "}\n",
        "\n",
        "position_to_number = {\"start\": 1, \"middle\": 2, \"end\": 3, \"full\": 1}\n",
        "\n",
        "def run_system_on_clip(system_name, system_config, video_name, clip_number, clip_path):\n",
        "    \"\"\"Run a tracking system on a clip\"\"\"\n",
        "\n",
        "    output_dir = OUTPUT_DIR / video_name / \"clips\" / str(clip_number) / system_name\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    output_file = output_dir / \"output.json\"\n",
        "\n",
        "    print_status(f\"Running {system_name} on {video_name}/clip_{clip_number}...\", \"INFO\")\n",
        "\n",
        "    # Change to system directory\n",
        "    original_dir = os.getcwd()\n",
        "    os.chdir(system_config[\"path\"])\n",
        "\n",
        "    # Build command\n",
        "    if system_name == \"eagle\":\n",
        "        cmd = [\n",
        "            \"uv\", \"run\", \"--python\", \"python3.11\", \"run_eagle.py\",\n",
        "            \"--video\", str(clip_path),\n",
        "            \"--output\", str(output_file)\n",
        "        ]\n",
        "    else:\n",
        "        cmd = [\n",
        "            \"python\", system_config[\"script\"],\n",
        "            \"--video\", str(clip_path),\n",
        "            \"--output\", str(output_file)\n",
        "        ]\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            cmd,\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=6000\n",
        "        )\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        os.chdir(original_dir)\n",
        "\n",
        "        if result.returncode == 0 and output_file.exists():\n",
        "            try:\n",
        "                with open(output_file) as f:\n",
        "                    data = json.load(f)\n",
        "                print_status(\n",
        "                    f\"{system_name} ({video_name}/clip_{clip_number}): SUCCESS in {elapsed:.1f}s\",\n",
        "                    \"SUCCESS\"\n",
        "                )\n",
        "                return {\"success\": True, \"time\": elapsed, \"output\": str(output_file), \"frames\": len(data)}\n",
        "            except json.JSONDecodeError:\n",
        "                print_status(\n",
        "                    f\"{system_name} ({video_name}/clip_{clip_number}): Invalid JSON output\",\n",
        "                    \"ERROR\"\n",
        "                )\n",
        "                return {\"success\": False, \"time\": elapsed, \"error\": \"Invalid JSON\"}\n",
        "        else:\n",
        "            error_msg = result.stderr[:200] if result.stderr else \"Unknown error\"\n",
        "            print_status(\n",
        "                f\"{system_name} ({video_name}/clip_{clip_number}): FAILED - {error_msg}\",\n",
        "                \"ERROR\"\n",
        "            )\n",
        "            return {\"success\": False, \"time\": elapsed, \"error\": error_msg}\n",
        "\n",
        "    except subprocess.TimeoutExpired:\n",
        "        os.chdir(original_dir)\n",
        "        print_status(f\"{system_name} ({video_name}/clip_{clip_number}): TIMEOUT\", \"ERROR\")\n",
        "        return {\"success\": False, \"time\": 600, \"error\": \"Timeout\"}\n",
        "\n",
        "    except Exception as e:\n",
        "        os.chdir(original_dir)\n",
        "        print_status(f\"{system_name} ({video_name}/clip_{clip_number}): EXCEPTION - {str(e)}\", \"ERROR\")\n",
        "        return {\"success\": False, \"time\": time.time() - start_time, \"error\": str(e)}\n",
        "\n",
        "# Run all systems on all clips\n",
        "\n",
        "print(\"STARTING EVALUATION\\n\")\n",
        "\n",
        "\n",
        "all_results = {}\n",
        "\n",
        "for video_name, clip_paths in ALL_CLIPS.items():\n",
        "\n",
        "    print(f\"VIDEO: {video_name}\")\n",
        "\n",
        "\n",
        "    video_results = {}\n",
        "\n",
        "    for clip_position, clip_path in clip_paths.items():\n",
        "        clip_number = position_to_number.get(clip_position, 1)\n",
        "\n",
        "        print_status(f\"Processing clip {clip_number} ({clip_position})...\", \"INFO\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        video_results[f\"clip_{clip_number}\"] = {}\n",
        "\n",
        "        for system_name, system_config in SYSTEM_CONFIGS.items():\n",
        "            result = run_system_on_clip(system_name, system_config, video_name, clip_number, clip_path)\n",
        "            video_results[f\"clip_{clip_number}\"][system_name] = result\n",
        "\n",
        "        print()\n",
        "\n",
        "    all_results[video_name] = video_results\n",
        "\n",
        "    # Save summary\n",
        "    summary_file = OUTPUT_DIR / video_name / \"summary.json\"\n",
        "    with open(summary_file, \"w\") as f:\n",
        "        json.dump(video_results, f, indent=2)\n",
        "\n",
        "    print_status(f\"Summary saved: {summary_file}\", \"SUCCESS\")\n",
        "\n",
        "# Save overall summary\n",
        "overall_summary = OUTPUT_DIR / \"overall_summary.json\"\n",
        "with open(overall_summary, \"w\") as f:\n",
        "    json.dump(all_results, f, indent=2)\n",
        "\n",
        "\n",
        "print(\"EVALUATION COMPLETE\\n\")\n",
        "\n",
        "print(f\"\\nResults: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "display_results",
        "outputId": "a7309e1f-0b58-491e-9f6b-e677bd1c67fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESULTS SUMMARY \n",
            "\n",
            "                                           Video   Clip        System Status Time (s)\n",
            "FULL MATCH  Brazil v Mexico  World Cup 2018 720p clip_1 anshchoudhary  Valid    137.8\n",
            "FULL MATCH  Brazil v Mexico  World Cup 2018 720p clip_2 anshchoudhary  Valid    148.0\n",
            "FULL MATCH  Brazil v Mexico  World Cup 2018 720p clip_3 anshchoudhary  Valid    122.0\n",
            "Success Rate: 3/3 (100.0%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cell 8: Display results\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "print(\"RESULTS SUMMARY \\n\")\n",
        "\n",
        "\n",
        "summary_data = []\n",
        "\n",
        "for video_name, clips in all_results.items():\n",
        "    for clip_key, systems in clips.items():\n",
        "        for system_name, result in systems.items():\n",
        "            summary_data.append({\n",
        "                \"Video\": video_name,\n",
        "                \"Clip\": clip_key,\n",
        "                \"System\": system_name,\n",
        "                \"Status\": \"Valid\" if result[\"success\"] else \"Invalid\",\n",
        "                \"Time (s)\": f\"{result['time']:.1f}\"\n",
        "            })\n",
        "\n",
        "df = pd.DataFrame(summary_data)\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "total_runs = len(summary_data)\n",
        "successful_runs = sum(1 for row in summary_data if row[\"Status\"] == \"Valid\")\n",
        "\n",
        "\n",
        "print(f\"Success Rate: {successful_runs}/{total_runs} ({100*successful_runs/total_runs:.1f}%)\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import cv2\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "def detect_json_format(data):\n",
        "    \"\"\"Detect which tracking system format the JSON is in\"\"\"\n",
        "    if not data:\n",
        "        return \"unknown\"\n",
        "\n",
        "    first_frame_key = list(data.keys())[0]\n",
        "    first_frame = data[first_frame_key]\n",
        "\n",
        "    # Eagle format: nested dict with \"Coordinates\" -> \"Player\"\n",
        "    if isinstance(first_frame, dict) and \"Coordinates\" in first_frame:\n",
        "        if \"Player\" in first_frame[\"Coordinates\"]:\n",
        "            return \"eagle\"\n",
        "\n",
        "    # AnshChoudhary/Darkmyter/TrackLab format: list of dicts with x, y, w, h\n",
        "    if isinstance(first_frame, list) and len(first_frame) > 0:\n",
        "        if \"x\" in first_frame[0] and \"w\" in first_frame[0]:\n",
        "            return \"xywh\"\n",
        "\n",
        "    return \"unknown\"\n",
        "\n",
        "def parse_eagle_frame(frame_data):\n",
        "    \"\"\"Parse Eagle format frame data\"\"\"\n",
        "    players = []\n",
        "    if \"Coordinates\" in frame_data and \"Player\" in frame_data[\"Coordinates\"]:\n",
        "        for player_id, player_data in frame_data[\"Coordinates\"][\"Player\"].items():\n",
        "            bbox = player_data[\"BBox\"]\n",
        "            players.append({\n",
        "                \"id\": int(player_id),\n",
        "                \"x1\": bbox[0],\n",
        "                \"y1\": bbox[1],\n",
        "                \"x2\": bbox[2],\n",
        "                \"y2\": bbox[3],\n",
        "                \"confidence\": player_data.get(\"Confidence\", 0)\n",
        "            })\n",
        "    return players, frame_data.get(\"Time\", \"\")\n",
        "\n",
        "def parse_xywh_frame(frame_data):\n",
        "    \"\"\"Parse AnshChoudhary/Darkmyter/TrackLab format frame data\"\"\"\n",
        "    players = []\n",
        "    if isinstance(frame_data, list):\n",
        "        for player_data in frame_data:\n",
        "            # Convert center x,y,w,h to corner coordinates\n",
        "            center_x = player_data[\"x\"]\n",
        "            center_y = player_data[\"y\"]\n",
        "            w = player_data[\"w\"]\n",
        "            h = player_data[\"h\"]\n",
        "\n",
        "            x1 = int(center_x - w/2)\n",
        "            y1 = int(center_y - h/2)\n",
        "            x2 = int(center_x + w/2)\n",
        "            y2 = int(center_y + h/2)\n",
        "\n",
        "            players.append({\n",
        "                \"id\": player_data[\"id\"],\n",
        "                \"x1\": x1,\n",
        "                \"y1\": y1,\n",
        "                \"x2\": x2,\n",
        "                \"y2\": y2,\n",
        "                \"confidence\": player_data.get(\"confidence\", 0)\n",
        "            })\n",
        "    return players, \"\"\n",
        "\n",
        "def create_universal_overlay_video(video_path, json_path, output_path, show_ids=True, show_confidence=False):\n",
        "    \"\"\"\n",
        "    Create an overlayed video that works with ANY tracking system format\n",
        "    \"\"\"\n",
        "    # Load tracking data\n",
        "    with open(json_path, 'r') as f:\n",
        "        tracking_data = json.load(f)\n",
        "\n",
        "    # Detect format\n",
        "    format_type = detect_json_format(tracking_data)\n",
        "    print(f\"    Detected format: {format_type}\")\n",
        "\n",
        "    if format_type == \"unknown\":\n",
        "        print(f\"    ✗ Unknown JSON format\")\n",
        "        return False\n",
        "\n",
        "    # Open video\n",
        "    cap = cv2.VideoCapture(str(video_path))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Create video writer\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))\n",
        "\n",
        "    # Colors for different players\n",
        "    colors = [\n",
        "        (0, 255, 0),    # Green\n",
        "        (255, 0, 0),    # Blue\n",
        "        (0, 0, 255),    # Red\n",
        "        (255, 255, 0),  # Cyan\n",
        "        (255, 0, 255),  # Magenta\n",
        "        (0, 255, 255),  # Yellow\n",
        "        (128, 255, 0),  # Light Green\n",
        "        (255, 128, 0),  # Light Blue\n",
        "        (0, 128, 255),  # Orange\n",
        "        (255, 0, 128),  # Pink\n",
        "    ]\n",
        "\n",
        "    frame_idx = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Get tracking data for this frame\n",
        "        frame_key = str(frame_idx)\n",
        "        if frame_key in tracking_data:\n",
        "            frame_data = tracking_data[frame_key]\n",
        "\n",
        "            # Parse based on format\n",
        "            if format_type == \"eagle\":\n",
        "                players, timestamp = parse_eagle_frame(frame_data)\n",
        "            elif format_type == \"xywh\":\n",
        "                players, timestamp = parse_xywh_frame(frame_data)\n",
        "            else:\n",
        "                players, timestamp = [], \"\"\n",
        "\n",
        "            # Draw each player\n",
        "            for player in players:\n",
        "                player_id = player[\"id\"]\n",
        "                x1, y1, x2, y2 = player[\"x1\"], player[\"y1\"], player[\"x2\"], player[\"y2\"]\n",
        "                confidence = player[\"confidence\"]\n",
        "\n",
        "                # Get color for this player ID\n",
        "                color = colors[player_id % len(colors)]\n",
        "\n",
        "                # Draw bounding box\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "\n",
        "                # Prepare label\n",
        "                label_parts = []\n",
        "                if show_ids:\n",
        "                    label_parts.append(f\"ID:{player_id}\")\n",
        "                if show_confidence and confidence > 0:\n",
        "                    label_parts.append(f\"{confidence:.2f}\")\n",
        "\n",
        "                if label_parts:\n",
        "                    label = \" \".join(label_parts)\n",
        "\n",
        "                    # Draw label background\n",
        "                    (label_width, label_height), _ = cv2.getTextSize(\n",
        "                        label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1\n",
        "                    )\n",
        "                    cv2.rectangle(\n",
        "                        frame,\n",
        "                        (x1, y1 - label_height - 5),\n",
        "                        (x1 + label_width, y1),\n",
        "                        color,\n",
        "                        -1\n",
        "                    )\n",
        "\n",
        "                    # Draw label text\n",
        "                    cv2.putText(\n",
        "                        frame,\n",
        "                        label,\n",
        "                        (x1, y1 - 5),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                        0.5,\n",
        "                        (255, 255, 255),\n",
        "                        1\n",
        "                    )\n",
        "\n",
        "                # Draw center point\n",
        "                center_x = (x1 + x2) // 2\n",
        "                center_y = (y1 + y2) // 2\n",
        "                cv2.circle(frame, (center_x, center_y), 3, color, -1)\n",
        "\n",
        "            # Add timestamp (for Eagle format)\n",
        "            if timestamp:\n",
        "                cv2.putText(\n",
        "                    frame,\n",
        "                    f\"Time: {timestamp}\",\n",
        "                    (10, 30),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    0.7,\n",
        "                    (255, 255, 255),\n",
        "                    2\n",
        "                )\n",
        "\n",
        "            # Add frame number (for all formats)\n",
        "            cv2.putText(\n",
        "                frame,\n",
        "                f\"Frame: {frame_idx}\",\n",
        "                (10, height - 10),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                0.5,\n",
        "                (255, 255, 255),\n",
        "                1\n",
        "            )\n",
        "\n",
        "        out.write(frame)\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    return True\n",
        "\n",
        "# GENERATE OVERLAYS FOR ALL SYSTEMS\n",
        "\n",
        "print(\"UNIVERSAL OVERLAY GENERATOR\\n\")\n",
        "\n",
        "overlay_count = 0\n",
        "failed_count = 0\n",
        "system_counts = {}\n",
        "\n",
        "for video_name, clips_data in all_results.items():\n",
        "    print(f\"\\n📹 Video: {video_name}\")\n",
        "\n",
        "    for clip_key, systems_data in clips_data.items():\n",
        "        # Reconstruct clip path\n",
        "        clip_number = int(clip_key.split('_')[1])\n",
        "        clip_path = None\n",
        "\n",
        "        for pos, num in position_to_number.items():\n",
        "            if num == clip_number and video_name in ALL_CLIPS and pos in ALL_CLIPS[video_name]:\n",
        "                clip_path = ALL_CLIPS[video_name][pos]\n",
        "                break\n",
        "\n",
        "        if not clip_path:\n",
        "            print(f\" Skipping {clip_key} - clip path not found\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n {clip_key}:\")\n",
        "\n",
        "        for system_name, result_data in systems_data.items():\n",
        "            if result_data.get('success'):\n",
        "                try:\n",
        "                    json_path = result_data['output']\n",
        "                    output_dir = Path(json_path).parent\n",
        "                    overlay_video_path = output_dir / \"overlay_video.mp4\"\n",
        "\n",
        "                    print(f\" {system_name}...\", end=\" \")\n",
        "\n",
        "                    success = create_universal_overlay_video(\n",
        "                        video_path=clip_path,\n",
        "                        json_path=json_path,\n",
        "                        output_path=overlay_video_path,\n",
        "                        show_ids=True,\n",
        "                        show_confidence=False\n",
        "                    )\n",
        "\n",
        "                    if success:\n",
        "                        print(f\"✓\")\n",
        "                        overlay_count += 1\n",
        "                        system_counts[system_name] = system_counts.get(system_name, 0) + 1\n",
        "                        result_data['overlay_video'] = str(overlay_video_path)\n",
        "                    else:\n",
        "                        print(f\"✗\")\n",
        "                        failed_count += 1\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"✗ Error: {e}\")\n",
        "                    failed_count += 1\n",
        "\n",
        "print(\"SUMMARY\\n\")\n",
        "print(f\"Total overlays created: {overlay_count}\")\n",
        "print(f\"Failed: {failed_count}\")\n",
        "print(\"\\nPer System:\")\n",
        "for system, count in sorted(system_counts.items()):\n",
        "    print(f\"  • {system}: {count} video(s)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Update summary files\n",
        "for video_name, video_results in all_results.items():\n",
        "    summary_file = OUTPUT_DIR / video_name / \"summary.json\"\n",
        "    with open(summary_file, \"w\") as f:\n",
        "        json.dump(video_results, f, indent=2)\n",
        "\n",
        "with open(overall_summary, \"w\") as f:\n",
        "    json.dump(all_results, f, indent=2)\n",
        "\n",
        "print(\"\\nSummary files updated with overlay paths!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxyRVI77A9EI",
        "outputId": "ebe8b3fc-d0c3-42c7-e062-cfb5bedca88f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNIVERSAL OVERLAY GENERATOR\n",
            "\n",
            "\n",
            "📹 Video: FULL MATCH  Brazil v Mexico  World Cup 2018 720p\n",
            "\n",
            " clip_1:\n",
            " anshchoudhary...     Detected format: xywh\n",
            "✓\n",
            "\n",
            " clip_2:\n",
            " anshchoudhary...     Detected format: xywh\n",
            "✓\n",
            "\n",
            " clip_3:\n",
            " anshchoudhary...     Detected format: xywh\n",
            "✓\n",
            "SUMMARY\n",
            "\n",
            "Total overlays created: 3\n",
            "Failed: 0\n",
            "\n",
            "Per System:\n",
            "  • anshchoudhary: 3 video(s)\n",
            "============================================================\n",
            "\n",
            "Summary files updated with overlay paths!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "download",
        "outputId": "9e9bf3c3-b4b0-4c37-a524-af6ce4dcb181"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Creating archive...\u001b[0m\n",
            "\u001b[92m[SUCCESS] Downloading...\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_abf755a7-16e9-4e48-b031-6b8b01a9e749\", \"tracking_results.zip\", 410072068)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m[SUCCESS] Complete!\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Cell 9: Download results\n",
        "\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "print_status(\"Creating archive...\", \"INFO\")\n",
        "\n",
        "archive_name = \"tracking_results\"\n",
        "archive_path = BASE_DIR / archive_name\n",
        "\n",
        "shutil.make_archive(str(archive_path), 'zip', OUTPUT_DIR)\n",
        "\n",
        "print_status(\"Downloading...\", \"SUCCESS\")\n",
        "files.download(f\"{archive_path}.zip\")\n",
        "\n",
        "print_status(\"Complete!\", \"SUCCESS\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}