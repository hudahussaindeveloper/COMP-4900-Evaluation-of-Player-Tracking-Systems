{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# Player Tracking System Comparison\n",
        "\n",
        "This notebook compares 3 different player tracking systems:\n",
        "- Eagle\n",
        "- Darkmyter (using Ultralytics YOLO)\n",
        "- Ultralytics YOLO 11 + Botsort\n",
        "\n",
        "**Important**: Run cells in order from top to bottom!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Setup directories and utilities\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "BASE_DIR = Path(\"/content\")\n",
        "REPOS_DIR = BASE_DIR / \"repositories\"\n",
        "VIDEOS_DIR = BASE_DIR / \"videos\"\n",
        "CLIPS_DIR = BASE_DIR / \"clips\"\n",
        "OUTPUT_DIR = BASE_DIR / \"output\"\n",
        "\n",
        "for d in [REPOS_DIR, VIDEOS_DIR, CLIPS_DIR, OUTPUT_DIR]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def print_status(msg, status=\"INFO\"):\n",
        "    \"Print colored status messages\"\n",
        "    colors = {\n",
        "        \"INFO\": \"\\033[94m\",\n",
        "        \"SUCCESS\": \"\\033[92m\",\n",
        "        \"WARNING\": \"\\033[93m\",\n",
        "        \"ERROR\": \"\\033[91m\",\n",
        "        \"RESET\": \"\\033[0m\"\n",
        "    }\n",
        "    print(f\"{colors.get(status, '')}[{status}] {msg}{colors['RESET']}\")\n",
        "\n",
        "print_status(\"Directory structure created\", \"SUCCESS\")\n",
        "print(f\"Working directory: {BASE_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone"
      },
      "outputs": [],
      "source": [
        "# Cell 2: Clone all repositories\n",
        "\n",
        "import subprocess\n",
        "\n",
        "REPOSITORIES = {\n",
        "    \"eagle\": \"https://github.com/nreHieW/Eagle.git\",\n",
        "    \"darkmyter\": \"https://github.com/Darkmyter/Football-Players-Tracking.git\",\n",
        "}\n",
        "\n",
        "print_status(\"Cloning repositories...\", \"INFO\")\n",
        "\n",
        "for name, url in REPOSITORIES.items():\n",
        "    repo_path = REPOS_DIR / name\n",
        "\n",
        "    if repo_path.exists():\n",
        "        print_status(f\"{name}: Already exists, skipping\", \"WARNING\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        print_status(f\"{name}: Cloning...\", \"INFO\")\n",
        "        result = subprocess.run(\n",
        "            [\"git\", \"clone\", url, str(repo_path)],\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=300\n",
        "        )\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            print_status(f\"{name}: Cloned successfully\", \"SUCCESS\")\n",
        "        else:\n",
        "            print_status(f\"{name}: Clone failed - {result.stderr[:100]}\", \"ERROR\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print_status(f\"{name}: Clone failed - {str(e)}\", \"ERROR\")\n",
        "\n",
        "print_status(\"Repository cloning complete\", \"SUCCESS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "# Cell 3: Install dependencies\n",
        "\n",
        "print_status(\"Installing dependencies...\", \"INFO\")\n",
        "\n",
        "!pip install -q torch torchvision torchaudio tracklab\n",
        "!pip install -q opencv-python numpy scipy pandas scikit-learn matplotlib\n",
        "!pip install -q ultralytics supervision\n",
        "!pip install -q gdown Pillow tqdm requests\n",
        "!pip install -q \\\n",
        "    loguru cython cython_bbox lap onemetric scikit-image tabulate tqdm numpy torch torchvision opencv-python pyyaml yolox\n",
        "!pip install -q loguru\n",
        "!pip install onemetric #THIS CELL IS IMPORTANT\n",
        "!pip install psutil\n",
        "\n",
        "\n",
        "print_status(\"Dependencies installed\", \"SUCCESS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzy7qI3atgID"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO(\"yolo11m.pt\")\n",
        "print(\"Loaded weights from:\", getattr(model, \"ckpt_path\", \"unknown path\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_videos"
      },
      "outputs": [],
      "source": [
        "# Cell 4: Download videos from Google Drive\n",
        "\n",
        "!pip install -q gdown\n",
        "\n",
        "import gdown\n",
        "from pathlib import Path\n",
        "\n",
        "# Shared folder ID\n",
        "FOLDER_ID = \"1Cs4kTX6GYwfcpKyDZdqRKBezz49wT7_N\"\n",
        "\n",
        "print_status(\"Downloading videos from shared folder...\", \"INFO\")\n",
        "\n",
        "try:\n",
        "    gdown.download_folder(\n",
        "        id=FOLDER_ID,\n",
        "        output=str(VIDEOS_DIR),\n",
        "        quiet=False,\n",
        "        use_cookies=False\n",
        "    )\n",
        "\n",
        "    # List downloaded videos\n",
        "    video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.MP4', '.AVI', '.MOV', '.MKV']\n",
        "    available_videos = []\n",
        "\n",
        "    for ext in video_extensions:\n",
        "        available_videos.extend(list(VIDEOS_DIR.glob(f\"*{ext}\")))\n",
        "\n",
        "    if not available_videos:\n",
        "        print_status(\"No video files found\", \"ERROR\")\n",
        "    else:\n",
        "        print(f\"\\nDOWNLOADED {len(available_videos)} VIDEO(S)\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        for idx, video in enumerate(available_videos, 1):\n",
        "            size_mb = video.stat().st_size / (1024 * 1024)\n",
        "            print(f\"{idx}. {video.name} ({size_mb:.1f} MB)\")\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(\"VIDEO SELECTION\")\n",
        "\n",
        "        # Ask for number of videos\n",
        "        print(\"\\nHow many videos do you want to evaluate?\")\n",
        "        print(f\"  - Enter a number between 1 and {len(available_videos)}\")\n",
        "        print(f\"  - Enter 'all' or leave blank to process ALL {len(available_videos)} videos\")\n",
        "\n",
        "        num_selection = input(\"\\nNumber of videos: \").strip().lower()\n",
        "\n",
        "        VIDEO_PATHS = []\n",
        "\n",
        "        if not num_selection or num_selection == 'all':\n",
        "            VIDEO_PATHS = available_videos\n",
        "            print_status(f\"Selected ALL {len(VIDEO_PATHS)} videos\", \"SUCCESS\")\n",
        "        elif num_selection.isdigit():\n",
        "            num_videos = int(num_selection)\n",
        "            if 1 <= num_videos <= len(available_videos):\n",
        "                if num_videos == len(available_videos):\n",
        "                    VIDEO_PATHS = available_videos\n",
        "                else:\n",
        "                    print(f\"\\nSelect {num_videos} video(s) from the list above:\")\n",
        "                    print(\"  - Enter comma-separated numbers (e.g., '1,3,5')\")\n",
        "                    print(f\"  - Or enter 'first' to select the first {num_videos} videos\")\n",
        "\n",
        "                    video_selection = input(\"\\nYour selection: \").strip().lower()\n",
        "\n",
        "                    if video_selection == 'first':\n",
        "                        VIDEO_PATHS = available_videos[:num_videos]\n",
        "                    else:\n",
        "                        try:\n",
        "                            indices = [int(x.strip()) for x in video_selection.split(',')]\n",
        "                            if len(indices) != num_videos:\n",
        "                                print_status(f\"Warning: Selected {len(indices)} videos instead of {num_videos}\", \"WARNING\")\n",
        "                            for idx in indices[:num_videos]:\n",
        "                                if 1 <= idx <= len(available_videos):\n",
        "                                    VIDEO_PATHS.append(available_videos[idx - 1])\n",
        "                        except ValueError:\n",
        "                            print_status(\"Invalid input, selecting first videos\", \"WARNING\")\n",
        "                            VIDEO_PATHS = available_videos[:num_videos]\n",
        "\n",
        "                print_status(f\"Selected {len(VIDEO_PATHS)} video(s)\", \"SUCCESS\")\n",
        "                for video in VIDEO_PATHS:\n",
        "                    print(f\"  - {video.name}\")\n",
        "            else:\n",
        "                print_status(f\"Invalid number. Must be between 1 and {len(available_videos)}\", \"ERROR\")\n",
        "        else:\n",
        "            print_status(\"Invalid input\", \"ERROR\")\n",
        "\n",
        "        if not VIDEO_PATHS:\n",
        "            print_status(\"No videos selected\", \"ERROR\")\n",
        "\n",
        "except Exception as e:\n",
        "    print_status(f\"Download failed: {str(e)}\", \"ERROR\")\n",
        "    print(\"\\nNote: Make sure the folder is set to 'Anyone with the link can view'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "extract_clips"
      },
      "outputs": [],
      "source": [
        "# Cell 5: Prepare videos and clips\n",
        "\n",
        "import cv2\n",
        "import subprocess\n",
        "\n",
        "CLIP_DURATION = 60\n",
        "\n",
        "# Prepare both full videos and clips\n",
        "FULL_VIDEOS = {}\n",
        "VIDEO_CLIPS = {}\n",
        "\n",
        "for VIDEO_PATH in VIDEO_PATHS:\n",
        "    VIDEO_NAME = VIDEO_PATH.stem\n",
        "\n",
        "    print(f\"\\nPREPARING: {VIDEO_NAME}\")\n",
        "\n",
        "    # Store full video path\n",
        "    FULL_VIDEOS[VIDEO_NAME] = {\"full\": VIDEO_PATH}\n",
        "\n",
        "    # Get video info for clip extraction\n",
        "    cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    duration = total_frames / fps\n",
        "    cap.release()\n",
        "\n",
        "    print(f\"Duration: {duration:.1f}s | FPS: {fps:.1f} | Frames: {total_frames}\")\n",
        "\n",
        "    # Determine clip positions\n",
        "    if duration < CLIP_DURATION * 3:\n",
        "        if duration < CLIP_DURATION:\n",
        "            CLIPS = [(0, duration, \"full\")]\n",
        "            print_status(f\"Video shorter than {CLIP_DURATION}s, will use full video\", \"INFO\")\n",
        "        else:\n",
        "            CLIPS = [\n",
        "                (0, CLIP_DURATION, \"start\"),\n",
        "                (max(duration - CLIP_DURATION, 0), CLIP_DURATION, \"end\")\n",
        "            ]\n",
        "            print_status(\"Will extract start and end clips\", \"INFO\")\n",
        "    else:\n",
        "        CLIPS = [\n",
        "            (0, CLIP_DURATION, \"start\"),\n",
        "            ((duration - CLIP_DURATION) / 2, CLIP_DURATION, \"middle\"),\n",
        "            (duration - CLIP_DURATION, CLIP_DURATION, \"end\")\n",
        "        ]\n",
        "        print_status(\"Will extract start, middle, and end clips\", \"INFO\")\n",
        "\n",
        "    # Extract clips\n",
        "    CLIP_PATHS = {}\n",
        "    for start_time, clip_dur, position in CLIPS:\n",
        "        clip_name = f\"{VIDEO_NAME}_{position}.mp4\"\n",
        "        clip_path = CLIPS_DIR / clip_name\n",
        "\n",
        "        cmd = [\n",
        "            \"ffmpeg\", \"-i\", str(VIDEO_PATH),\n",
        "            \"-ss\", str(start_time),\n",
        "            \"-t\", str(clip_dur),\n",
        "            \"-c\", \"copy\",\n",
        "            str(clip_path),\n",
        "            \"-y\",\n",
        "            \"-loglevel\", \"error\"\n",
        "        ]\n",
        "\n",
        "        result = subprocess.run(cmd, capture_output=True)\n",
        "\n",
        "        if result.returncode == 0 and clip_path.exists():\n",
        "            CLIP_PATHS[position] = clip_path\n",
        "            size_mb = clip_path.stat().st_size / (1024 * 1024)\n",
        "            print_status(f\"Clip '{position}' ready ({size_mb:.1f} MB)\", \"SUCCESS\")\n",
        "        else:\n",
        "            print_status(f\"Failed to extract '{position}' clip\", \"ERROR\")\n",
        "\n",
        "    VIDEO_CLIPS[VIDEO_NAME] = CLIP_PATHS\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"PREPARATION COMPLETE\")\n",
        "print(f\"Prepared {len(VIDEO_PATHS)} video(s) with both full and clip options\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "H_etsZN8K1QG"
      },
      "outputs": [],
      "source": [
        "# Cell: Setup Darkmyter (Original ByteTrack + YOLO - Authentic Implementation)\n",
        "\n",
        "print_status(\"Setting up Darkmyter tracking...\", \"INFO\")\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "darkmyter_dir = REPOS_DIR / \"darkmyter\"\n",
        "\n",
        "# Clone original ByteTrack repo (required for authentic Darkmyter)\n",
        "bytetrack_dir = darkmyter_dir / \"ByteTrack\"\n",
        "if not bytetrack_dir.exists():\n",
        "    print_status(\"Cloning original ByteTrack repository...\", \"INFO\")\n",
        "    subprocess.run([\n",
        "        \"git\", \"clone\", \"--depth\", \"1\",\n",
        "        \"https://github.com/ifzhang/ByteTrack.git\",\n",
        "        str(bytetrack_dir)\n",
        "    ], check=True)\n",
        "\n",
        "# Install ByteTrack dependencies\n",
        "!pip install -q cython lap cython_bbox\n",
        "\n",
        "# Download football-specific weights\n",
        "weights_dir = darkmyter_dir / \"yolov8-weights\"\n",
        "weights_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "custom_weights = weights_dir / \"yolov8l-football-players.pt\"\n",
        "gdrive_id = \"12dWRBsegmyGE3feTdy9LBf1eZ-hTZ9Sx\"\n",
        "\n",
        "def download_darkmyter_weights():\n",
        "    print_status(\"Downloading Darkmyter football weights...\", \"INFO\")\n",
        "    try:\n",
        "        import gdown\n",
        "        url = f\"https://drive.google.com/uc?id={gdrive_id}\"\n",
        "        gdown.download(url, str(custom_weights), quiet=False)\n",
        "        print_status(\"Darkmyter weights downloaded\", \"SUCCESS\")\n",
        "    except Exception as e:\n",
        "        print_status(f\"Failed to download weights: {e}\", \"ERROR\")\n",
        "\n",
        "if custom_weights.exists():\n",
        "    try:\n",
        "        with open(custom_weights, \"rb\") as f:\n",
        "            header = f.read(16)\n",
        "        if header.startswith(b\"<\"):\n",
        "            print_status(\"Weights file is HTML, re-downloading...\", \"ERROR\")\n",
        "            custom_weights.unlink(missing_ok=True)\n",
        "            download_darkmyter_weights()\n",
        "        else:\n",
        "            print_status(\"Darkmyter weights already present\", \"SUCCESS\")\n",
        "    except Exception:\n",
        "        custom_weights.unlink(missing_ok=True)\n",
        "        download_darkmyter_weights()\n",
        "else:\n",
        "    download_darkmyter_weights()\n",
        "\n",
        "# Create Darkmyter wrapper\n",
        "darkmyter_wrapper = darkmyter_dir / \"run_darkmyter.py\"\n",
        "darkmyter_wrapper.write_text('''\n",
        "#!/usr/bin/env python\n",
        "\"\"\"\n",
        "Darkmyter: YOLOv8 + original ByteTrack (football, notebook-authentic).\n",
        "\n",
        "This script is a CLI version of the Roboflow \"track players with ByteTrack + YOLOv8\"\n",
        "notebook, adapted to output JSON instead of an annotated video.\n",
        "\n",
        "It:\n",
        "- Uses yolov8l-football-players.pt if present, else falls back to yolov8x.pt\n",
        "- Uses original ifzhang/ByteTrack\n",
        "- Uses football-specific BYTETrackerArgs\n",
        "- Uses the same format_predictions + match_detections_with_tracks pattern\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import sys\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    from ultralytics import YOLO\n",
        "    import torch\n",
        "except ImportError:\n",
        "    print(\"Error: ultralytics or torch not installed\", file=sys.stderr)\n",
        "    sys.exit(1)\n",
        "\n",
        "# Original ByteTrack imports\n",
        "BYTETRACK_PATH = Path(__file__).resolve().parent / \"ByteTrack\"\n",
        "sys.path.insert(0, str(BYTETRACK_PATH))\n",
        "\n",
        "try:\n",
        "    from yolox.tracker.byte_tracker import BYTETracker, STrack\n",
        "except ImportError:\n",
        "    print(\"Error: ByteTrack repo not found; expected at ./ByteTrack\", file=sys.stderr)\n",
        "    sys.exit(1)\n",
        "\n",
        "try:\n",
        "    from onemetric.cv.utils.iou import box_iou_batch\n",
        "except ImportError:\n",
        "    print(\"Error: onemetric not installed (needed for IoU). \"\n",
        "          \"Install with: pip install onemetric\", file=sys.stderr)\n",
        "    sys.exit(1)\n",
        "try:\n",
        "    from yolox.tracker.byte_tracker import BYTETracker, STrack\n",
        "except ImportError as e:\n",
        "    import traceback\n",
        "    print(\"Error importing ByteTrack from ./ByteTrack:\", e, file=sys.stderr)\n",
        "    traceback.print_exc()\n",
        "    sys.exit(1)\n",
        "\n",
        "\n",
        "#BYTETrackerArgs: football-specific params (from notebook)\n",
        "@dataclass(frozen=True)\n",
        "class BYTETrackerArgs:\n",
        "    track_thresh: float = 0.25\n",
        "    track_buffer: int = 30\n",
        "    match_thresh: float = 0.8\n",
        "    aspect_ratio_thresh: float = 3.0\n",
        "    min_box_area: float = 1.0\n",
        "    mot20: bool = False\n",
        "\n",
        "\n",
        "# Same mapping as in the notebook\n",
        "IND_TO_CLS = {\n",
        "    0: \"ball\",\n",
        "    1: \"goalkeeper\",\n",
        "    2: \"player\",\n",
        "    3: \"referee\",\n",
        "}\n",
        "\n",
        "\n",
        "def format_predictions(predictions, with_conf: bool = True) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Format YOLO detections to ByteTrack format: (x1, y1, x2, y2, conf).\n",
        "\n",
        "    This mirrors the notebook's function exactly:\n",
        "        bbox = pred.boxes.xyxy.int().tolist()[0]\n",
        "        conf = pred.boxes.conf.item()\n",
        "    \"\"\"\n",
        "    frame_detections = []\n",
        "    for pred in predictions:\n",
        "        # pred is a ultralytics Results object with a single box\n",
        "        bbox = pred.boxes.xyxy.int().tolist()[0]  # [x1, y1, x2, y2]\n",
        "        conf = float(pred.boxes.conf.item())\n",
        "        if with_conf:\n",
        "            detection = bbox + [conf]\n",
        "        else:\n",
        "            detection = bbox\n",
        "        frame_detections.append(detection)\n",
        "\n",
        "    if not frame_detections:\n",
        "        # shape must be (0, 5) or (0, 4) depending on with_conf\n",
        "        return np.zeros((0, 5 if with_conf else 4), dtype=float)\n",
        "\n",
        "    return np.array(frame_detections, dtype=float)\n",
        "\n",
        "\n",
        "def match_detections_with_tracks(detections, tracks):\n",
        "    \"\"\"\n",
        "    Notebook-authentic matching:\n",
        "\n",
        "    - Build detections_bboxes using format_predictions(with_conf=False)\n",
        "    - Build tracks_bboxes from track.tlbr\n",
        "    - Compute IoU matrix with box_iou_batch\n",
        "    - For each track, assign its track_id to the best IoU detection if IoU != 0\n",
        "    \"\"\"\n",
        "    if not detections or not tracks:\n",
        "        return detections\n",
        "\n",
        "    detections_bboxes = format_predictions(detections, with_conf=False)\n",
        "    tracks_bboxes = np.array([track.tlbr for track in tracks], dtype=float)\n",
        "\n",
        "    iou = box_iou_batch(tracks_bboxes, detections_bboxes)  # [num_tracks, num_dets]\n",
        "    track2detection = np.argmax(iou, axis=1)\n",
        "\n",
        "    for tracker_index, detection_index in enumerate(track2detection):\n",
        "        if iou[tracker_index, detection_index] != 0:\n",
        "            detections[detection_index].tracker_id = tracks[tracker_index].track_id\n",
        "\n",
        "    return detections\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=\"Darkmyter: YOLOv8 + original ByteTrack (football)\"\n",
        "    )\n",
        "    parser.add_argument(\"--video\", required=True, help=\"Path to input video\")\n",
        "    parser.add_argument(\"--output\", required=True, help=\"Path to output JSON file\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    video_path = Path(args.video)\n",
        "    output_path = Path(args.output)\n",
        "\n",
        "    if not video_path.exists():\n",
        "        print(f\"Error: video not found: {video_path}\", file=sys.stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Load YOLO model (football weights if available)\n",
        "    repo_root = Path(__file__).resolve().parent\n",
        "    custom_weights = repo_root / \"yolov8-weights\" / \"yolov8l-football-players.pt\"\n",
        "\n",
        "    if custom_weights.exists():\n",
        "        print(f\"[Darkmyter] Using football-specific weights: {custom_weights}\", file=sys.stderr)\n",
        "        model = YOLO(str(custom_weights))\n",
        "        model_name = \"yolov8l-football\"\n",
        "        football_specific = True\n",
        "    else:\n",
        "        print(\"[Darkmyter] Football weights not found, using yolov8x.pt\", file=sys.stderr)\n",
        "        model = YOLO(\"yolov8x.pt\")\n",
        "        model_name = \"yolov8x\"\n",
        "        football_specific = False\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"[Darkmyter] Device: {device}\", file=sys.stderr)\n",
        "\n",
        "    # --- Open video -----------------------------------------------------------\n",
        "    cap = cv2.VideoCapture(str(video_path))\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: cannot open video: {video_path}\", file=sys.stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    if fps is None or fps <= 0:\n",
        "        fps = 30.0\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) if cap.get(cv2.CAP_PROP_FRAME_COUNT) > 0 else -1\n",
        "\n",
        "    print(f\"[Darkmyter] FPS={fps:.1f}, total_frames={total_frames}\", file=sys.stderr)\n",
        "\n",
        "    # --- Initialize ByteTrack (with proper frame_rate) ------------------------\n",
        "    tracker = BYTETracker(BYTETrackerArgs(), frame_rate=int(round(fps)))\n",
        "\n",
        "    detections_json = []\n",
        "    total_tracks = set()\n",
        "    frame_idx = 0\n",
        "\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Notebook: detections = yolo_model(frame, verbose=0)[0]\n",
        "        results = model(frame, verbose=False)[0]\n",
        "\n",
        "        # \"detections\" in the notebook is iterable; each element is a single-box Results\n",
        "        detections_with_tracker = []\n",
        "        for detection in results:\n",
        "            detection.tracker_id = \"\"  # will be filled in after tracking\n",
        "            detections_with_tracker.append(detection)\n",
        "\n",
        "        if detections_with_tracker:\n",
        "            # get trackers with ByteTrack\n",
        "            bt_input = format_predictions(detections_with_tracker, with_conf=True)\n",
        "\n",
        "            tracks = tracker.update(\n",
        "                output_results=bt_input,\n",
        "                img_info=frame.shape,\n",
        "                img_size=frame.shape,\n",
        "            )\n",
        "\n",
        "            # set tracker_id in yolo detections\n",
        "            detections_with_tracker = match_detections_with_tracks(\n",
        "                detections_with_tracker,\n",
        "                tracks,\n",
        "            )\n",
        "\n",
        "            # Convert to JSON rows\n",
        "            for det in detections_with_tracker:\n",
        "                if det.tracker_id == \"\":\n",
        "                    continue\n",
        "\n",
        "                # Single box per det\n",
        "                bbox = det.boxes.xyxy.tolist()[0]\n",
        "                x1, y1, x2, y2 = map(float, bbox)\n",
        "                conf = float(det.boxes.conf.item())\n",
        "                cls_idx = int(det.boxes.cls.item()) if det.boxes.cls is not None else 0\n",
        "\n",
        "                detections_json.append(\n",
        "                    {\n",
        "                        \"frame_id\": int(frame_idx),\n",
        "                        \"track_id\": int(det.tracker_id),\n",
        "                        \"bbox\": [x1, y1, x2, y2],\n",
        "                        \"score\": conf,\n",
        "                        \"class_id\": cls_idx,\n",
        "                        \"class_name\": IND_TO_CLS.get(cls_idx, \"unknown\"),\n",
        "                    }\n",
        "                )\n",
        "                total_tracks.add(int(det.tracker_id))\n",
        "\n",
        "        if frame_idx % 100 == 0:\n",
        "            if total_frames > 0:\n",
        "                pct = 100.0 * frame_idx / total_frames\n",
        "                print(f\"[Darkmyter] Processed {frame_idx}/{total_frames} frames ({pct:.1f}%)\",\n",
        "                      file=sys.stderr)\n",
        "            else:\n",
        "                print(f\"[Darkmyter] Processed {frame_idx} frames...\", file=sys.stderr)\n",
        "\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    stats = {\n",
        "        \"total_tracks\": len(total_tracks),\n",
        "        \"frames_processed\": frame_idx,\n",
        "    }\n",
        "\n",
        "    full_output = {\n",
        "        \"framework\": \"Darkmyter\",\n",
        "        \"model\": model_name,\n",
        "        \"tracker\": \"ByteTrack (ifzhang/ByteTrack)\",\n",
        "        \"tracker_params\": {\n",
        "            \"track_thresh\": BYTETrackerArgs.track_thresh,\n",
        "            \"track_buffer\": BYTETrackerArgs.track_buffer,\n",
        "            \"match_thresh\": BYTETrackerArgs.match_thresh,\n",
        "            \"aspect_ratio_thresh\": BYTETrackerArgs.aspect_ratio_thresh,\n",
        "            \"min_box_area\": BYTETrackerArgs.min_box_area,\n",
        "        },\n",
        "        \"features\": {\n",
        "            \"football_specific\": football_specific,\n",
        "            \"original_bytetrack\": True,\n",
        "        },\n",
        "        \"detections\": detections_json,\n",
        "        \"statistics\": stats,\n",
        "    }\n",
        "\n",
        "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with output_path.open(\"w\") as f:\n",
        "        json.dump(full_output, f, indent=2)\n",
        "\n",
        "    print(\n",
        "        f\"[Darkmyter] Complete: {len(detections_json)} detections, \"\n",
        "        f\"{stats['total_tracks']} tracks. Output saved to: {output_path}\",\n",
        "        file=sys.stderr,\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "''')\n",
        "\n",
        "darkmyter_wrapper.chmod(0o755)\n",
        "print_status(\"Darkmyter wrapper created (original ByteTrack)\", \"SUCCESS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2ES5pWHUmqE"
      },
      "outputs": [],
      "source": [
        "# Patch ByteTrack for NumPy 1.24+ compatibility\n",
        "import os\n",
        "\n",
        "bytetrack_path = REPOS_DIR / \"darkmyter\" / \"ByteTrack\"\n",
        "\n",
        "# Files that typically have np.float issues\n",
        "for root, dirs, files in os.walk(bytetrack_path):\n",
        "    for file in files:\n",
        "        if file.endswith('.py'):\n",
        "            filepath = os.path.join(root, file)\n",
        "            try:\n",
        "                with open(filepath, 'r') as f:\n",
        "                    content = f.read()\n",
        "\n",
        "                # Replace deprecated numpy aliases\n",
        "                new_content = content\n",
        "                new_content = new_content.replace('np.float,', 'float,')\n",
        "                new_content = new_content.replace('np.float)', 'float)')\n",
        "                new_content = new_content.replace('np.float]', 'float]')\n",
        "                new_content = new_content.replace('np.int,', 'int,')\n",
        "                new_content = new_content.replace('np.int)', 'int)')\n",
        "                new_content = new_content.replace('np.int]', 'int]')\n",
        "\n",
        "                if new_content != content:\n",
        "                    with open(filepath, 'w') as f:\n",
        "                        f.write(new_content)\n",
        "                    print(f\"Patched: {filepath}\")\n",
        "            except Exception as e:\n",
        "                pass\n",
        "\n",
        "print(\"ByteTrack patched for NumPy compatibility\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2I5iE6qiWWTy"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "import ultralytics\n",
        "\n",
        "REPOS_DIR = Path(\"/content/repositories\")\n",
        "ultra_dir = REPOS_DIR / \"ultra_trackers\"\n",
        "ultra_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "# 1) Choose custom configs for bytetrack + botsort\n",
        "runner_script = ultra_dir / \"run_ultra_yolo_tracker.py\"\n",
        "runner_script.write_text(textwrap.dedent(\"\"\"\\\n",
        "    #!/usr/bin/env python\n",
        "    \\\"\\\"\\\"Run Ultralytics YOLO (v5 / v8 / v11 weights) with a chosen tracker and dump JSON tracks.\n",
        "\n",
        "    Usage:\n",
        "      python run_ultra_yolo_tracker.py \\\\\n",
        "          --video input.mp4 \\\\\n",
        "          --output output.json \\\\\n",
        "          --weights yolo11m.pt \\\\\n",
        "          --tracker botsort\n",
        "    \\\"\\\"\\\"\n",
        "\n",
        "    import argparse\n",
        "    import json\n",
        "    from pathlib import Path\n",
        "    from ultralytics import YOLO\n",
        "    import yaml\n",
        "\n",
        "    def main():\n",
        "        parser = argparse.ArgumentParser(description=\"YOLO + tracker to JSON\")\n",
        "        parser.add_argument(\"--video\", required=True, help=\"Path to input video\")\n",
        "        parser.add_argument(\"--output\", required=True, help=\"Path to output JSON\")\n",
        "        parser.add_argument(\n",
        "            \"--weights\",\n",
        "            default=\"yolo11m.pt\",\n",
        "            help=\"YOLO weights (e.g., yolov5s.pt, yolov8n.pt, yolo11m.pt, ...)\",\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--tracker\",\n",
        "            default=\"botsort\",\n",
        "            choices=[\"botsort\", \"bytetrack\", \"deepsort\"],\n",
        "            help=\"Which tracker to use\",\n",
        "        )\n",
        "        parser.add_argument(\"--conf\", type=float, default=0.3,\n",
        "                    help=\"Confidence threshold (detector)\")\n",
        "        parser.add_argument(\"--iou\", type=float, default=0.4,\n",
        "                    help=\"IOU threshold for NMS (lower = keep more boxes)\")\n",
        "        parser.add_argument(\"--imgsz\", type=int, default=1280,\n",
        "                    help=\"Image size for inference\")\n",
        "        parser.add_argument(\"--max-det\", type=int, default=300,\n",
        "                    help=\"Maximum detections per image\")\n",
        "\n",
        "        args = parser.parse_args()\n",
        "\n",
        "        video_path = Path(args.video)\n",
        "        out_path = Path(args.output)\n",
        "\n",
        "        if not video_path.exists():\n",
        "            raise SystemExit(f\"Video not found: {video_path}\")\n",
        "\n",
        "        # Load YOLO model\n",
        "        model = YOLO(args.weights)\n",
        "\n",
        "        # Get the script's directory for saving custom configs\n",
        "        ultra_root = Path(__file__).resolve().parent\n",
        "\n",
        "        # Try to load Ultralytics default configs first\n",
        "        import ultralytics\n",
        "        ultra_path = Path(ultralytics.__file__).parent\n",
        "        tracker_base_path = ultra_path / \"cfg\" / \"trackers\"\n",
        "\n",
        "        # Select the default config path\n",
        "        if args.tracker == \"bytetrack\":\n",
        "            default_cfg_path = tracker_base_path / \"bytetrack.yaml\"\n",
        "        elif args.tracker == \"botsort\":\n",
        "            default_cfg_path = tracker_base_path / \"botsort.yaml\"\n",
        "        else:  # deepsort\n",
        "            default_cfg_path = tracker_base_path / \"deepsort.yaml\"\n",
        "\n",
        "        # Path for our custom config\n",
        "        custom_cfg_path = ultra_root / f\"{args.tracker}_football.yaml\"\n",
        "\n",
        "        # Load and modify the config\n",
        "        if default_cfg_path.exists():\n",
        "            # Load the default config\n",
        "            with open(default_cfg_path, 'r') as f:\n",
        "                tracker_cfg = yaml.safe_load(f)\n",
        "\n",
        "            # Modify with football-optimized values from tracklab\n",
        "\n",
        "            if args.tracker == \"botsort\":\n",
        "                tracker_cfg.update({\n",
        "                    \"track_high_thresh\": 0.33824964456239337,\n",
        "                    \"new_track_thresh\": 0.21144301345190655,\n",
        "                    \"track_buffer\": 60,\n",
        "                    \"match_thresh\": 0.22734550911325851,\n",
        "                    \"proximity_thresh\": 0.5945380911899254,\n",
        "                    \"appearance_thresh\": 0.4818211117541298,\n",
        "                    \"cmc_method\": \"sparseOptFlow\",\n",
        "                    \"frame_rate\": 30,\n",
        "                    \"lambda_\": 0.9896143462366406,\n",
        "                    \"conf_thres\": 0.3501265956918775,\n",
        "                    \"with_reid\": True\n",
        "                })\n",
        "\n",
        "            # Save the modified config to a file\n",
        "            with open(custom_cfg_path, 'w') as f:\n",
        "                yaml.dump(tracker_cfg, f)\n",
        "\n",
        "            # Use the custom config FILE PATH (not the dictionary!)\n",
        "            tracker_cfg_path = str(custom_cfg_path)\n",
        "        else:\n",
        "            # Fallback: just use the default tracker name\n",
        "            print(f\"Warning: Could not find default config at {default_cfg_path}\")\n",
        "            print(f\"Using default tracker: {args.tracker}.yaml\")\n",
        "            tracker_cfg_path = f\"{args.tracker}.yaml\"\n",
        "\n",
        "        # Run tracking with the config FILE PATH\n",
        "        results = model.track(\n",
        "            source=str(video_path),\n",
        "            tracker=tracker_cfg_path,  # Pass the FILE PATH, not dictionary!\n",
        "            conf=args.conf,\n",
        "            iou=args.iou,\n",
        "            imgsz=args.imgsz,\n",
        "            max_det=args.max_det,\n",
        "            stream=True,\n",
        "            device=0,\n",
        "            save=False,\n",
        "            verbose=False,\n",
        "            persist=True,\n",
        "            vid_stride=1,\n",
        "        )\n",
        "\n",
        "        print(f\"Tracking with {args.tracker} on device: {model.device}\")\n",
        "\n",
        "        all_detections = []\n",
        "        frame_idx = 0\n",
        "\n",
        "        for r in results:\n",
        "            boxes = r.boxes\n",
        "            if boxes is None:\n",
        "                frame_idx += 1\n",
        "                continue\n",
        "\n",
        "            ids = boxes.id\n",
        "            if ids is None:\n",
        "                frame_idx += 1\n",
        "                continue\n",
        "\n",
        "            xyxy = boxes.xyxy\n",
        "            confs = boxes.conf\n",
        "            clses = boxes.cls\n",
        "\n",
        "            ids = ids.cpu().tolist()\n",
        "            xyxy = xyxy.cpu().tolist()\n",
        "            confs = confs.cpu().tolist()\n",
        "            clses = clses.cpu().tolist()\n",
        "\n",
        "            for tid, (x1, y1, x2, y2), score, c in zip(ids, xyxy, confs, clses):\n",
        "                all_detections.append({\n",
        "                    \"frame_id\": frame_idx,\n",
        "                    \"track_id\": int(tid),\n",
        "                    \"bbox\": [float(x1), float(y1), float(x2), float(y2)],\n",
        "                    \"score\": float(score),\n",
        "                    \"class_id\": int(c),\n",
        "                })\n",
        "\n",
        "            frame_idx += 1\n",
        "\n",
        "        out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        with out_path.open(\"w\") as f:\n",
        "            json.dump(all_detections, f)\n",
        "\n",
        "        print(f\"Wrote {len(all_detections)} tracked detections to {out_path}\")\n",
        "\n",
        "\n",
        "    if __name__ == \"__main__\":\n",
        "        main()\n",
        "    \"\"\"))\n",
        "\n",
        "runner_script.chmod(0o755)\n",
        "print_status(\"Created wrapper for Botsort and Bytetrack\", \"SUCCESS\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jIMyv7HMfsbb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Cell: Setup Eagle with Python 3.13\n",
        "\n",
        "print_status(\"Setting up Eagle with Python 3.13...\", \"INFO\")\n",
        "\n",
        "eagle_dir = REPOS_DIR / \"eagle\"\n",
        "\n",
        "# Install Python 3.13 (Eagle's required version)\n",
        "print_status(\"Installing Python 3.13...\", \"INFO\")\n",
        "!apt-get update -qq\n",
        "!apt-get install -y software-properties-common\n",
        "!add-apt-repository -y ppa:deadsnakes/ppa\n",
        "!apt-get update -qq\n",
        "!apt-get install -y python3.13 python3.13-venv python3.13-dev python3.13-distutils\n",
        "\n",
        "# Install pip for Python 3.13\n",
        "!curl -sS https://bootstrap.pypa.io/get-pip.py | python3.13\n",
        "\n",
        "# Install uv if not already installed\n",
        "print_status(\"Installing uv...\", \"INFO\")\n",
        "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "\n",
        "# Add uv to PATH\n",
        "import os\n",
        "os.environ['PATH'] = f\"/root/.local/bin:{os.environ['PATH']}\"\n",
        "\n",
        "# Create Eagle environment with Python 3.13\n",
        "os.chdir(eagle_dir)\n",
        "print_status(\"Creating Eagle environment with Python 3.13...\", \"INFO\")\n",
        "!uv venv --python python3.13\n",
        "!uv sync\n",
        "\n",
        "# Download model weights\n",
        "print_status(\"Downloading Eagle model weights...\", \"INFO\")\n",
        "models_dir = eagle_dir / \"eagle\" / \"models\"\n",
        "if models_dir.exists():\n",
        "    os.chdir(models_dir)\n",
        "    !bash get_weights.sh\n",
        "    os.chdir(eagle_dir)\n",
        "    print_status(\"Eagle weights downloaded\", \"SUCCESS\")\n",
        "else:\n",
        "    print_status(\"Eagle models directory not found\", \"ERROR\")\n",
        "\n",
        "# Create Eagle wrapper that uses Python 3.13\n",
        "\n",
        "eagle_wrapper = eagle_dir / \"run_eagle.py\"\n",
        "eagle_wrapper.write_text('''\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Clean Eagle wrapper that produces a single output file\n",
        "Outputs Eagle's native raw format directly\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "\n",
        "def get_eagle_output(eagle_output_dir):\n",
        "    \"\"\"\n",
        "    Find and return Eagle's raw output data\n",
        "\n",
        "    Args:\n",
        "        eagle_output_dir: Path to Eagle's output directory\n",
        "\n",
        "    Returns:\n",
        "        Raw Eagle data dictionary\n",
        "    \"\"\"\n",
        "    coords_dir = eagle_output_dir / \"raw_coordinates\"\n",
        "    if not coords_dir.exists():\n",
        "        coords_dir = eagle_output_dir\n",
        "\n",
        "    raw_coords_file = coords_dir / \"raw_coordinates.json\"\n",
        "    raw_data_file = coords_dir / \"raw_data.json\"\n",
        "    processed_file = coords_dir / \"processed_data.json\"\n",
        "\n",
        "    data = None\n",
        "    source_file = None\n",
        "\n",
        "    for file_path in [raw_coords_file, processed_file, raw_data_file]:\n",
        "        if file_path.exists():\n",
        "            with open(file_path, 'r') as f:\n",
        "                data = json.load(f)\n",
        "            source_file = file_path\n",
        "            print(f\"[Eagle] Using {file_path.name} as source\", file=sys.stderr)\n",
        "            break\n",
        "\n",
        "    if data is None:\n",
        "        json_files = list(coords_dir.glob(\"*.json\"))\n",
        "        if json_files:\n",
        "            with open(json_files[0], 'r') as f:\n",
        "                data = json.load(f)\n",
        "            source_file = json_files[0]\n",
        "            print(f\"[Eagle] Using {json_files[0].name} as source\", file=sys.stderr)\n",
        "\n",
        "    if data is None:\n",
        "        print(f\"[Eagle] No output files found in {coords_dir}\", file=sys.stderr)\n",
        "        raise FileNotFoundError(f\"No Eagle JSON outputs found in {coords_dir}\")\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description='Eagle wrapper for unified output')\n",
        "    parser.add_argument('--video', required=True, help='Path to input video')\n",
        "    parser.add_argument('--output', required=True, help='Path to output JSON file')\n",
        "    parser.add_argument('--fps', default=24, type=int, help='FPS to process (default: 24)')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    video_path = Path(args.video)\n",
        "    output_path = Path(args.output)\n",
        "\n",
        "    if not video_path.exists():\n",
        "        print(f\"Error: Video not found: {video_path}\", file=sys.stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    env = os.environ.copy()\n",
        "    env[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "    cmd = [\n",
        "        \"uv\", \"run\", \"--python\", \"python3.13\",\n",
        "        \"main.py\",\n",
        "        \"--video_path\", str(video_path),\n",
        "        \"--fps\", str(args.fps),\n",
        "    ]\n",
        "\n",
        "    print(f\"[Eagle] Processing {video_path.name} at {args.fps} FPS...\", file=sys.stderr)\n",
        "    start = time.time()\n",
        "\n",
        "    eagle_dir = Path(__file__).parent\n",
        "    result = subprocess.run(\n",
        "        cmd,\n",
        "        capture_output=True,\n",
        "        text=True,\n",
        "        cwd=eagle_dir,\n",
        "        env=env,\n",
        "    )\n",
        "\n",
        "    elapsed = time.time() - start\n",
        "    print(f\"[Eagle] Processing took {elapsed:.1f}s\", file=sys.stderr)\n",
        "\n",
        "    if result.returncode != 0:\n",
        "        print(f\"[Eagle] Warning: Process returned {result.returncode}\", file=sys.stderr)\n",
        "        if result.stderr:\n",
        "            print(f\"[Eagle] Stderr: {result.stderr[:500]}\", file=sys.stderr)\n",
        "\n",
        "    video_stem = video_path.stem\n",
        "    eagle_output_base = eagle_dir / \"output\"\n",
        "    eagle_output_dir = eagle_output_base / video_stem\n",
        "\n",
        "    if not eagle_output_dir.exists():\n",
        "        for d in eagle_output_base.iterdir():\n",
        "            if d.is_dir() and video_stem in d.name:\n",
        "                eagle_output_dir = d\n",
        "                break\n",
        "\n",
        "    if not eagle_output_dir.exists():\n",
        "        print(f\"[Eagle] Error: Could not find output directory for {video_stem}\", file=sys.stderr)\n",
        "        with open(output_path, 'w') as f:\n",
        "            json.dump([], f)\n",
        "        sys.exit(1)\n",
        "\n",
        "    try:\n",
        "        print(f\"[Eagle] Consolidating output from {eagle_output_dir}\", file=sys.stderr)\n",
        "        raw_data = get_eagle_output(eagle_output_dir)\n",
        "    except Exception as e:\n",
        "        print(f\"[Eagle] Error while getting Eagle output: {e}\", file=sys.stderr)\n",
        "        with open(output_path, \"w\") as f:\n",
        "            json.dump([], f)\n",
        "        sys.exit(1)\n",
        "\n",
        "    with open(output_path, 'w') as f:\n",
        "        json.dump(raw_data, f, indent=2)\n",
        "\n",
        "    if isinstance(raw_data, dict):\n",
        "        print(f\"[Eagle] Output: {len(raw_data)} frames (raw format)\", file=sys.stderr)\n",
        "    elif isinstance(raw_data, list):\n",
        "        print(f\"[Eagle] Output: {len(raw_data)} frames\", file=sys.stderr)\n",
        "\n",
        "    print(f\"[Eagle] Saved to: {output_path}\", file=sys.stderr)\n",
        "    sys.exit(0)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "''')\n",
        "\n",
        "eagle_wrapper.chmod(0o755)\n",
        "print_status(\"Eagle  wrapper created\", \"SUCCESS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwKkf9KCsLQY"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# Base folder on Drive where all results will go\n",
        "BASE_DIR = Path(\"/content/drive/MyDrive/tracklab_eval\")  # change name if you like\n",
        "OUTPUT_DIR = BASE_DIR / \"results\"\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Results will be saved under:\", OUTPUT_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EMRXc5GpkG4d"
      },
      "outputs": [],
      "source": [
        "# Cell: Final System Evaluation\n",
        "\n",
        "import time\n",
        "import json\n",
        "import subprocess\n",
        "import os\n",
        "import psutil\n",
        "import threading\n",
        "from pathlib import Path\n",
        "\n",
        "# System configurations\n",
        "SYSTEM_CONFIGS = {\n",
        "    \"eagle\": {\n",
        "        \"path\": REPOS_DIR / \"eagle\",\n",
        "        \"script\": \"run_eagle.py\",\n",
        "        \"python\": \"python3.13\",\n",
        "    },\n",
        "    \"yolo11_botsort\": {\n",
        "        \"path\": REPOS_DIR / \"ultra_trackers\",\n",
        "        \"script\": \"run_ultra_yolo_tracker.py\",\n",
        "        \"args\": [\"--weights\", \"yolo11m.pt\", \"--tracker\", \"botsort\"],\n",
        "    },\n",
        "    \"darkmyter\": {\n",
        "        \"path\": REPOS_DIR / \"darkmyter\",\n",
        "        \"script\": \"run_darkmyter.py\",\n",
        "    },\n",
        "}\n",
        "\n",
        "def get_gpu_memory():\n",
        "    \"\"\"Get current GPU memory usage in MB using nvidia-smi\"\"\"\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            ['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader'],\n",
        "            capture_output=True, text=True\n",
        "        )\n",
        "        return int(result.stdout.strip().split('\\n')[0])\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def monitor_memory(stop_event, memory_stats):\n",
        "    \"\"\"Background thread to sample memory usage\"\"\"\n",
        "    memory_stats['peak_ram_mb'] = 0\n",
        "    memory_stats['peak_gpu_mb'] = 0\n",
        "\n",
        "    while not stop_event.is_set():\n",
        "        ram_mb = psutil.virtual_memory().used / (1024 * 1024)\n",
        "        memory_stats['peak_ram_mb'] = max(memory_stats['peak_ram_mb'], ram_mb)\n",
        "\n",
        "        gpu_mb = get_gpu_memory()\n",
        "        if gpu_mb:\n",
        "            memory_stats['peak_gpu_mb'] = max(memory_stats['peak_gpu_mb'], gpu_mb)\n",
        "\n",
        "        stop_event.wait(0.5)\n",
        "\n",
        "# Ask user for processing mode\n",
        "print(\"EVALUATION MODE SELECTION \\n\")\n",
        "print(\"\\nHow do you want to evaluate the videos?\")\n",
        "print(\"  1. Use clips (faster - 60s segments)\")\n",
        "print(\"  2. Use full videos (comprehensive but slower)\")\n",
        "\n",
        "mode_choice = input(\"\\nEnter your choice (1 or 2): \").strip()\n",
        "USE_CLIPS = mode_choice != '2'\n",
        "\n",
        "if USE_CLIPS:\n",
        "    print_status(\"Mode: CLIP-BASED EVALUATION\", \"INFO\")\n",
        "    ALL_VIDEOS = VIDEO_CLIPS\n",
        "    eval_type = \"clips\"\n",
        "else:\n",
        "    print_status(\"Mode: FULL VIDEO EVALUATION\", \"INFO\")\n",
        "    ALL_VIDEOS = FULL_VIDEOS\n",
        "    eval_type = \"full\"\n",
        "\n",
        "position_to_number = {\"start\": 1, \"middle\": 2, \"end\": 3, \"full\": 1}\n",
        "\n",
        "def run_system_on_video(system_name, system_config, video_name, segment_name, video_path):\n",
        "    \"\"\"Run a tracking system on a video or clip\"\"\"\n",
        "\n",
        "    if USE_CLIPS:\n",
        "        segment_number = position_to_number.get(segment_name, 1)\n",
        "        output_dir = OUTPUT_DIR / video_name / \"clips\" / str(segment_number) / system_name\n",
        "    else:\n",
        "        output_dir = OUTPUT_DIR / video_name / \"full\" / system_name\n",
        "\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if USE_CLIPS:\n",
        "        print_status(f\"Running {system_name} on {video_name}/clip_{segment_number}...\", \"INFO\")\n",
        "    else:\n",
        "        print_status(f\"Running {system_name} on {video_name} (full video)...\", \"INFO\")\n",
        "\n",
        "    output_file = output_dir / f\"{system_name}_output.json\"\n",
        "    system_path = system_config.get(\"path\", REPOS_DIR)\n",
        "\n",
        "    # Build command\n",
        "    if system_name == \"eagle\":\n",
        "        cmd = [\n",
        "            \"uv\", \"run\", \"--python\", system_config.get(\"python\", \"python3.13\"),\n",
        "            \"run_eagle.py\",\n",
        "            \"--video\", str(video_path),\n",
        "            \"--output\", str(output_file),\n",
        "        ]\n",
        "    else:\n",
        "        cmd = [\n",
        "            \"python\", system_config[\"script\"],\n",
        "            \"--video\", str(video_path),\n",
        "            \"--output\", str(output_file),\n",
        "        ] + [str(extra) for extra in system_config.get(\"args\", [])]\n",
        "\n",
        "    # Get baseline memory before starting\n",
        "    baseline_ram = psutil.virtual_memory().used / (1024 * 1024)\n",
        "    baseline_gpu = get_gpu_memory() or 0\n",
        "\n",
        "    # Start memory monitoring\n",
        "    memory_stats = {}\n",
        "    stop_event = threading.Event()\n",
        "    monitor_thread = threading.Thread(target=monitor_memory, args=(stop_event, memory_stats))\n",
        "    monitor_thread.start()\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            cmd,\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            cwd=str(system_path),\n",
        "        )\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        # Stop monitoring\n",
        "        stop_event.set()\n",
        "        monitor_thread.join()\n",
        "\n",
        "        # Calculate peak usage above baseline\n",
        "        peak_ram_delta = max(0, memory_stats.get('peak_ram_mb', 0) - baseline_ram)\n",
        "        peak_gpu_delta = max(0, memory_stats.get('peak_gpu_mb', 0) - baseline_gpu)\n",
        "\n",
        "        if result.returncode == 0 and output_file.exists():\n",
        "            try:\n",
        "                with open(output_file) as f:\n",
        "                    data = json.load(f)\n",
        "\n",
        "                if isinstance(data, list):\n",
        "                    num_detections = len(data)\n",
        "                elif isinstance(data, dict):\n",
        "                    num_detections = sum(\n",
        "                        len(dets) if isinstance(dets, list) else 0\n",
        "                        for dets in data.values()\n",
        "                    )\n",
        "                else:\n",
        "                    num_detections = 0\n",
        "\n",
        "                print_status(\n",
        "                    f\"{system_name}: SUCCESS - {num_detections} detections in {elapsed:.1f}s \"\n",
        "                    f\"(RAM: +{peak_ram_delta:.0f}MB, GPU: +{peak_gpu_delta:.0f}MB)\",\n",
        "                    \"SUCCESS\",\n",
        "                )\n",
        "                return {\n",
        "                    \"success\": True,\n",
        "                    \"time\": elapsed,\n",
        "                    \"output\": str(output_file),\n",
        "                    \"detections\": num_detections,\n",
        "                    \"peak_ram_mb\": peak_ram_delta,\n",
        "                    \"peak_gpu_mb\": peak_gpu_delta,\n",
        "                }\n",
        "\n",
        "            except json.JSONDecodeError as e:\n",
        "                print_status(f\"{system_name}: Invalid JSON\", \"ERROR\")\n",
        "                return {\n",
        "                    \"success\": False,\n",
        "                    \"time\": elapsed,\n",
        "                    \"error\": f\"Invalid JSON: {e}\",\n",
        "                    \"peak_ram_mb\": peak_ram_delta,\n",
        "                    \"peak_gpu_mb\": peak_gpu_delta,\n",
        "                }\n",
        "        else:\n",
        "            error_msg = result.stderr[-500:] if result.stderr else \"Unknown error\"\n",
        "            print_status(f\"{system_name}: FAILED\", \"ERROR\")\n",
        "            print(f\"Error: {error_msg}\")\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"time\": elapsed,\n",
        "                \"error\": error_msg,\n",
        "                \"peak_ram_mb\": peak_ram_delta,\n",
        "                \"peak_gpu_mb\": peak_gpu_delta,\n",
        "            }\n",
        "\n",
        "    except subprocess.TimeoutExpired:\n",
        "        stop_event.set()\n",
        "        monitor_thread.join()\n",
        "        peak_ram_delta = max(0, memory_stats.get('peak_ram_mb', 0) - baseline_ram)\n",
        "        peak_gpu_delta = max(0, memory_stats.get('peak_gpu_mb', 0) - baseline_gpu)\n",
        "        print_status(f\"{system_name}: TIMEOUT\", \"ERROR\")\n",
        "        return {\n",
        "            \"success\": False,\n",
        "            \"time\": 10000,\n",
        "            \"error\": \"Timeout\",\n",
        "            \"peak_ram_mb\": peak_ram_delta,\n",
        "            \"peak_gpu_mb\": peak_gpu_delta,\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        stop_event.set()\n",
        "        monitor_thread.join()\n",
        "        peak_ram_delta = max(0, memory_stats.get('peak_ram_mb', 0) - baseline_ram)\n",
        "        peak_gpu_delta = max(0, memory_stats.get('peak_gpu_mb', 0) - baseline_gpu)\n",
        "        print_status(f\"{system_name}: EXCEPTION - {str(e)}\", \"ERROR\")\n",
        "        return {\n",
        "            \"success\": False,\n",
        "            \"time\": time.time() - start_time,\n",
        "            \"error\": str(e),\n",
        "            \"peak_ram_mb\": peak_ram_delta,\n",
        "            \"peak_gpu_mb\": peak_gpu_delta,\n",
        "        }\n",
        "\n",
        "def save_progress(all_results, eval_type):\n",
        "    \"\"\"Save current progress to disk (in Drive, via OUTPUT_DIR)\"\"\"\n",
        "    progress_file = OUTPUT_DIR / f\"progress_{eval_type}.json\"\n",
        "    with open(progress_file, \"w\") as f:\n",
        "        json.dump(all_results, f, indent=2)\n",
        "    return progress_file\n",
        "\n",
        "def load_progress(eval_type):\n",
        "    \"\"\"Load existing progress if available\"\"\"\n",
        "    progress_file = OUTPUT_DIR / f\"progress_{eval_type}.json\"\n",
        "    if progress_file.exists():\n",
        "        try:\n",
        "            with open(progress_file) as f:\n",
        "                return json.load(f)\n",
        "        except Exception:\n",
        "            return {}\n",
        "    return {}\n",
        "\n",
        "print(f\"STARTING {eval_type.upper()} EVALUATION\\n\")\n",
        "\n",
        "all_results = load_progress(eval_type)\n",
        "if all_results:\n",
        "    print_status(f\"Loaded existing progress with {len(all_results)} videos\", \"INFO\")\n",
        "    print(\"Videos already processed:\")\n",
        "    for video_name in all_results.keys():\n",
        "        print(f\"  - {video_name}\")\n",
        "\n",
        "    print(\"\\nDo you want to:\")\n",
        "    print(\"  1. Continue from where you left off\")\n",
        "    print(\"  2. Start fresh (delete existing progress)\")\n",
        "    continue_choice = input(\"\\nEnter your choice (1 or 2): \").strip()\n",
        "\n",
        "    if continue_choice == '2':\n",
        "        all_results = {}\n",
        "        print_status(\"Starting fresh evaluation\", \"INFO\")\n",
        "\n",
        "for video_name, segments in ALL_VIDEOS.items():\n",
        "    print(f\"\\nVIDEO: {video_name}\")\n",
        "\n",
        "    video_results = all_results.get(video_name, {})\n",
        "\n",
        "    for segment_name, video_path in segments.items():\n",
        "        if USE_CLIPS:\n",
        "            segment_number = position_to_number.get(segment_name, 1)\n",
        "            segment_key = f\"clip_{segment_number}\"\n",
        "            print(f\"\\nProcessing clip {segment_number} ({segment_name})...\")\n",
        "        else:\n",
        "            segment_key = \"full\"\n",
        "            print(f\"\\nProcessing full video...\")\n",
        "\n",
        "        segment_results = video_results.get(segment_key, {})\n",
        "        video_results[segment_key] = segment_results\n",
        "\n",
        "        for system_name, system_config in SYSTEM_CONFIGS.items():\n",
        "            if system_name in segment_results and segment_results[system_name].get(\"success\"):\n",
        "                print_status(f\"{system_name}: Already completed successfully\", \"SKIP\")\n",
        "                continue\n",
        "            elif system_name in segment_results:\n",
        "                print_status(f\"{system_name}: Retrying previous failure\", \"RETRY\")\n",
        "\n",
        "            result = run_system_on_video(\n",
        "                system_name, system_config, video_name, segment_name, video_path\n",
        "            )\n",
        "            segment_results[system_name] = result\n",
        "\n",
        "            all_results[video_name] = video_results\n",
        "            progress_file = save_progress(all_results, eval_type)\n",
        "            print_status(f\"Progress saved to {progress_file.name}\", \"SAVE\")\n",
        "\n",
        "        successful = sum(1 for r in segment_results.values() if r.get(\"success\", False))\n",
        "        total = len(segment_results)\n",
        "\n",
        "        if USE_CLIPS:\n",
        "            print(f\"\\nClip summary: {successful}/{total} systems succeeded\")\n",
        "        else:\n",
        "            print(f\"\\nVideo summary: {successful}/{total} systems succeeded\")\n",
        "\n",
        "    summary_file = OUTPUT_DIR / video_name / f\"summary_{eval_type}.json\"\n",
        "    summary_file.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with open(summary_file, \"w\") as f:\n",
        "        json.dump(video_results, f, indent=2)\n",
        "    print_status(f\"Video summary saved to {summary_file.name}\", \"SAVE\")\n",
        "\n",
        "# Save overall summary\n",
        "overall_summary = OUTPUT_DIR / f\"overall_summary_{eval_type}.json\"\n",
        "with open(overall_summary, \"w\") as f:\n",
        "    json.dump(all_results, f, indent=2)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(f\"{eval_type.upper()} EVALUATION COMPLETE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "system_stats = {\n",
        "    sys: {\n",
        "        \"success\": 0,\n",
        "        \"total\": 0,\n",
        "        \"avg_time\": [],\n",
        "        \"avg_detections\": [],\n",
        "        \"avg_ram\": [],\n",
        "        \"avg_gpu\": [],\n",
        "    }\n",
        "    for sys in SYSTEM_CONFIGS.keys()\n",
        "}\n",
        "\n",
        "for video_results in all_results.values():\n",
        "    for segment_results in video_results.values():\n",
        "        for system_name, result in segment_results.items():\n",
        "            if system_name in system_stats:\n",
        "                system_stats[system_name][\"total\"] += 1\n",
        "                if result.get(\"success\", False):\n",
        "                    system_stats[system_name][\"success\"] += 1\n",
        "                    if \"time\" in result:\n",
        "                        system_stats[system_name][\"avg_time\"].append(result[\"time\"])\n",
        "                    if \"detections\" in result:\n",
        "                        system_stats[system_name][\"avg_detections\"].append(result[\"detections\"])\n",
        "                    if \"peak_ram_mb\" in result:\n",
        "                        system_stats[system_name][\"avg_ram\"].append(result[\"peak_ram_mb\"])\n",
        "                    if \"peak_gpu_mb\" in result:\n",
        "                        system_stats[system_name][\"avg_gpu\"].append(result[\"peak_gpu_mb\"])\n",
        "\n",
        "print(\"\\nSystem Performance Summary:\")\n",
        "print(\"-\" * 50)\n",
        "for system_name, stats in system_stats.items():\n",
        "    if stats[\"total\"] > 0:\n",
        "        success_rate = (stats[\"success\"] / stats[\"total\"]) * 100\n",
        "        print(f\"\\n{system_name}:\")\n",
        "        print(f\"  Success Rate: {stats['success']}/{stats['total']} ({success_rate:.1f}%)\")\n",
        "        if stats[\"avg_time\"]:\n",
        "            avg_time = sum(stats[\"avg_time\"]) / len(stats[\"avg_time\"])\n",
        "            print(f\"  Avg Time: {avg_time:.1f}s\")\n",
        "        if stats[\"avg_detections\"]:\n",
        "            avg_det = sum(stats[\"avg_detections\"]) / len(stats[\"avg_detections\"])\n",
        "            print(f\"  Avg Detections: {avg_det:.0f}\")\n",
        "        if stats[\"avg_ram\"]:\n",
        "            avg_ram = sum(stats[\"avg_ram\"]) / len(stats[\"avg_ram\"])\n",
        "            max_ram = max(stats[\"avg_ram\"])\n",
        "            print(f\"  Avg RAM: +{avg_ram:.0f}MB (peak: +{max_ram:.0f}MB)\")\n",
        "        if stats[\"avg_gpu\"]:\n",
        "            avg_gpu = sum(stats[\"avg_gpu\"]) / len(stats[\"avg_gpu\"])\n",
        "            max_gpu = max(stats[\"avg_gpu\"])\n",
        "            print(f\"  Avg GPU: +{avg_gpu:.0f}MB (peak: +{max_gpu:.0f}MB)\")\n",
        "\n",
        "print(f\"\\nResults Directory: {OUTPUT_DIR}\")\n",
        "print(f\"Overall Summary: {overall_summary}\")\n",
        "print(f\"Progress File: {OUTPUT_DIR / f'progress_{eval_type}.json'}\")\n",
        "\n",
        "total_expected = len(ALL_VIDEOS) * len(next(iter(ALL_VIDEOS.values())))\n",
        "total_processed = sum(len(video_results) for video_results in all_results.values())\n",
        "\n",
        "if total_processed == total_expected:\n",
        "    print(\"\\n\")\n",
        "    print(\"ALL VIDEOS PROCESSED SUCCESSFULLY!\")\n",
        "    print(\"Progress file kept for reference.\")\n",
        "else:\n",
        "    print(\"\\n\")\n",
        "    print(f\"PARTIAL COMPLETION: {total_processed}/{total_expected} segments processed\")\n",
        "    print(\"Run the script again to continue from where you left off.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0imTFkAc84oC"
      },
      "outputs": [],
      "source": [
        "#Cell 10: Download pre-run results from google.\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.path.exists(\"/content/results\"):\n",
        "    !gdown 1-TR0bycui1zpL5TRZLzhdxcuJIv9qLUO -O results.zip\n",
        "    !unzip results.zip -d /content\n",
        "    print(\"Using cached results\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download"
      },
      "outputs": [],
      "source": [
        "# Cell 9: Download results\n",
        "\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "print_status(\"Creating archive...\", \"INFO\")\n",
        "\n",
        "archive_name = \"tracking_results\"\n",
        "archive_path = BASE_DIR / archive_name\n",
        "\n",
        "shutil.make_archive(str(archive_path), 'zip', OUTPUT_DIR)\n",
        "\n",
        "print_status(\"Downloading...\", \"SUCCESS\")\n",
        "files.download(f\"{archive_path}.zip\")\n",
        "\n",
        "print_status(\"Complete!\", \"SUCCESS\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": [],
      "generative_ai_disabled": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}