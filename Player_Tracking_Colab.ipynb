{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# Player Tracking System Comparison\n",
        "\n",
        "This notebook compares 3 different player tracking systems:\n",
        "- Eagle\n",
        "- Darkmyter (using Ultralytics YOLO)\n",
        "- TrackLab\n",
        "\n",
        "**Important**: Run cells in order from top to bottom!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "setup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bed4526-df4e-4060-f6e8-27b132679858"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m[SUCCESS] Directory structure created\u001b[0m\n",
            "Working directory: /content\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Setup directories and utilities\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "BASE_DIR = Path(\"/content\")\n",
        "REPOS_DIR = BASE_DIR / \"repositories\"\n",
        "VIDEOS_DIR = BASE_DIR / \"videos\"\n",
        "CLIPS_DIR = BASE_DIR / \"clips\"\n",
        "OUTPUT_DIR = BASE_DIR / \"output\"\n",
        "\n",
        "for d in [REPOS_DIR, VIDEOS_DIR, CLIPS_DIR, OUTPUT_DIR]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def print_status(msg, status=\"INFO\"):\n",
        "    \"\"\"Print colored status messages\"\"\"\n",
        "    colors = {\n",
        "        \"INFO\": \"\\033[94m\",\n",
        "        \"SUCCESS\": \"\\033[92m\",\n",
        "        \"WARNING\": \"\\033[93m\",\n",
        "        \"ERROR\": \"\\033[91m\",\n",
        "        \"RESET\": \"\\033[0m\"\n",
        "    }\n",
        "    print(f\"{colors.get(status, '')}[{status}] {msg}{colors['RESET']}\")\n",
        "\n",
        "print_status(\"Directory structure created\", \"SUCCESS\")\n",
        "print(f\"Working directory: {BASE_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "clone",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04192215-0ffb-4dce-ffde-e581a5e085d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Cloning repositories...\u001b[0m\n",
            "\u001b[94m[INFO] eagle: Cloning...\u001b[0m\n",
            "\u001b[92m[SUCCESS] eagle: Cloned successfully\u001b[0m\n",
            "\u001b[94m[INFO] darkmyter: Cloning...\u001b[0m\n",
            "\u001b[92m[SUCCESS] darkmyter: Cloned successfully\u001b[0m\n",
            "\u001b[94m[INFO] tracklab: Cloning...\u001b[0m\n",
            "\u001b[92m[SUCCESS] tracklab: Cloned successfully\u001b[0m\n",
            "\u001b[92m[SUCCESS] Repository cloning complete\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Clone all repositories\n",
        "\n",
        "import subprocess\n",
        "\n",
        "REPOSITORIES = {\n",
        "    \"eagle\": \"https://github.com/nreHieW/Eagle.git\",\n",
        "    \"darkmyter\": \"https://github.com/Darkmyter/Football-Players-Tracking.git\",\n",
        "    \"tracklab\": \"https://github.com/TrackingLaboratory/tracklab.git\"\n",
        "}\n",
        "\n",
        "print_status(\"Cloning repositories...\", \"INFO\")\n",
        "\n",
        "for name, url in REPOSITORIES.items():\n",
        "    repo_path = REPOS_DIR / name\n",
        "\n",
        "    if repo_path.exists():\n",
        "        print_status(f\"{name}: Already exists, skipping\", \"WARNING\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        print_status(f\"{name}: Cloning...\", \"INFO\")\n",
        "        result = subprocess.run(\n",
        "            [\"git\", \"clone\", url, str(repo_path)],\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=300\n",
        "        )\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            print_status(f\"{name}: Cloned successfully\", \"SUCCESS\")\n",
        "        else:\n",
        "            print_status(f\"{name}: Clone failed - {result.stderr[:100]}\", \"ERROR\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print_status(f\"{name}: Clone failed - {str(e)}\", \"ERROR\")\n",
        "\n",
        "print_status(\"Repository cloning complete\", \"SUCCESS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "install",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "556b566a-2daa-4634-adf6-df4bf48b9b75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Installing dependencies...\u001b[0m\n",
            "\u001b[92m[SUCCESS] Dependencies installed\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Install dependencies\n",
        "\n",
        "print_status(\"Installing dependencies...\", \"INFO\")\n",
        "\n",
        "!pip install -q torch torchvision torchaudio tracklab\n",
        "!pip install -q opencv-python numpy scipy pandas scikit-learn matplotlib\n",
        "!pip install -q ultralytics supervision\n",
        "!pip install -q gdown Pillow tqdm requests\n",
        "\n",
        "print_status(\"Dependencies installed\", \"SUCCESS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "download_videos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4dfaeb5-a607-4bde-aac9-6e765184b5f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Downloading videos from shared folder...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1uXckJCK4pVPfoRvJWaZmtM_uH6pFQogf FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720.mp4\n",
            "Processing file 1RvqkxASOD23jfigqSgSgGja5_NGZReO4 FULL MATCH  Brazil v Mexico  World Cup 2018 720p.mp4\n",
            "Processing file 1urwKF6wjitkREymiNi9O3jCLLIysTp6F FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1uXckJCK4pVPfoRvJWaZmtM_uH6pFQogf\n",
            "From (redirected): https://drive.google.com/uc?id=1uXckJCK4pVPfoRvJWaZmtM_uH6pFQogf&confirm=t&uuid=eac5e386-ae9a-4914-a545-2df267f48772\n",
            "To: /content/videos/FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720.mp4\n",
            "100%|██████████| 1.68G/1.68G [00:17<00:00, 97.9MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1RvqkxASOD23jfigqSgSgGja5_NGZReO4\n",
            "From (redirected): https://drive.google.com/uc?id=1RvqkxASOD23jfigqSgSgGja5_NGZReO4&confirm=t&uuid=7cbcbc67-bfda-4454-9a6d-0a96920ea70b\n",
            "To: /content/videos/FULL MATCH  Brazil v Mexico  World Cup 2018 720p.mp4\n",
            "100%|██████████| 1.92G/1.92G [00:18<00:00, 105MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1urwKF6wjitkREymiNi9O3jCLLIysTp6F\n",
            "From (redirected): https://drive.google.com/uc?id=1urwKF6wjitkREymiNi9O3jCLLIysTp6F&confirm=t&uuid=75d4854f-3780-4410-bb3b-819ef12c425c\n",
            "To: /content/videos/FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p.mp4\n",
            "100%|██████████| 1.32G/1.32G [00:13<00:00, 96.9MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DOWNLOADED 3 VIDEO(S)\n",
            "1. FULL MATCH  Croatia 1-1 Czechia  VIP Tactical Camera 720p.mp4 (1260.8 MB)\n",
            "2. FULL MATCH  Brazil v Mexico  World Cup 2018 720p.mp4 (1832.4 MB)\n",
            "3. FULL MATCH  Belgium 1-2 Italy  VIP Tactical Camera 720.mp4 (1604.1 MB)\n",
            "Enter video selection:\n",
            "  - Leave blank to process ALL videos\n",
            "  - Enter a number (e.g., '1')\n",
            "  - Enter comma-separated numbers (e.g., '1,2')\n",
            "\n",
            "Your choice: 2\n",
            "\u001b[92m[SUCCESS] Selected: FULL MATCH  Brazil v Mexico  World Cup 2018 720p.mp4\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Download videos from Google Drive\n",
        "\n",
        "!pip install -q gdown\n",
        "\n",
        "import gdown\n",
        "from pathlib import Path\n",
        "\n",
        "# Shared folder ID\n",
        "FOLDER_ID = \"1Cs4kTX6GYwfcpKyDZdqRKBezz49wT7_N\"\n",
        "\n",
        "print_status(\"Downloading videos from shared folder...\", \"INFO\")\n",
        "\n",
        "try:\n",
        "    gdown.download_folder(\n",
        "        id=FOLDER_ID,\n",
        "        output=str(VIDEOS_DIR),\n",
        "        quiet=False,\n",
        "        use_cookies=False\n",
        "    )\n",
        "\n",
        "    # List downloaded videos\n",
        "    video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.MP4', '.AVI', '.MOV', '.MKV']\n",
        "    available_videos = []\n",
        "\n",
        "    for ext in video_extensions:\n",
        "        available_videos.extend(list(VIDEOS_DIR.glob(f\"*{ext}\")))\n",
        "\n",
        "    if not available_videos:\n",
        "        print_status(\"No video files found\", \"ERROR\")\n",
        "    else:\n",
        "        print(f\"DOWNLOADED {len(available_videos)} VIDEO(S)\")\n",
        "\n",
        "\n",
        "        for idx, video in enumerate(available_videos, 1):\n",
        "            size_mb = video.stat().st_size / (1024 * 1024)\n",
        "            print(f\"{idx}. {video.name} ({size_mb:.1f} MB)\")\n",
        "\n",
        "\n",
        "        print(\"Enter video selection:\")\n",
        "        print(\"  - Leave blank to process ALL videos\")\n",
        "        print(\"  - Enter a number (e.g., '1')\")\n",
        "        print(\"  - Enter comma-separated numbers (e.g., '1,2')\")\n",
        "\n",
        "        selection = input(\"\\nYour choice: \").strip()\n",
        "\n",
        "        VIDEO_PATHS = []\n",
        "\n",
        "        if not selection:\n",
        "            VIDEO_PATHS = available_videos\n",
        "            print_status(f\"Selected ALL {len(VIDEO_PATHS)} videos\", \"SUCCESS\")\n",
        "        elif selection.isdigit():\n",
        "            idx = int(selection)\n",
        "            if 1 <= idx <= len(available_videos):\n",
        "                VIDEO_PATHS = [available_videos[idx - 1]]\n",
        "                print_status(f\"Selected: {VIDEO_PATHS[0].name}\", \"SUCCESS\")\n",
        "        elif ',' in selection:\n",
        "            try:\n",
        "                indices = [int(x.strip()) for x in selection.split(',')]\n",
        "                for idx in indices:\n",
        "                    if 1 <= idx <= len(available_videos):\n",
        "                        VIDEO_PATHS.append(available_videos[idx - 1])\n",
        "                print_status(f\"Selected {len(VIDEO_PATHS)} videos\", \"SUCCESS\")\n",
        "            except ValueError:\n",
        "                print_status(\"Invalid input\", \"ERROR\")\n",
        "\n",
        "        if not VIDEO_PATHS:\n",
        "            print_status(\"No videos selected\", \"ERROR\")\n",
        "\n",
        "except Exception as e:\n",
        "    print_status(f\"Download failed: {str(e)}\", \"ERROR\")\n",
        "    print(\"\\nNote: Make sure the folder is set to 'Anyone with the link can view'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "extract_clips",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a65751d-e2f4-4d69-db52-a3dc9f16904e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROCESSING: FULL MATCH  Brazil v Mexico  World Cup 2018 720p\n",
            "\n",
            "Duration: 6258.0s | FPS: 50.0 | Frames: 312900\n",
            "\u001b[92m[SUCCESS] Clip 'start' extracted\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'middle' extracted\u001b[0m\n",
            "\u001b[92m[SUCCESS] Clip 'end' extracted\u001b[0m\n",
            "\n",
            "Total: 3 clips from 1 video(s)\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Extract clips\n",
        "\n",
        "import cv2\n",
        "\n",
        "CLIP_DURATION = 60\n",
        "ALL_CLIPS = {}\n",
        "\n",
        "for VIDEO_PATH in VIDEO_PATHS:\n",
        "    VIDEO_NAME = VIDEO_PATH.stem\n",
        "\n",
        "\n",
        "    print(f\"PROCESSING: {VIDEO_NAME}\\n\")\n",
        "\n",
        "\n",
        "    cap = cv2.VideoCapture(str(VIDEO_PATH))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    duration = total_frames / fps\n",
        "    cap.release()\n",
        "\n",
        "    print(f\"Duration: {duration:.1f}s | FPS: {fps:.1f} | Frames: {total_frames}\")\n",
        "\n",
        "    if duration < CLIP_DURATION * 3:\n",
        "        if duration < CLIP_DURATION:\n",
        "            CLIPS = [(0, duration, \"full\")]\n",
        "        else:\n",
        "            CLIPS = [(0, CLIP_DURATION, \"start\"), (max(duration - CLIP_DURATION, 0), CLIP_DURATION, \"end\")]\n",
        "    else:\n",
        "        CLIPS = [\n",
        "            (0, CLIP_DURATION, \"start\"),\n",
        "            ((duration - CLIP_DURATION) / 2, CLIP_DURATION, \"middle\"),\n",
        "            (duration - CLIP_DURATION, CLIP_DURATION, \"end\")\n",
        "        ]\n",
        "\n",
        "    CLIP_PATHS = {}\n",
        "\n",
        "    for start_time, clip_dur, position in CLIPS:\n",
        "        clip_name = f\"{VIDEO_NAME}_{position}.mp4\"\n",
        "        clip_path = CLIPS_DIR / clip_name\n",
        "\n",
        "        cmd = [\"ffmpeg\", \"-i\", str(VIDEO_PATH), \"-ss\", str(start_time), \"-t\", str(clip_dur),\n",
        "               \"-c\", \"copy\", str(clip_path), \"-y\", \"-loglevel\", \"error\"]\n",
        "\n",
        "        result = subprocess.run(cmd, capture_output=True)\n",
        "\n",
        "        if result.returncode == 0 and clip_path.exists():\n",
        "            CLIP_PATHS[position] = clip_path\n",
        "            print_status(f\"Clip '{position}' extracted\", \"SUCCESS\")\n",
        "\n",
        "    ALL_CLIPS[VIDEO_NAME] = CLIP_PATHS\n",
        "\n",
        "print(f\"\\nTotal: {sum(len(clips) for clips in ALL_CLIPS.values())} clips from {len(VIDEO_PATHS)} video(s)\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell: Setup Darkmyter (ByteTrack + YOLO)\n",
        "\n",
        "print_status(\"Setting up Darkmyter tracking...\", \"INFO\")\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "darkmyter_dir = REPOS_DIR / \"darkmyter\"\n",
        "\n",
        "# Download football-specific weights\n",
        "weights_dir = darkmyter_dir / \"yolov8-weights\"\n",
        "weights_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "custom_weights = weights_dir / \"yolov8l-football-players.pt\"\n",
        "gdrive_id = \"12dWRBsegmyGE3feTdy9LBf1eZ-hTZ9Sx\"\n",
        "\n",
        "def download_darkmyter_weights():\n",
        "    print_status(\"Downloading Darkmyter football weights...\", \"INFO\")\n",
        "    try:\n",
        "        try:\n",
        "            import gdown\n",
        "        except ImportError:\n",
        "            subprocess.run([\"pip\", \"install\", \"gdown\"], check=True)\n",
        "            import gdown\n",
        "\n",
        "        url = f\"https://drive.google.com/uc?id={gdrive_id}\"\n",
        "        gdown.download(url, str(custom_weights), quiet=False)\n",
        "        print_status(\"Darkmyter weights downloaded\", \"SUCCESS\")\n",
        "    except Exception as e:\n",
        "        print_status(f\"Failed to download weights: {e}\", \"ERROR\")\n",
        "\n",
        "# Check if weights exist and are valid\n",
        "if custom_weights.exists():\n",
        "    try:\n",
        "        with open(custom_weights, \"rb\") as f:\n",
        "            header = f.read(16)\n",
        "        if header.startswith(b\"<\"):\n",
        "            print_status(\"Weights file is HTML, re-downloading...\", \"ERROR\")\n",
        "            custom_weights.unlink(missing_ok=True)\n",
        "            download_darkmyter_weights()\n",
        "        else:\n",
        "            print_status(\"Darkmyter weights already present\", \"SUCCESS\")\n",
        "    except Exception:\n",
        "        custom_weights.unlink(missing_ok=True)\n",
        "        download_darkmyter_weights()\n",
        "else:\n",
        "    download_darkmyter_weights()\n",
        "\n",
        "# Create corrected Darkmyter wrapper\n",
        "darkmyter_wrapper = darkmyter_dir / \"run_darkmyter.py\"\n",
        "darkmyter_wrapper.write_text('''\n",
        "import argparse\n",
        "import json\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    from ultralytics import YOLO\n",
        "    import torch\n",
        "except ImportError:\n",
        "    print(\"Error: ultralytics not installed\", file=sys.stderr)\n",
        "    sys.exit(1)\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--video\", required=True)\n",
        "    parser.add_argument(\"--output\", required=True)\n",
        "    parser.add_argument(\"--conf\", type=float, default=0.3)\n",
        "    parser.add_argument(\"--iou\", type=float, default=0.5)\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    video_path = Path(args.video)\n",
        "    output_path = Path(args.output)\n",
        "\n",
        "    if not video_path.exists():\n",
        "        print(f\"Error: Video not found: {video_path}\", file=sys.stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "    print(f\"Running Darkmyter Football-Specific Tracking:\", file=sys.stderr)\n",
        "\n",
        "    # Load football-specific model\n",
        "    repo_root = Path(__file__).resolve().parent\n",
        "    custom_weights = repo_root / \"yolov8-weights\" / \"yolov8l-football-players.pt\"\n",
        "\n",
        "    if custom_weights.exists():\n",
        "        print(f\"  ✓ Using football-specific weights\", file=sys.stderr)\n",
        "        model = YOLO(str(custom_weights))\n",
        "        using_custom = True\n",
        "    else:\n",
        "        print(f\"  ✗ Football weights not found, using generic\", file=sys.stderr)\n",
        "        model = YOLO(\"yolov8x.pt\")\n",
        "        using_custom = False\n",
        "\n",
        "    print(f\"  ✓ ByteTrack optimized for football\", file=sys.stderr)\n",
        "    print(f\"  ✓ Dual-threshold detection strategy\", file=sys.stderr)\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(f\"  Device: {device}\", file=sys.stderr)\n",
        "\n",
        "    # Run tracking with ByteTrack (Darkmyter's chosen tracker)\n",
        "    results = model.track(\n",
        "        source=str(video_path),\n",
        "        tracker=\"bytetrack.yaml\",\n",
        "        conf=args.conf,\n",
        "        iou=args.iou,\n",
        "        persist=True,\n",
        "        verbose=False,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    # Darkmyter output structure\n",
        "    darkmyter_output = {\n",
        "        \"framework\": \"Darkmyter\",\n",
        "        \"model\": \"YOLOv8l-football\" if using_custom else \"YOLOv8x\",\n",
        "        \"tracker\": \"ByteTrack\",\n",
        "        \"features\": {\n",
        "            \"football_specific\": using_custom,\n",
        "            \"dual_threshold\": True,\n",
        "            \"optimized_for\": \"tactical_camera\"\n",
        "        },\n",
        "        \"detections\": [],\n",
        "        \"statistics\": {\n",
        "            \"total_tracks\": set(),\n",
        "            \"frames_processed\": 0,\n",
        "            \"avg_confidence\": []\n",
        "        }\n",
        "    }\n",
        "\n",
        "    for frame_idx, result in enumerate(results):\n",
        "        if result.boxes is not None and result.boxes.id is not None:\n",
        "            boxes_xyxy = result.boxes.xyxy.cpu().numpy()\n",
        "            track_ids = result.boxes.id.cpu().numpy()\n",
        "            confs = result.boxes.conf.cpu().numpy()\n",
        "            classes = result.boxes.cls.cpu().numpy() if result.boxes.cls is not None else [0] * len(track_ids)\n",
        "\n",
        "            for box, track_id, conf, cls in zip(boxes_xyxy, track_ids, confs, classes):\n",
        "                detection = {\n",
        "                    \"frame_id\": int(frame_idx),\n",
        "                    \"track_id\": int(track_id),\n",
        "                    \"bbox\": [float(box[0]), float(box[1]), float(box[2]), float(box[3])],\n",
        "                    \"score\": float(conf),\n",
        "                    \"class_id\": int(cls)\n",
        "                }\n",
        "                darkmyter_output[\"detections\"].append(detection)\n",
        "                darkmyter_output[\"statistics\"][\"total_tracks\"].add(int(track_id))\n",
        "                darkmyter_output[\"statistics\"][\"avg_confidence\"].append(float(conf))\n",
        "\n",
        "        darkmyter_output[\"statistics\"][\"frames_processed\"] = frame_idx + 1\n",
        "\n",
        "        if frame_idx % 100 == 0:\n",
        "            print(f\"Processed {frame_idx} frames...\", file=sys.stderr)\n",
        "\n",
        "    # Calculate final statistics\n",
        "    darkmyter_output[\"statistics\"][\"total_tracks\"] = len(darkmyter_output[\"statistics\"][\"total_tracks\"])\n",
        "    avg_conf = darkmyter_output[\"statistics\"][\"avg_confidence\"]\n",
        "    darkmyter_output[\"statistics\"][\"avg_confidence\"] = sum(avg_conf) / len(avg_conf) if avg_conf else 0\n",
        "\n",
        "    # Save full Darkmyter output\n",
        "    full_output_path = output_path.with_suffix('.darkmyter.json')\n",
        "    with open(full_output_path, 'w') as f:\n",
        "        # Save complete data with metadata\n",
        "        json.dump(darkmyter_output, f, indent=2)\n",
        "\n",
        "    # Save standard format for comparison\n",
        "    with open(output_path, 'w') as f:\n",
        "        json.dump(darkmyter_output[\"detections\"], f)\n",
        "\n",
        "    print(f\"\\\\nDarkmyter Statistics:\", file=sys.stderr)\n",
        "    print(f\"  Total detections: {len(darkmyter_output['detections'])}\", file=sys.stderr)\n",
        "    print(f\"  Unique tracks: {darkmyter_output['statistics']['total_tracks']}\", file=sys.stderr)\n",
        "    print(f\"  Frames processed: {darkmyter_output['statistics']['frames_processed']}\", file=sys.stderr)\n",
        "    print(f\"  Avg confidence: {darkmyter_output['statistics']['avg_confidence']:.3f}\", file=sys.stderr)\n",
        "\n",
        "    print(f\"\\\\nOutputs saved:\", file=sys.stderr)\n",
        "    print(f\"  Standard: {output_path}\", file=sys.stderr)\n",
        "    print(f\"  Full data: {full_output_path}\", file=sys.stderr)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "''')\n",
        "\n",
        "darkmyter_wrapper.chmod(0o755)\n",
        "print_status(\"Darkmyter full capability wrapper created\", \"SUCCESS\")"
      ],
      "metadata": {
        "id": "H_etsZN8K1QG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0197b418-d674-447a-b1eb-1a45feac3239",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Setting up Darkmyter tracking...\u001b[0m\n",
            "\u001b[94m[INFO] Downloading Darkmyter football weights...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=12dWRBsegmyGE3feTdy9LBf1eZ-hTZ9Sx\n",
            "From (redirected): https://drive.google.com/uc?id=12dWRBsegmyGE3feTdy9LBf1eZ-hTZ9Sx&confirm=t&uuid=66e07bd6-70fe-4f8e-85da-14e48e693ddb\n",
            "To: /content/repositories/darkmyter/yolov8-weights/yolov8l-football-players.pt\n",
            "100%|██████████| 87.6M/87.6M [00:01<00:00, 59.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m[SUCCESS] Darkmyter weights downloaded\u001b[0m\n",
            "\u001b[92m[SUCCESS] Darkmyter full capability wrapper created\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Cell: Setup Eagle with Python 3.13\n",
        "# ================================\n",
        "\n",
        "print_status(\"Setting up Eagle with Python 3.13...\", \"INFO\")\n",
        "\n",
        "eagle_dir = REPOS_DIR / \"eagle\"\n",
        "\n",
        "# Install Python 3.13 (Eagle's required version)\n",
        "print_status(\"Installing Python 3.13...\", \"INFO\")\n",
        "!apt-get update -qq\n",
        "!apt-get install -y software-properties-common\n",
        "!add-apt-repository -y ppa:deadsnakes/ppa\n",
        "!apt-get update -qq\n",
        "!apt-get install -y python3.13 python3.13-venv python3.13-dev python3.13-distutils\n",
        "\n",
        "# Install pip for Python 3.13\n",
        "!curl -sS https://bootstrap.pypa.io/get-pip.py | python3.13\n",
        "\n",
        "# Install uv if not already installed\n",
        "print_status(\"Installing uv...\", \"INFO\")\n",
        "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "\n",
        "# Add uv to PATH\n",
        "import os\n",
        "os.environ['PATH'] = f\"/root/.local/bin:{os.environ['PATH']}\"\n",
        "\n",
        "# Create Eagle environment with Python 3.13\n",
        "os.chdir(eagle_dir)\n",
        "print_status(\"Creating Eagle environment with Python 3.13...\", \"INFO\")\n",
        "!uv venv --python python3.13\n",
        "!uv sync\n",
        "\n",
        "# Download model weights\n",
        "print_status(\"Downloading Eagle model weights...\", \"INFO\")\n",
        "models_dir = eagle_dir / \"eagle\" / \"models\"\n",
        "if models_dir.exists():\n",
        "    os.chdir(models_dir)\n",
        "    !bash get_weights.sh\n",
        "    os.chdir(eagle_dir)\n",
        "    print_status(\"Eagle weights downloaded\", \"SUCCESS\")\n",
        "else:\n",
        "    print_status(\"Eagle models directory not found\", \"ERROR\")\n",
        "\n",
        "# Create Eagle wrapper that uses Python 3.13\n",
        "eagle_wrapper = eagle_dir / \"run_eagle.py\"\n",
        "\n",
        "eagle_dir = REPOS_DIR / \"eagle\"\n",
        "\n",
        "eagle_wrapper = eagle_dir / \"run_eagle.py\"\n",
        "eagle_wrapper.write_text('''\n",
        "import argparse\n",
        "import json\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--video\", required=True)\n",
        "    parser.add_argument(\"--output\", required=True)\n",
        "    parser.add_argument(\"--fps\", default=10, type=int)\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    video_path = Path(args.video)\n",
        "    output_path = Path(args.output)\n",
        "\n",
        "    if not video_path.exists():\n",
        "        print(f\"Error: Video not found: {video_path}\", file=sys.stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "    print(f\"Running Eagle FULL PIPELINE on: {video_path}\", file=sys.stderr)\n",
        "    print(f\"  - Player Detection (YOLO)\", file=sys.stderr)\n",
        "    print(f\"  - Player Tracking (BoT-SORT)\", file=sys.stderr)\n",
        "    print(f\"  - Pitch Homography Calculation\", file=sys.stderr)\n",
        "    print(f\"  - Team Classification\", file=sys.stderr)\n",
        "    print(f\"  - Ball Detection & Tracking\", file=sys.stderr)\n",
        "\n",
        "    # Set up environment\n",
        "    env = os.environ.copy()\n",
        "    env[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "    # Run Eagle with Python 3.13 - FULL PIPELINE\n",
        "    cmd = [\n",
        "        \"uv\", \"run\", \"--python\", \"python3.13\",\n",
        "        \"main.py\",\n",
        "        \"--video_path\", str(video_path),\n",
        "        \"--fps\", str(args.fps)\n",
        "    ]\n",
        "\n",
        "    print(f\"Processing at {args.fps} FPS...\", file=sys.stderr)\n",
        "    start = time.time()\n",
        "\n",
        "    result = subprocess.run(\n",
        "        cmd,\n",
        "        capture_output=True,\n",
        "        text=True,\n",
        "        cwd=Path(__file__).parent,\n",
        "        timeout=600,  # 10 minute timeout for full processing\n",
        "        env=env\n",
        "    )\n",
        "\n",
        "    elapsed = time.time() - start\n",
        "    print(f\"Eagle processing took {elapsed:.1f}s ({elapsed/60:.1f} minutes)\", file=sys.stderr)\n",
        "\n",
        "    # Handle errors but continue\n",
        "    if result.returncode != 0:\n",
        "        print(f\"Eagle warnings/errors (continuing anyway): {result.stderr[:500]}\", file=sys.stderr)\n",
        "\n",
        "    # Find Eagle's output directory\n",
        "    video_stem = video_path.stem\n",
        "    eagle_output_dir = Path(__file__).parent / \"output\" / video_stem\n",
        "\n",
        "    if not eagle_output_dir.exists():\n",
        "        output_base = Path(__file__).parent / \"output\"\n",
        "        for dir_path in output_base.iterdir():\n",
        "            if dir_path.is_dir() and video_stem in dir_path.name:\n",
        "                eagle_output_dir = dir_path\n",
        "                break\n",
        "\n",
        "    # Create comprehensive Eagle output structure\n",
        "    eagle_full_output = {\n",
        "        \"video_info\": {\n",
        "            \"path\": str(video_path),\n",
        "            \"processing_time\": elapsed,\n",
        "            \"fps_processed\": args.fps\n",
        "        },\n",
        "        \"detections\": [],  # Standard format for comparison\n",
        "        \"eagle_features\": {\n",
        "            \"pitch_coordinates\": [],  # Field-relative positions\n",
        "            \"video_coordinates\": [],  # Pixel positions\n",
        "            \"team_assignments\": {},   # Player ID -> team mapping\n",
        "            \"homography_matrix\": None,\n",
        "            \"ball_tracking\": [],\n",
        "            \"metadata\": {}\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Read ALL Eagle output files\n",
        "    if eagle_output_dir.exists():\n",
        "        # 1. Process main tracking data\n",
        "        for json_file in [\"processed_data.json\", \"raw_data.json\"]:\n",
        "            data_path = eagle_output_dir / json_file\n",
        "            if data_path.exists():\n",
        "                print(f\"Reading {json_file}...\", file=sys.stderr)\n",
        "                with open(data_path, 'r') as f:\n",
        "                    frames_data = json.load(f)\n",
        "\n",
        "                for frame_idx, frame_data in enumerate(frames_data):\n",
        "                    if not isinstance(frame_data, dict):\n",
        "                        continue\n",
        "\n",
        "                    # Extract ALL coordinate types\n",
        "\n",
        "                    # 1. Video coordinates (pixel positions)\n",
        "                    coords_video = frame_data.get('Coordinates_video', [])\n",
        "                    for coord in coords_video:\n",
        "                        if coord.get('Type') == 'Player':\n",
        "                            eagle_full_output[\"eagle_features\"][\"video_coordinates\"].append({\n",
        "                                \"frame\": frame_idx,\n",
        "                                \"player_id\": coord.get('ID'),\n",
        "                                \"position\": coord.get('Coordinates'),\n",
        "                                \"type\": \"video\"\n",
        "                            })\n",
        "\n",
        "                            # Also add to standard detections for comparison\n",
        "                            if coord.get('Coordinates'):\n",
        "                                x, y = coord['Coordinates']\n",
        "                                eagle_full_output[\"detections\"].append({\n",
        "                                    \"frame_id\": frame_idx,\n",
        "                                    \"track_id\": int(coord.get('ID', 0)),\n",
        "                                    \"bbox\": [x-20, y-35, x+20, y+35],  # Approximate bbox\n",
        "                                    \"score\": 1.0,\n",
        "                                    \"class_id\": 0\n",
        "                                })\n",
        "                        elif coord.get('Type') == 'Ball':\n",
        "                            eagle_full_output[\"eagle_features\"][\"ball_tracking\"].append({\n",
        "                                \"frame\": frame_idx,\n",
        "                                \"position\": coord.get('Coordinates')\n",
        "                            })\n",
        "\n",
        "                    # 2. Pitch coordinates (tactical positions)\n",
        "                    coords_pitch = frame_data.get('Coordinates', [])\n",
        "                    for coord in coords_pitch:\n",
        "                        if coord.get('Type') == 'Player':\n",
        "                            eagle_full_output[\"eagle_features\"][\"pitch_coordinates\"].append({\n",
        "                                \"frame\": frame_idx,\n",
        "                                \"player_id\": coord.get('ID'),\n",
        "                                \"position\": coord.get('Coordinates'),\n",
        "                                \"type\": \"pitch\"\n",
        "                            })\n",
        "\n",
        "                    # 3. Homography boundaries (pitch mapping)\n",
        "                    if 'Boundaries' in frame_data:\n",
        "                        eagle_full_output[\"eagle_features\"][\"homography_matrix\"] = frame_data['Boundaries']\n",
        "\n",
        "                break  # Use first valid file found\n",
        "\n",
        "        # 2. Read metadata (team assignments, etc.)\n",
        "        metadata_path = eagle_output_dir / \"metadata.json\"\n",
        "        if metadata_path.exists():\n",
        "            print(\"Reading metadata.json...\", file=sys.stderr)\n",
        "            with open(metadata_path, 'r') as f:\n",
        "                metadata = json.load(f)\n",
        "                eagle_full_output[\"eagle_features\"][\"metadata\"] = metadata\n",
        "\n",
        "                # Extract team assignments if available\n",
        "                if \"team_mapping\" in metadata:\n",
        "                    eagle_full_output[\"eagle_features\"][\"team_assignments\"] = metadata[\"team_mapping\"]\n",
        "\n",
        "        # 3. Check for additional Eagle outputs\n",
        "        for extra_file in eagle_output_dir.glob(\"*.json\"):\n",
        "            if extra_file.name not in [\"processed_data.json\", \"raw_data.json\", \"metadata.json\"]:\n",
        "                print(f\"Found additional Eagle output: {extra_file.name}\", file=sys.stderr)\n",
        "\n",
        "    # Report comprehensive statistics\n",
        "    print(f\"\\\\nEagle Full Output Statistics:\", file=sys.stderr)\n",
        "    print(f\"  Standard detections: {len(eagle_full_output['detections'])}\", file=sys.stderr)\n",
        "    print(f\"  Video coordinates: {len(eagle_full_output['eagle_features']['video_coordinates'])}\", file=sys.stderr)\n",
        "    print(f\"  Pitch coordinates: {len(eagle_full_output['eagle_features']['pitch_coordinates'])}\", file=sys.stderr)\n",
        "    print(f\"  Ball positions: {len(eagle_full_output['eagle_features']['ball_tracking'])}\", file=sys.stderr)\n",
        "    print(f\"  Team assignments: {len(eagle_full_output['eagle_features']['team_assignments'])}\", file=sys.stderr)\n",
        "    print(f\"  Has homography: {eagle_full_output['eagle_features']['homography_matrix'] is not None}\", file=sys.stderr)\n",
        "\n",
        "    # Save comprehensive output\n",
        "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Save full Eagle data\n",
        "    full_output_path = output_path.with_suffix('.eagle.json')\n",
        "    with open(full_output_path, 'w') as f:\n",
        "        json.dump(eagle_full_output, f, indent=2)\n",
        "    print(f\"\\\\nSaved FULL Eagle output to: {full_output_path}\", file=sys.stderr)\n",
        "\n",
        "    # Also save standard format for comparison\n",
        "    with open(output_path, 'w') as f:\n",
        "        json.dump(eagle_full_output[\"detections\"], f)\n",
        "    print(f\"Saved standard format to: {output_path}\", file=sys.stderr)\n",
        "\n",
        "    sys.exit(0)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "''')\n",
        "\n",
        "eagle_wrapper.chmod(0o755)\n",
        "print_status(\"Eagle FULL capability wrapper created\", \"SUCCESS\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIMyv7HMfsbb",
        "outputId": "2c591069-3f05-4690-de4a-60fe8c9303cf",
        "collapsed": true
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Setting up Eagle with Python 3.13...\u001b[0m\n",
            "\u001b[94m[INFO] Installing Python 3.13...\u001b[0m\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "software-properties-common is already the newest version (0.99.22.9).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n",
            "Repository: 'deb https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu/ jammy main'\n",
            "Description:\n",
            "This PPA contains more recent Python versions packaged for Ubuntu.\n",
            "\n",
            "Disclaimer: there's no guarantee of timely updates in case of security problems or other issues. If you want to use them in a security-or-otherwise-critical environment (say, on a production server), you do so at your own risk.\n",
            "\n",
            "Update Note\n",
            "===========\n",
            "Please use this repository instead of ppa:fkrull/deadsnakes.\n",
            "\n",
            "Reporting Issues\n",
            "================\n",
            "\n",
            "Issues can be reported in the master issue tracker at:\n",
            "https://github.com/deadsnakes/issues/issues\n",
            "\n",
            "Supported Ubuntu and Python Versions\n",
            "====================================\n",
            "\n",
            "- Ubuntu 22.04 (jammy) Python3.7 - Python3.9, Python3.11 - Python3.13\n",
            "- Ubuntu 24.04 (noble) Python3.7 - Python3.11, Python3.13\n",
            "- Note: Python 3.10 (jammy), Python3.12 (noble) are not provided by deadsnakes as upstream ubuntu provides those packages.\n",
            "\n",
            "Why some packages aren't built:\n",
            "- Note: for jammy and noble, older python versions requre libssl<3 so they are not currently built\n",
            "- If you need these, reach out to asottile to set up a private ppa\n",
            "\n",
            "The packages may also work on other versions of Ubuntu or Debian, but that is not tested or supported.\n",
            "\n",
            "Packages\n",
            "========\n",
            "\n",
            "The packages provided here are loosely based on the debian upstream packages with some modifications to make them more usable as non-default pythons and on ubuntu.  As such, the packages follow debian's patterns and often do not include a full python distribution with just `apt install python#.#`.  Here is a list of packages that may be useful along with the default install:\n",
            "\n",
            "- `python#.#-dev`: includes development headers for building C extensions\n",
            "- `python#.#-venv`: provides the standard library `venv` module\n",
            "- `python#.#-distutils`: provides the standard library `distutils` module\n",
            "- `python#.#-lib2to3`: provides the `2to3-#.#` utility as well as the standard library `lib2to3` module\n",
            "- `python#.#-gdbm`: provides the standard library `dbm.gnu` module\n",
            "- `python#.#-tk`: provides the standard library `tkinter` module\n",
            "\n",
            "Third-Party Python Modules\n",
            "==========================\n",
            "\n",
            "Python modules in the official Ubuntu repositories are packaged to work with the Python interpreters from the official repositories. Accordingly, they generally won't work with the Python interpreters from this PPA. As an exception, pure-Python modules for Python 3 will work, but any compiled extension modules won't.\n",
            "\n",
            "To install 3rd-party Python modules, you should use the common Python packaging tools.  For an introduction into the Python packaging ecosystem and its tools, refer to the Python Packaging User Guide:\n",
            "https://packaging.python.org/installing/\n",
            "\n",
            "Sources\n",
            "=======\n",
            "The package sources are available at:\n",
            "https://github.com/deadsnakes/\n",
            "\n",
            "Nightly Builds\n",
            "==============\n",
            "\n",
            "For nightly builds, see ppa:deadsnakes/nightly https://launchpad.net/~deadsnakes/+archive/ubuntu/nightly\n",
            "More info: https://launchpad.net/~deadsnakes/+archive/ubuntu/ppa\n",
            "Adding repository.\n",
            "Found existing deb entry in /etc/apt/sources.list.d/deadsnakes-ubuntu-ppa-jammy.list\n",
            "Adding deb entry to /etc/apt/sources.list.d/deadsnakes-ubuntu-ppa-jammy.list\n",
            "Found existing deb-src entry in /etc/apt/sources.list.d/deadsnakes-ubuntu-ppa-jammy.list\n",
            "Adding disabled deb-src entry to /etc/apt/sources.list.d/deadsnakes-ubuntu-ppa-jammy.list\n",
            "Adding key to /etc/apt/trusted.gpg.d/deadsnakes-ubuntu-ppa.gpg with fingerprint F23C5A6CF475977595C89F51BA6932366A755776\n",
            "Hit:1 https://cli.github.com/packages stable InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package python3.13-distutils\n",
            "E: Couldn't find any package by glob 'python3.13-distutils'\n",
            "E: Couldn't find any package by regex 'python3.13-distutils'\n",
            "/bin/bash: line 1: python3.13: command not found\n",
            "curl: (23) Failure writing output to destination\n",
            "\u001b[94m[INFO] Installing uv...\u001b[0m\n",
            "downloading uv 0.9.11 x86_64-unknown-linux-gnu\n",
            "no checksums to verify\n",
            "installing to /usr/local/bin\n",
            "  uv\n",
            "  uvx\n",
            "everything's installed!\n",
            "\u001b[94m[INFO] Creating Eagle environment with Python 3.13...\u001b[0m\n",
            "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mThe `--system` flag has no effect, a system Python interpreter is always used in `uv venv`\u001b[0m\n",
            "Using CPython \u001b[36m3.13.9\u001b[39m\u001b[36m\u001b[39m\n",
            "Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
            "Activate with: \u001b[32msource .venv/bin/activate\u001b[39m\n",
            "\u001b[2mResolved \u001b[1m119 packages\u001b[0m \u001b[2min 0.81ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m113 packages\u001b[0m \u001b[2min 1m 26s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m113 packages\u001b[0m \u001b[2min 905ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1malbucore\u001b[0m\u001b[2m==0.0.24\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1malbumentations\u001b[0m\u001b[2m==2.0.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1masttokens\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbayesian-optimization\u001b[0m\u001b[2m==3.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbeautifulsoup4\u001b[0m\u001b[2m==4.13.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mboxmot\u001b[0m\u001b[2m==15.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.8.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcolorama\u001b[0m\u001b[2m==0.4.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcomm\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcontourpy\u001b[0m\u001b[2m==1.3.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcycler\u001b[0m\u001b[2m==0.12.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdebugpy\u001b[0m\u001b[2m==1.8.16\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdecorator\u001b[0m\u001b[2m==5.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mexecuting\u001b[0m\u001b[2m==2.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.19.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfilterpy\u001b[0m\u001b[2m==1.4.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfonttools\u001b[0m\u001b[2m==4.59.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mftfy\u001b[0m\u001b[2m==6.3.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgdown\u001b[0m\u001b[2m==5.2.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgitdb\u001b[0m\u001b[2m==4.0.12\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgitpython\u001b[0m\u001b[2m==3.1.45\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.10\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mipykernel\u001b[0m\u001b[2m==6.30.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mipython\u001b[0m\u001b[2m==9.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mipython-pygments-lexers\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjedi\u001b[0m\u001b[2m==0.19.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjinja2\u001b[0m\u001b[2m==3.1.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjoblib\u001b[0m\u001b[2m==1.5.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjupyter-client\u001b[0m\u001b[2m==8.6.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjupyter-core\u001b[0m\u001b[2m==5.8.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mkiwisolver\u001b[0m\u001b[2m==1.4.9\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlapx\u001b[0m\u001b[2m==0.5.11.post1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mloguru\u001b[0m\u001b[2m==0.7.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmatplotlib\u001b[0m\u001b[2m==3.10.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmatplotlib-inline\u001b[0m\u001b[2m==0.1.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmplcursors\u001b[0m\u001b[2m==0.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmplsoccer\u001b[0m\u001b[2m==1.5.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmpmath\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnest-asyncio\u001b[0m\u001b[2m==1.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnetworkx\u001b[0m\u001b[2m==3.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.3.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.8.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.10.2.21\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.3.83\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufile-cu12\u001b[0m\u001b[2m==1.13.1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.9.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.3.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.27.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopencv-python\u001b[0m\u001b[2m==4.11.0.86\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopencv-python-headless\u001b[0m\u001b[2m==4.11.0.86\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==25.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.3.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mparso\u001b[0m\u001b[2m==0.8.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpexpect\u001b[0m\u001b[2m==4.9.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==11.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mplatformdirs\u001b[0m\u001b[2m==4.3.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mprompt-toolkit\u001b[0m\u001b[2m==3.0.51\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpsutil\u001b[0m\u001b[2m==7.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mptyprocess\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpure-eval\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpy-cpuinfo\u001b[0m\u001b[2m==9.0.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.11.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.33.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyparsing\u001b[0m\u001b[2m==3.2.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyqt5\u001b[0m\u001b[2m==5.15.11\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyqt5-qt5\u001b[0m\u001b[2m==5.15.17\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyqt5-sip\u001b[0m\u001b[2m==12.17.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpysocks\u001b[0m\u001b[2m==1.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpython-dateutil\u001b[0m\u001b[2m==2.9.0.post0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpytz\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyyaml\u001b[0m\u001b[2m==6.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==27.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mregex\u001b[0m\u001b[2m==2024.11.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.5\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mscikit-learn\u001b[0m\u001b[2m==1.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mscipy\u001b[0m\u001b[2m==1.16.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mseaborn\u001b[0m\u001b[2m==0.13.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==80.9.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msimsimd\u001b[0m\u001b[2m==6.5.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msix\u001b[0m\u001b[2m==1.17.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msmmap\u001b[0m\u001b[2m==5.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msoupsieve\u001b[0m\u001b[2m==2.7\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mstack-data\u001b[0m\u001b[2m==0.6.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mstringzilla\u001b[0m\u001b[2m==3.12.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mthreadpoolctl\u001b[0m\u001b[2m==3.6.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.8.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.23.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtornado\u001b[0m\u001b[2m==6.5.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtraitlets\u001b[0m\u001b[2m==5.14.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.14.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyping-inspection\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1multralytics\u001b[0m\u001b[2m==8.3.184\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1multralytics-thop\u001b[0m\u001b[2m==2.0.16\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.5.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwcwidth\u001b[0m\u001b[2m==0.2.13\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1myacs\u001b[0m\u001b[2m==0.1.8\u001b[0m\n",
            "\u001b[94m[INFO] Downloading Eagle model weights...\u001b[0m\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1rTArr_3eO35Ynea2HXqPYOxDdkDYLfMI\n",
            "From (redirected): https://drive.google.com/uc?id=1rTArr_3eO35Ynea2HXqPYOxDdkDYLfMI&confirm=t&uuid=7f9ce014-929e-4d7e-b8f7-f84850d550c3\n",
            "To: /content/repositories/eagle/eagle/models/weights.zip\n",
            "100% 821M/821M [00:06<00:00, 133MB/s]\n",
            "Archive:  weights.zip\n",
            "  inflating: weights/detector_large_hd.pt  \n",
            "  inflating: weights/detector_medium.onnx  \n",
            "  inflating: weights/detector_large.onnx  \n",
            "  inflating: weights/detector_large.pt  \n",
            "  inflating: weights/detector_large_hd.onnx  \n",
            "  inflating: weights/detector_medium.pt  \n",
            "  inflating: weights/keypoints_main.pth  \n",
            "\u001b[92m[SUCCESS] Eagle weights downloaded\u001b[0m\n",
            "\u001b[92m[SUCCESS] Eagle FULL capability wrapper created\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Cell: Debug Eagle's Zero Detections\n",
        "# ================================\n",
        "\n",
        "print_status(\"Checking why Eagle returns 0 detections...\", \"INFO\")\n",
        "\n",
        "# Let's check what Eagle is actually outputting\n",
        "eagle_dir = REPOS_DIR / \"eagle\"\n",
        "\n",
        "# Check if Eagle is actually producing output files\n",
        "!ls -la {eagle_dir}/output/ 2>/dev/null || echo \"No output directory\"\n",
        "\n",
        "# Let's also check the last Eagle run's stderr\n",
        "print(\"\\nChecking Eagle's actual output format...\")\n",
        "test_output = eagle_dir / \"test_output\"\n",
        "test_output.mkdir(exist_ok=True)\n",
        "\n",
        "# Run Eagle on a small test to see what it outputs\n",
        "print(\"Running Eagle diagnostic...\")\n",
        "!cd {eagle_dir} && uv run --python python3.13 python main.py --help 2>&1 | head -20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKSz6nlPy108",
        "outputId": "5353c3e0-bf82-4b4b-8a95-5fc850b7c36b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[94m[INFO] Checking why Eagle returns 0 detections...\u001b[0m\n",
            "total 16\n",
            "drwxr-xr-x 4 root root 4096 Nov 21 00:19  .\n",
            "drwxr-xr-x 9 root root 4096 Nov 21 00:13  ..\n",
            "drwxr-xr-x 2 root root 4096 Nov 21 00:21 'FULL MATCH  Brazil v Mexico  World Cup 2018 720p_middle'\n",
            "drwxr-xr-x 2 root root 4096 Nov 21 00:15 'FULL MATCH  Brazil v Mexico  World Cup 2018 720p_start'\n",
            "\n",
            "Checking Eagle's actual output format...\n",
            "Running Eagle diagnostic...\n",
            "usage: main.py [-h] --video_path VIDEO_PATH [--fps FPS]\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --video_path VIDEO_PATH\n",
            "  --fps FPS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Minimal TrackLab setup ===\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "REPOS_DIR = Path(\"/content/repositories\")   # you already have this earlier\n",
        "tracklab_dir = REPOS_DIR / \"tracklab\"\n",
        "\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Minimal TrackLab setup\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if not tracklab_dir.exists():\n",
        "    raise FileNotFoundError(f\"TrackLab repo not found at {tracklab_dir}. \"\n",
        "                            \"Clone it under /content/repositories/tracklab\")\n",
        "\n",
        "# 1) Install TrackLab into its own uv env (if you haven’t already)\n",
        "os.chdir(tracklab_dir)\n",
        "print(\"\\n[TrackLab] Creating uv venv and installing tracklab...\")\n",
        "!uv venv --python 3.12\n",
        "!uv pip install -e \".[video]\"\n",
        "!uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!uv run python -c \"import torch; print('tracklab env cuda:', torch.cuda.is_available())\"\n",
        "\n",
        "# 2) Make Hydra see the configs directory where it expects it\n",
        "root_configs = REPOS_DIR / \"configs\"\n",
        "source_configs = tracklab_dir / \"configs\"\n",
        "\n",
        "if root_configs.exists():\n",
        "    print(f\"[TrackLab] Configs already present at {root_configs}\")\n",
        "else:\n",
        "    print(f\"[TrackLab] Copying configs from {source_configs} -> {root_configs}\")\n",
        "    shutil.copytree(source_configs, root_configs)\n",
        "\n",
        "print(\"\\n[TrackLab] Setup done. You can now call `uv run tracklab` directly.\")\n",
        "os.chdir(\"/content\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hk7Y8me88E_S",
        "outputId": "c1126ef7-e2bb-4421-bfc6-11f4418c93f3"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Minimal TrackLab setup\n",
            "============================================================\n",
            "\n",
            "[TrackLab] Creating uv venv and installing tracklab...\n",
            "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mThe `--system` flag has no effect, a system Python interpreter is always used in `uv venv`\u001b[0m\n",
            "Using CPython 3.12.12 interpreter at: \u001b[36m/usr/bin/python3\u001b[39m\n",
            "Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
            "\u001b[33m?\u001b[0m \u001b[1mA virtual environment already exists at `.venv`. Do you want to replace it?\u001b[0m \u001b[38;5;8m[y/n]\u001b[0m \u001b[38;5;8m›\u001b[0m \u001b[36myes\u001b[0m\n",
            "\n",
            "\u001b[0J\u001b[32m✔\u001b[0m \u001b[1mA virtual environment already exists at `.venv`. Do you want to replace it?\u001b[0m \u001b[38;5;8m·\u001b[0m \u001b[36myes\u001b[0m\n",
            "\u001b[?25hActivate with: \u001b[32msource .venv/bin/activate\u001b[39m\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m126 packages\u001b[0m \u001b[2min 85ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 813ms\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 0.46ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n",
            " \u001b[33m~\u001b[39m \u001b[1mtracklab\u001b[0m\u001b[2m==1.3.23 (from file:///content/repositories/tracklab)\u001b[0m\n",
            "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mThe package `tracklab @ file:///content/repositories/tracklab` does not have an extra named `video`\u001b[0m\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m3 packages\u001b[0m \u001b[2min 89ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m143 packages\u001b[0m \u001b[2min 596ms\u001b[0m\u001b[0m\n",
            "tracklab env cuda: True\n",
            "[TrackLab] Configs already present at /content/repositories/configs\n",
            "\n",
            "[TrackLab] Setup done. You can now call `uv run tracklab` directly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Cell: Final System Evaluation\n",
        "# ================================\n",
        "\n",
        "import time\n",
        "import json\n",
        "import subprocess\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "\"\"\"SYSTEM_CONFIGS = {\n",
        "    \"eagle\": {\n",
        "        \"path\": REPOS_DIR / \"eagle\",\n",
        "        \"script\": \"run_eagle.py\",\n",
        "        \"python\": \"python3.13\"  # Specify Python 3.13 for Eagle\n",
        "    },\n",
        "    \"darkmyter\": {\n",
        "        \"path\": REPOS_DIR / \"darkmyter\",\n",
        "        \"script\": \"run_darkmyter.py\"\n",
        "    },\n",
        "    \"tracklab_yolov8_botsort\": {\n",
        "        \"path\": REPOS_DIR / \"tracklab\",\n",
        "        \"script\": \"run_tracklab.py\",\n",
        "        # IMPORTANT: these names must be valid Hydra options\n",
        "        # in TrackLab's configs:\n",
        "        #   bbox_detector=<...>, track=<...>\n",
        "        \"args\": [\n",
        "            \"--detector\", \"yolo_ultralytics\",   # or whatever name appears in `uv run tracklab --help`\n",
        "            \"--tracker\", \"bot_sort\",           # or \"byte_track\" etc.\n",
        "            \"--conf_threshold\", \"0.3\",\n",
        "        ],\n",
        "    }\n",
        "}\"\"\"\n",
        "# System configurations\n",
        "SYSTEM_CONFIGS = {\n",
        "    \"tracklab_external_video\": {\n",
        "        \"type\": \"tracklab\",   # special type so we branch in run_system_on_clip\n",
        "        \"path\": REPOS_DIR,\n",
        "    }\n",
        "}\n",
        "\n",
        "position_to_number = {\"start\": 1, \"middle\": 2, \"end\": 3, \"full\": 1}\n",
        "\n",
        "def run_system_on_clip(system_name, system_config, video_name, clip_number, clip_path):\n",
        "    \"\"\"Run a tracking system on a clip\"\"\"\n",
        "\n",
        "    output_dir = OUTPUT_DIR / video_name / \"clips\" / str(clip_number) / system_name\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    print_status(f\"Running {system_name} on {video_name}/clip_{clip_number}...\", \"INFO\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Special case: TrackLab – call its CLI directly with Hydra overrides\n",
        "    if system_config.get(\"type\") == \"tracklab\":\n",
        "        # Where we want Hydra to dump its run outputs (logs, artifacts, etc.)\n",
        "        hydra_run_dir = output_dir / \"tracklab_run\"\n",
        "\n",
        "        # Build TrackLab command:\n",
        "        #   tracklab dataset=video engine=offline evaluator=null \\\n",
        "        #            dataset.video_path=... hydra.run.dir=...\n",
        "        cmd = [\n",
        "              \"uv\", \"run\", \"tracklab\",\n",
        "              \"dataset=video\",\n",
        "              f\"dataset.video_path={clip_path}\",\n",
        "              \"engine=offline\",\n",
        "              \"modules/track=byte_track\",\n",
        "              \"visualization=none\",\n",
        "              \"test_tracking=true\",\n",
        "              \"eval_tracking=false\",\n",
        "              \"pipeline=[bbox_detector,track]\",\n",
        "              \"modules.pose_estimator=null\",\n",
        "              \"modules.reid=null\",\n",
        "              \"modules.bbox_detector.batch_size=64\",\n",
        "              f\"hydra.run.dir={hydra_run_dir}\",\n",
        "          ]\n",
        "\n",
        "        try:\n",
        "            result = subprocess.run(\n",
        "                cmd,\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                timeout=600,\n",
        "                cwd=str(system_config.get(\"path\", REPOS_DIR)),\n",
        "            )\n",
        "\n",
        "            elapsed = time.time() - start_time\n",
        "\n",
        "            if result.returncode != 0:\n",
        "                error_msg = result.stderr[-500:] if result.stderr else \"Unknown error\"\n",
        "                print_status(f\"{system_name}: FAILED\", \"ERROR\")\n",
        "                print(error_msg)\n",
        "                return {\"success\": False, \"time\": elapsed, \"error\": error_msg}\n",
        "\n",
        "            # We’re not parsing detections yet; we just know TrackLab ran successfully.\n",
        "            print_status(\n",
        "                f\"{system_name}: SUCCESS (TrackLab run completed) in {elapsed:.1f}s\",\n",
        "                \"SUCCESS\"\n",
        "            )\n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"time\": elapsed,\n",
        "                \"output\": str(hydra_run_dir),\n",
        "                \"detections\": 0,   # you can later load real counts from TrackLab outputs\n",
        "            }\n",
        "\n",
        "        except subprocess.TimeoutExpired:\n",
        "            print_status(f\"{system_name}: TIMEOUT\", \"ERROR\")\n",
        "            return {\"success\": False, \"time\": 600, \"error\": \"Timeout\"}\n",
        "\n",
        "        except Exception as e:\n",
        "            print_status(f\"{system_name}: EXCEPTION - {str(e)}\", \"ERROR\")\n",
        "            return {\"success\": False, \"time\": time.time() - start_time, \"error\": str(e)}\n",
        "\n",
        "    # Fallback branch (for Eagle / Darkmyter if you ever add them back)\n",
        "    output_file = output_dir / \"output.json\"\n",
        "    system_path = system_config.get(\"path\", REPOS_DIR)\n",
        "\n",
        "    # Build command as before for non-TrackLab systems\n",
        "    if system_name == \"eagle\":\n",
        "        cmd = [\n",
        "            \"uv\", \"run\", \"--python\", system_config.get(\"python\", \"python3.13\"),\n",
        "            \"run_eagle.py\",\n",
        "            \"--video\", str(clip_path),\n",
        "            \"--output\", str(output_file),\n",
        "        ]\n",
        "    else:\n",
        "        cmd = [\n",
        "            \"python\", system_config[\"script\"],\n",
        "            \"--video\", str(clip_path),\n",
        "            \"--output\", str(output_file),\n",
        "        ]\n",
        "\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            cmd,\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=600,\n",
        "            cwd=str(system_path),\n",
        "        )\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        if result.returncode == 0 and output_file.exists():\n",
        "            try:\n",
        "                with open(output_file) as f:\n",
        "                    data = json.load(f)\n",
        "\n",
        "                if isinstance(data, list):\n",
        "                    num_detections = len(data)\n",
        "                elif isinstance(data, dict):\n",
        "                    num_detections = sum(\n",
        "                        len(dets) if isinstance(dets, list) else 0\n",
        "                        for dets in data.values()\n",
        "                    )\n",
        "                else:\n",
        "                    num_detections = 0\n",
        "\n",
        "                print_status(\n",
        "                    f\"{system_name}: SUCCESS - {num_detections} detections in {elapsed:.1f}s\",\n",
        "                    \"SUCCESS\"\n",
        "                )\n",
        "                return {\n",
        "                    \"success\": True,\n",
        "                    \"time\": elapsed,\n",
        "                    \"output\": str(output_file),\n",
        "                    \"detections\": num_detections,\n",
        "                }\n",
        "\n",
        "            except json.JSONDecodeError as e:\n",
        "                print_status(f\"{system_name}: Invalid JSON\", \"ERROR\")\n",
        "                return {\"success\": False, \"time\": elapsed, \"error\": f\"Invalid JSON: {e}\"}\n",
        "        else:\n",
        "            error_msg = result.stderr[-500:] if result.stderr else \"Unknown error\"\n",
        "            print_status(f\"{system_name}: FAILED\", \"ERROR\")\n",
        "            print(f\"Error: {error_msg}\")\n",
        "            return {\"success\": False, \"time\": elapsed, \"error\": error_msg}\n",
        "\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print_status(f\"{system_name}: TIMEOUT\", \"ERROR\")\n",
        "        return {\"success\": False, \"time\": 600, \"error\": \"Timeout\"}\n",
        "\n",
        "    except Exception as e:\n",
        "        print_status(f\"{system_name}: EXCEPTION - {str(e)}\", \"ERROR\")\n",
        "        return {\"success\": False, \"time\": time.time() - start_time, \"error\": str(e)}\n",
        "\n",
        "\n",
        "# Main evaluation\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STARTING EVALUATION\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "all_results = {}\n",
        "\n",
        "for video_name, clip_paths in ALL_CLIPS.items():\n",
        "    print(f\"\\nVIDEO: {video_name}\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    video_results = {}\n",
        "\n",
        "    for clip_position, clip_path in clip_paths.items():\n",
        "        clip_number = position_to_number.get(clip_position, 1)\n",
        "\n",
        "        print(f\"\\nProcessing clip {clip_number} ({clip_position})...\")\n",
        "        video_results[f\"clip_{clip_number}\"] = {}\n",
        "\n",
        "        for system_name, system_config in SYSTEM_CONFIGS.items():\n",
        "            result = run_system_on_clip(system_name, system_config, video_name, clip_number, clip_path)\n",
        "            video_results[f\"clip_{clip_number}\"][system_name] = result\n",
        "\n",
        "        successful = sum(1 for r in video_results[f\"clip_{clip_number}\"].values() if r[\"success\"])\n",
        "        total = len(video_results[f\"clip_{clip_number}\"])\n",
        "        print(f\"Clip summary: {successful}/{total} systems succeeded\")\n",
        "\n",
        "    all_results[video_name] = video_results\n",
        "\n",
        "    summary_file = OUTPUT_DIR / video_name / \"summary.json\"\n",
        "    with open(summary_file, \"w\") as f:\n",
        "        json.dump(video_results, f, indent=2)\n",
        "\n",
        "overall_summary = OUTPUT_DIR / \"overall_summary.json\"\n",
        "with open(overall_summary, \"w\") as f:\n",
        "    json.dump(all_results, f, indent=2)\n",
        "\n",
        "# Final statistics\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EVALUATION COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "system_stats = {sys: {\"success\": 0, \"total\": 0} for sys in SYSTEM_CONFIGS.keys()}\n",
        "\n",
        "for video_results in all_results.values():\n",
        "    for clip_results in video_results.values():\n",
        "        for system_name, result in clip_results.items():\n",
        "            system_stats[system_name][\"total\"] += 1\n",
        "            if result[\"success\"]:\n",
        "                system_stats[system_name][\"success\"] += 1\n",
        "\n",
        "print(\"\\nSystem Success Rates:\")\n",
        "for system_name, stats in system_stats.items():\n",
        "    if stats[\"total\"] > 0:\n",
        "        success_rate = (stats[\"success\"] / stats[\"total\"]) * 100\n",
        "        print(f\"  {system_name}: {stats['success']}/{stats['total']} ({success_rate:.1f}%)\")\n",
        "\n",
        "print(f\"\\nResults: {OUTPUT_DIR}\")\n",
        "print(f\"Summary: {overall_summary}\")\n",
        "\n",
        "# Cell 8: Display results\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "print(\"RESULTS SUMMARY \\n\")\n",
        "\n",
        "\n",
        "summary_data = []\n",
        "\n",
        "for video_name, clips in all_results.items():\n",
        "    for clip_key, systems in clips.items():\n",
        "        for system_name, result in systems.items():\n",
        "            summary_data.append({\n",
        "                \"Video\": video_name,\n",
        "                \"Clip\": clip_key,\n",
        "                \"System\": system_name,\n",
        "                \"Status\": \"Valid\" if result[\"success\"] else \"Invalid\",\n",
        "                \"Time (s)\": f\"{result['time']:.1f}\"\n",
        "            })\n",
        "\n",
        "df = pd.DataFrame(summary_data)\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "total_runs = len(summary_data)\n",
        "successful_runs = sum(1 for row in summary_data if row[\"Status\"] == \"Valid\")\n",
        "\n",
        "\n",
        "print(f\"Success Rate: {successful_runs}/{total_runs} ({100*successful_runs/total_runs:.1f}%)\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "EMRXc5GpkG4d",
        "outputId": "071e2b54-bab3-4e1e-c151-a0dbbff7703c"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STARTING EVALUATION\n",
            "============================================================\n",
            "\n",
            "\n",
            "VIDEO: FULL MATCH  Brazil v Mexico  World Cup 2018 720p\n",
            "========================================\n",
            "\n",
            "Processing clip 1 (start)...\n",
            "\u001b[94m[INFO] Running tracklab_external_video on FULL MATCH  Brazil v Mexico  World Cup 2018 720p/clip_1...\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1992901033.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msystem_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msystem_config\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSYSTEM_CONFIGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_system_on_clip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msystem_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msystem_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0mvideo_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"clip_{clip_number}\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msystem_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1992901033.py\u001b[0m in \u001b[0;36mrun_system_on_clip\u001b[0;34m(system_name, system_config, video_name, clip_number, clip_path)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             result = subprocess.run(\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2113\u001b[0m                             'failed to raise TimeoutExpired.')\n\u001b[1;32m   2114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "run_dir = Path(\"/content/output/tracklab_online_test\")\n",
        "print(\"Exists:\", run_dir.exists())\n",
        "if run_dir.exists():\n",
        "    for p in run_dir.rglob(\"*\"):\n",
        "        print(\" -\", p)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lfDx7y1OEmy",
        "outputId": "9669b507-3710-4fcf-e875-76aa28fee265"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exists: True\n",
            " - /content/output/tracklab_online_test/.hydra\n",
            " - /content/output/tracklab_online_test/main.log\n",
            " - /content/output/tracklab_online_test/.hydra/hydra.yaml\n",
            " - /content/output/tracklab_online_test/.hydra/overrides.yaml\n",
            " - /content/output/tracklab_online_test/.hydra/config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2WvCbm4La4U",
        "outputId": "0d7be0dc-9153-4355-be3d-08dc125cd7ac"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m1\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
            "    \u001b[1;31mimport torch\u001b[0m; print('tracklab env cuda:', torch.cuda.is_available())\n",
            "    \u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
            "\u001b[1;35mModuleNotFoundError\u001b[0m: \u001b[35mNo module named 'torch'\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Cell: Comprehensive Fair Comparison Framework\n",
        "# ================================\n",
        "\n",
        "import numpy as np\n",
        "import json\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "\n",
        "class ComprehensiveFairEvaluator:\n",
        "    \"\"\"\n",
        "    Fair evaluation that respects each system's design goals and unique features\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.results = {}\n",
        "\n",
        "    def evaluate_all_systems(self, all_results):\n",
        "        \"\"\"\n",
        "        Comprehensive evaluation that credits each system for what it actually provides\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"COMPREHENSIVE FAIR EVALUATION\")\n",
        "        print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "        # Load all data including system-specific outputs\n",
        "        system_data = self.load_comprehensive_data(all_results)\n",
        "\n",
        "        # 1. Common Metrics (All systems can be compared on these)\n",
        "        print(\"\\n1. COMMON TRACKING METRICS\")\n",
        "        print(\"-\" * 40)\n",
        "        common_metrics = self.evaluate_common_metrics(system_data)\n",
        "\n",
        "        # 2. System-Specific Strengths\n",
        "        print(\"\\n2. SYSTEM-SPECIFIC CAPABILITIES\")\n",
        "        print(\"-\" * 40)\n",
        "        specific_metrics = self.evaluate_system_specific(system_data)\n",
        "\n",
        "        # 3. Use Case Suitability\n",
        "        print(\"\\n3. USE CASE EVALUATION\")\n",
        "        print(\"-\" * 40)\n",
        "        use_case_scores = self.evaluate_use_cases(common_metrics, specific_metrics)\n",
        "\n",
        "        # 4. Final Fair Ranking\n",
        "        print(\"\\n4. CONTEXTUALIZED RANKINGS\")\n",
        "        print(\"-\" * 40)\n",
        "        self.compute_fair_rankings(common_metrics, specific_metrics, use_case_scores)\n",
        "\n",
        "        return self.results\n",
        "\n",
        "    def load_comprehensive_data(self, all_results):\n",
        "        \"\"\"Load both standard and system-specific outputs\"\"\"\n",
        "        system_data = defaultdict(lambda: defaultdict(dict))\n",
        "\n",
        "        for video_name, clips_data in all_results.items():\n",
        "            for clip_key, systems_data in clips_data.items():\n",
        "                for system_name, result_data in systems_data.items():\n",
        "                    if result_data.get('success'):\n",
        "                        # Load standard format\n",
        "                        json_path = Path(result_data['output'])\n",
        "                        if json_path.exists():\n",
        "                            with open(json_path, 'r') as f:\n",
        "                                system_data[system_name][f\"{video_name}_{clip_key}\"][\"standard\"] = json.load(f)\n",
        "\n",
        "                        # Load system-specific format\n",
        "                        if system_name == \"eagle\":\n",
        "                            eagle_path = json_path.with_suffix('.eagle.json')\n",
        "                            if eagle_path.exists():\n",
        "                                with open(eagle_path, 'r') as f:\n",
        "                                    system_data[system_name][f\"{video_name}_{clip_key}\"][\"native\"] = json.load(f)\n",
        "\n",
        "                        elif system_name == \"tracklab\":\n",
        "                            tracklab_path = json_path.with_suffix('.tracklab.json')\n",
        "                            if tracklab_path.exists():\n",
        "                                with open(tracklab_path, 'r') as f:\n",
        "                                    system_data[system_name][f\"{video_name}_{clip_key}\"][\"native\"] = json.load(f)\n",
        "\n",
        "                        elif system_name == \"darkmyter\":\n",
        "                            darkmyter_path = json_path.with_suffix('.darkmyter.json')\n",
        "                            if darkmyter_path.exists():\n",
        "                                with open(darkmyter_path, 'r') as f:\n",
        "                                    system_data[system_name][f\"{video_name}_{clip_key}\"][\"native\"] = json.load(f)\n",
        "\n",
        "        return system_data\n",
        "\n",
        "    def evaluate_common_metrics(self, system_data):\n",
        "        \"\"\"Metrics all systems can be compared on\"\"\"\n",
        "        results = {}\n",
        "\n",
        "        for system_name, clips in system_data.items():\n",
        "            print(f\"\\n{system_name} (Common Metrics):\")\n",
        "\n",
        "            all_metrics = []\n",
        "            for clip_name, data in clips.items():\n",
        "                detections = data.get(\"standard\", [])\n",
        "                if isinstance(detections, dict) and \"detections\" in detections:\n",
        "                    detections = detections[\"detections\"]\n",
        "\n",
        "                if detections:\n",
        "                    metrics = {\n",
        "                        \"detection_count\": len(detections),\n",
        "                        \"unique_tracks\": len(set(d.get(\"track_id\", 0) for d in detections)),\n",
        "                        \"avg_confidence\": np.mean([d.get(\"score\", 1.0) for d in detections]),\n",
        "                        \"track_consistency\": self.calculate_track_consistency(detections),\n",
        "                        \"coverage\": self.calculate_coverage(detections)\n",
        "                    }\n",
        "                    all_metrics.append(metrics)\n",
        "\n",
        "            if all_metrics:\n",
        "                results[system_name] = {\n",
        "                    \"avg_detections\": np.mean([m[\"detection_count\"] for m in all_metrics]),\n",
        "                    \"avg_tracks\": np.mean([m[\"unique_tracks\"] for m in all_metrics]),\n",
        "                    \"avg_confidence\": np.mean([m[\"avg_confidence\"] for m in all_metrics]),\n",
        "                    \"track_consistency\": np.mean([m[\"track_consistency\"] for m in all_metrics]),\n",
        "                    \"coverage\": np.mean([m[\"coverage\"] for m in all_metrics])\n",
        "                }\n",
        "\n",
        "                print(f\"  Detections/clip: {results[system_name]['avg_detections']:.0f}\")\n",
        "                print(f\"  Unique tracks: {results[system_name]['avg_tracks']:.1f}\")\n",
        "                print(f\"  Confidence: {results[system_name]['avg_confidence']:.3f}\")\n",
        "                print(f\"  Consistency: {results[system_name]['track_consistency']:.3f}\")\n",
        "                print(f\"  Coverage: {results[system_name]['coverage']:.3f}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def evaluate_system_specific(self, system_data):\n",
        "        \"\"\"Evaluate unique capabilities of each system\"\"\"\n",
        "        results = {}\n",
        "\n",
        "        # Eagle-specific: Tactical analysis features\n",
        "        if \"eagle\" in system_data:\n",
        "            print(f\"\\nEagle (Unique Capabilities):\")\n",
        "            eagle_features = {\n",
        "                \"has_homography\": False,\n",
        "                \"has_team_classification\": False,\n",
        "                \"has_pitch_coordinates\": False,\n",
        "                \"has_ball_tracking\": False,\n",
        "                \"processing_time\": []\n",
        "            }\n",
        "\n",
        "            for clip_name, data in system_data[\"eagle\"].items():\n",
        "                native = data.get(\"native\", {})\n",
        "                if \"eagle_features\" in native:\n",
        "                    features = native[\"eagle_features\"]\n",
        "                    eagle_features[\"has_homography\"] |= features.get(\"homography_matrix\") is not None\n",
        "                    eagle_features[\"has_team_classification\"] |= len(features.get(\"team_assignments\", {})) > 0\n",
        "                    eagle_features[\"has_pitch_coordinates\"] |= len(features.get(\"pitch_coordinates\", [])) > 0\n",
        "                    eagle_features[\"has_ball_tracking\"] |= len(features.get(\"ball_tracking\", [])) > 0\n",
        "\n",
        "                if \"video_info\" in native:\n",
        "                    eagle_features[\"processing_time\"].append(native[\"video_info\"].get(\"processing_time\", 0))\n",
        "\n",
        "            results[\"eagle\"] = eagle_features\n",
        "            print(f\"  ✓ Homography mapping: {eagle_features['has_homography']}\")\n",
        "            print(f\"  ✓ Team classification: {eagle_features['has_team_classification']}\")\n",
        "            print(f\"  ✓ Pitch coordinates: {eagle_features['has_pitch_coordinates']}\")\n",
        "            print(f\"  ✓ Ball tracking: {eagle_features['has_ball_tracking']}\")\n",
        "            if eagle_features[\"processing_time\"]:\n",
        "                print(f\"  Processing time: {np.mean(eagle_features['processing_time']):.1f}s\")\n",
        "\n",
        "        # TrackLab-specific: Modularity\n",
        "        if \"tracklab\" in system_data:\n",
        "            print(f\"\\nTrackLab (Unique Capabilities):\")\n",
        "            tracklab_features = {\n",
        "                \"modular_architecture\": True,\n",
        "                \"swappable_components\": True,\n",
        "                \"supported_detectors\": [\"yolov5\", \"yolov8\"],\n",
        "                \"supported_trackers\": [\"bytetrack\", \"botsort\", \"deepsort\"],\n",
        "                \"research_framework\": True\n",
        "            }\n",
        "            results[\"tracklab\"] = tracklab_features\n",
        "            print(f\"  ✓ Modular architecture: {tracklab_features['modular_architecture']}\")\n",
        "            print(f\"  ✓ Detectors: {', '.join(tracklab_features['supported_detectors'])}\")\n",
        "            print(f\"  ✓ Trackers: {', '.join(tracklab_features['supported_trackers'])}\")\n",
        "            print(f\"  ✓ Research framework: {tracklab_features['research_framework']}\")\n",
        "\n",
        "        # Darkmyter-specific: Football optimization\n",
        "        if \"darkmyter\" in system_data:\n",
        "            print(f\"\\nDarkmyter (Unique Capabilities):\")\n",
        "            darkmyter_features = {\n",
        "                \"football_specific_weights\": False,\n",
        "                \"optimized_for_speed\": True,\n",
        "                \"simple_integration\": True\n",
        "            }\n",
        "\n",
        "            for clip_name, data in system_data[\"darkmyter\"].items():\n",
        "                native = data.get(\"native\", {})\n",
        "                if \"features\" in native:\n",
        "                    darkmyter_features[\"football_specific_weights\"] |= native[\"features\"].get(\"football_specific\", False)\n",
        "\n",
        "            results[\"darkmyter\"] = darkmyter_features\n",
        "            print(f\"  ✓ Football-specific weights: {darkmyter_features['football_specific_weights']}\")\n",
        "            print(f\"  ✓ Speed optimized: {darkmyter_features['optimized_for_speed']}\")\n",
        "            print(f\"  ✓ Simple integration: {darkmyter_features['simple_integration']}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def evaluate_use_cases(self, common_metrics, specific_metrics):\n",
        "        \"\"\"Score each system for different use cases\"\"\"\n",
        "        use_cases = {}\n",
        "\n",
        "        print(\"\\nUse Case Suitability Scores (0-100):\")\n",
        "\n",
        "        # Use Case 1: Real-time tracking\n",
        "        print(\"\\n  Real-time Tracking:\")\n",
        "        use_cases[\"realtime\"] = {}\n",
        "        for system in common_metrics.keys():\n",
        "            score = 0\n",
        "            score += common_metrics[system][\"avg_confidence\"] * 30\n",
        "            score += common_metrics[system][\"coverage\"] * 20\n",
        "\n",
        "            if system == \"darkmyter\":\n",
        "                score += 30  # Speed optimized\n",
        "            elif system == \"tracklab\":\n",
        "                score += 20  # Flexible but not speed-focused\n",
        "            elif system == \"eagle\":\n",
        "                score += 0   # Too slow for real-time\n",
        "\n",
        "            use_cases[\"realtime\"][system] = min(score, 100)\n",
        "            print(f\"    {system}: {use_cases['realtime'][system]:.1f}\")\n",
        "\n",
        "        # Use Case 2: Tactical analysis\n",
        "        print(\"\\n  Tactical Analysis:\")\n",
        "        use_cases[\"tactical\"] = {}\n",
        "        for system in common_metrics.keys():\n",
        "            score = 0\n",
        "            score += common_metrics[system][\"track_consistency\"] * 20\n",
        "\n",
        "            if system == \"eagle\" and system in specific_metrics:\n",
        "                eagle_feats = specific_metrics[\"eagle\"]\n",
        "                score += 20 if eagle_feats.get(\"has_homography\") else 0\n",
        "                score += 20 if eagle_feats.get(\"has_team_classification\") else 0\n",
        "                score += 20 if eagle_feats.get(\"has_pitch_coordinates\") else 0\n",
        "                score += 20 if eagle_feats.get(\"has_ball_tracking\") else 0\n",
        "            elif system == \"tracklab\":\n",
        "                score += 30  # Good tracking quality\n",
        "            elif system == \"darkmyter\":\n",
        "                score += 25  # Football-specific\n",
        "\n",
        "            use_cases[\"tactical\"][system] = min(score, 100)\n",
        "            print(f\"    {system}: {use_cases['tactical'][system]:.1f}\")\n",
        "\n",
        "        # Use Case 3: Research/Experimentation\n",
        "        print(\"\\n  Research & Development:\")\n",
        "        use_cases[\"research\"] = {}\n",
        "        for system in common_metrics.keys():\n",
        "            score = 0\n",
        "\n",
        "            if system == \"tracklab\" and system in specific_metrics:\n",
        "                score += 40  # Modular architecture\n",
        "                score += 30  # Multiple options\n",
        "                score += 20  # Research framework\n",
        "            elif system == \"eagle\":\n",
        "                score += 30  # Complex features\n",
        "            elif system == \"darkmyter\":\n",
        "                score += 20  # Simple baseline\n",
        "\n",
        "            score += common_metrics[system][\"avg_confidence\"] * 10\n",
        "\n",
        "            use_cases[\"research\"][system] = min(score, 100)\n",
        "            print(f\"    {system}: {use_cases['research'][system]:.1f}\")\n",
        "\n",
        "        return use_cases\n",
        "\n",
        "    def compute_fair_rankings(self, common_metrics, specific_metrics, use_case_scores):\n",
        "        \"\"\"Provide context-aware rankings\"\"\"\n",
        "\n",
        "        print(\"\\nOVERALL RANKINGS BY CONTEXT:\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Best for each use case\n",
        "        for use_case, scores in use_case_scores.items():\n",
        "            ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "            print(f\"\\nBest for {use_case.title()}:\")\n",
        "            for i, (system, score) in enumerate(ranked, 1):\n",
        "                print(f\"  {i}. {system}: {score:.1f}/100\")\n",
        "\n",
        "        # Overall balanced score\n",
        "        print(\"\\nBalanced Overall Score:\")\n",
        "        overall_scores = {}\n",
        "        for system in common_metrics.keys():\n",
        "            score = 0\n",
        "            # Common metrics (40% weight)\n",
        "            score += common_metrics[system][\"avg_confidence\"] * 10\n",
        "            score += common_metrics[system][\"track_consistency\"] * 15\n",
        "            score += common_metrics[system][\"coverage\"] * 15\n",
        "\n",
        "            # Average use case performance (60% weight)\n",
        "            use_case_avg = np.mean([scores[system] for scores in use_case_scores.values()])\n",
        "            score += use_case_avg * 0.6\n",
        "\n",
        "            overall_scores[system] = score\n",
        "\n",
        "        ranked_overall = sorted(overall_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "        for i, (system, score) in enumerate(ranked_overall, 1):\n",
        "            print(f\"  {i}. {system}: {score:.1f}/100\")\n",
        "\n",
        "        # Save comprehensive results\n",
        "        self.results = {\n",
        "            \"common_metrics\": common_metrics,\n",
        "            \"specific_capabilities\": specific_metrics,\n",
        "            \"use_case_scores\": use_case_scores,\n",
        "            \"overall_ranking\": ranked_overall,\n",
        "            \"evaluation_type\": \"comprehensive_fair\"\n",
        "        }\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"FAIR EVALUATION COMPLETE\")\n",
        "        print(\"Each system evaluated on its intended strengths\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "    def calculate_track_consistency(self, detections):\n",
        "        \"\"\"Calculate how consistent tracks are\"\"\"\n",
        "        if not detections:\n",
        "            return 0\n",
        "\n",
        "        tracks = defaultdict(list)\n",
        "        for d in detections:\n",
        "            tracks[d.get(\"track_id\", 0)].append(d.get(\"frame_id\", 0))\n",
        "\n",
        "        consistencies = []\n",
        "        for track_id, frames in tracks.items():\n",
        "            if len(frames) > 1:\n",
        "                frames_sorted = sorted(frames)\n",
        "                gaps = [frames_sorted[i+1] - frames_sorted[i] for i in range(len(frames_sorted)-1)]\n",
        "                consistency = 1.0 / (1 + np.std(gaps)) if gaps else 1.0\n",
        "                consistencies.append(consistency)\n",
        "\n",
        "        return np.mean(consistencies) if consistencies else 0\n",
        "\n",
        "    def calculate_coverage(self, detections):\n",
        "        \"\"\"Calculate frame coverage\"\"\"\n",
        "        if not detections:\n",
        "            return 0\n",
        "\n",
        "        frames = set(d.get(\"frame_id\", 0) for d in detections)\n",
        "        if frames:\n",
        "            frame_range = max(frames) - min(frames) + 1\n",
        "            return len(frames) / frame_range if frame_range > 0 else 0\n",
        "        return 0\n",
        "\n",
        "# ================================\n",
        "# Run Comprehensive Fair Evaluation\n",
        "# ================================\n",
        "\n",
        "fair_evaluator = ComprehensiveFairEvaluator()\n",
        "fair_results = fair_evaluator.evaluate_all_systems(all_results)\n",
        "\n",
        "# Save fair evaluation results\n",
        "fair_eval_file = OUTPUT_DIR / \"fair_evaluation_report.json\"\n",
        "with open(fair_eval_file, \"w\") as f:\n",
        "    json.dump(fair_results, f, indent=2)\n",
        "\n",
        "print(f\"\\n✅ Fair evaluation report saved to: {fair_eval_file}\")"
      ],
      "metadata": {
        "id": "CEQ4BiwHwTq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download"
      },
      "outputs": [],
      "source": [
        "# Cell 9: Download results\n",
        "\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "print_status(\"Creating archive...\", \"INFO\")\n",
        "\n",
        "archive_name = \"tracking_results\"\n",
        "archive_path = BASE_DIR / archive_name\n",
        "\n",
        "shutil.make_archive(str(archive_path), 'zip', OUTPUT_DIR)\n",
        "\n",
        "print_status(\"Downloading...\", \"SUCCESS\")\n",
        "files.download(f\"{archive_path}.zip\")\n",
        "\n",
        "print_status(\"Complete!\", \"SUCCESS\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}